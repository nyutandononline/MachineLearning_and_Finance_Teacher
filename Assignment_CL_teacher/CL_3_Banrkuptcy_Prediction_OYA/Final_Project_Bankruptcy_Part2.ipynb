{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem description\n",
    "\n",
    "You are to predict whether a company will go bankrupt in the following year, based on financial attributes of the company.\n",
    "\n",
    "Perhaps you are contemplating lending money to a company, and need to know whether the company\n",
    "is in near-term danger of not being able to repay.\n",
    "\n",
    "This task is divided in to two parts,\n",
    "- Part 1 is the Assignment 3\n",
    "- Part 2 is this final project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Goal\n",
    "\n",
    "In the Assignment 3, we went through the first few but very important steps to solve a machine learning problem, and we got the data prepared for the final project. \n",
    "\n",
    "Now, you will need to build your own models to train your prepared dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Demonstrate mastery on solving a classification problem and presenting\n",
    "the entire Recipe for Machine Learning process in a notebook.\n",
    "- We will make suggestions for ways to approach the problem\n",
    "    - But there will be little explicit direction for this task.\n",
    "- It is meant to be analogous to a pre-interview task that a potential employer might assign\n",
    "to verify your skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Grading\n",
    "Prior assignments evaluated you step by step.\n",
    "\n",
    "This project is results-based. Your goal is to create a well performed model.\n",
    "\n",
    "We will evaluate the metric using 3 increasing values for the threshold\n",
    "- You will get points for each threshold that you surpass\n",
    "\n",
    "There are 2 data files in this directory:\n",
    "\n",
    "- train.csv:\n",
    "This is the dataset on which you will train your model\n",
    "- test.csv:\n",
    "    - This is the dataset by which you will be judged !\n",
    "    - It has no labels so you can't use it to train or test your model\n",
    "        - But we do have the labels so we can test your accuracy\n",
    "    - Once you have built your model, you will make predictions on these examples and submit them for grading\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Load the bankruptcy_helper module\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Import bankruptcy_helper module\n",
    "import bankruptcy_helper\n",
    "%aimport bankruptcy_helper\n",
    "\n",
    "helper = bankruptcy_helper.Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# API for students\n",
    "\n",
    "We have defined some utility routines in a file `bankruptcy_helper.py`. There is a class named `Helper` in it.  \n",
    "\n",
    "This will simplify problem solving\n",
    "\n",
    "\n",
    "\n",
    "`helper = bankruptcy_helper.Helper()`\n",
    "\n",
    "- plot_attr: plot the distribution of one feature, conditional on the value of the associated target value\n",
    "  > `X`: features      \n",
    "  > `y`: labels       \n",
    "  > `attr`: condition feature        \n",
    "  > `trunc`: percentage of outliers you want to remove  \n",
    "  \n",
    "  >`helper.plot_attr(X, y, attr, trunc)`       \n",
    "\n",
    "- save_data: save the training and test data into a folder named \"my_data\"\n",
    "  > `helper.save_data(X_train, X_test, y_train, y_test)`\n",
    " \n",
    "- load_data: load the training and test data from a folder named \"my_data\"\n",
    "  > `X_train, X_test, y_train, y_test = helper.load_data()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Load the data\n",
    "\n",
    "The first step we need to do in this project is to load the data we have dealed with in the Assignment 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (4336, 65)\n",
      "X_test shape: (482, 65)\n"
     ]
    }
   ],
   "source": [
    "# Load the data you have prepared for this project\n",
    "X_train, X_test, y_train, y_test = helper.load_data()\n",
    "\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Your model\n",
    "\n",
    "Time for you to continue the Recipe for Machine Learning on your own.\n",
    "\n",
    "Follow the steps and submit your *best* model.\n",
    "\n",
    "For your best model, using the test set you created, report\n",
    "- Accuracy \n",
    "- Recall\n",
    "- Precision\n",
    "\n",
    "We will evaluate your model using the holdout data.  Grades will be based on\n",
    "the following metrics meeting certain thresholds\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "\n",
    "We will evaluate the metric using 3 increasing values for the threshold\n",
    "- You will get points for each threshold that you surpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM (t=None) avg cross val score=0.9382\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSVM Accuracy: 91.7%, Recall 0.0%, Precision 0.0%\n",
      "Model: Random Forest (t=None) avg cross val score=0.9405\n",
      "\n",
      "\tRandom Forest Accuracy: 93.2%, Recall 25.0%, Precision 76.9%\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, classification_report\n",
    "\n",
    "impute_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "\n",
    "## SVM and Random Forest model\n",
    "# logistic_clf = linear_model.LogisticRegression(solver = 'liblinear', max_iter = 10000)\n",
    "svm_clf = SVC(gamma=\"auto\", C=.1)\n",
    "forest_clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "r = \"None\"\n",
    "\n",
    "for name, clf in { \"SVM\": svm_clf,\n",
    "                   \"Random Forest\": forest_clf\n",
    "                 }.items():\n",
    "    \n",
    "    pipe = Pipeline([(\"imputer\", impute_transformer), \n",
    "                      (\"model\", clf)\n",
    "                     ]\n",
    "                    )\n",
    "    \n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "    print(\"Model: {m:s} (t={r:s}) avg cross val score={s:3.4f}\\n\".format(m=name, r=r, s=scores.mean()) )\n",
    "\n",
    "    # Out of sample prediction\n",
    "    _= pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # recall_\n",
    "    recall_test = recall_score(y_test, y_pred, pos_label=1, average=\"binary\")\n",
    "    precision_test = precision_score(y_test,   y_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "\n",
    "    print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                                a=accuracy_test,\n",
    "                                                                                r=recall_test,\n",
    "                                                                                p=precision_test\n",
    "                                                                                )\n",
    "         )\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Models wih Dimensionality reduction\n",
    "\n",
    "- Reduce the number of features\n",
    "    -Try other models. For example, PCA\n",
    "- Cost sensitive training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM (t=1) avg cross val score=0.9382\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSVM Accuracy: 91.7%, Recall 0.0%, Precision 0.0%\n",
      "Model: Logistic (t=1) avg cross val score=0.9345\n",
      "\n",
      "\tLogistic Accuracy: 91.5%, Recall 0.0%, Precision 0.0%\n",
      "Model: SVM (t=10) avg cross val score=0.8750\n",
      "\n",
      "\tSVM Accuracy: 85.7%, Recall 47.5%, Precision 28.4%\n",
      "Model: Logistic (t=10) avg cross val score=0.8741\n",
      "\n",
      "\tLogistic Accuracy: 85.3%, Recall 47.5%, Precision 27.5%\n",
      "Model: SVM (t=12) avg cross val score=0.8522\n",
      "\n",
      "\tSVM Accuracy: 82.6%, Recall 55.0%, Precision 25.0%\n",
      "Model: Logistic (t=12) avg cross val score=0.8448\n",
      "\n",
      "\tLogistic Accuracy: 83.4%, Recall 62.5%, Precision 27.8%\n",
      "Model: SVM (t=13) avg cross val score=0.8342\n",
      "\n",
      "\tSVM Accuracy: 81.3%, Recall 60.0%, Precision 24.5%\n",
      "Model: Logistic (t=13) avg cross val score=0.8263\n",
      "\n",
      "\tLogistic Accuracy: 81.1%, Recall 62.5%, Precision 24.8%\n",
      "Model: SVM (t=15) avg cross val score=0.7952\n",
      "\n",
      "\tSVM Accuracy: 78.4%, Recall 65.0%, Precision 22.4%\n",
      "Model: Logistic (t=15) avg cross val score=0.7874\n",
      "\n",
      "\tLogistic Accuracy: 78.2%, Recall 75.0%, Precision 24.0%\n",
      "Model: SVM (t=18) avg cross val score=0.7368\n",
      "\n",
      "\tSVM Accuracy: 72.2%, Recall 82.5%, Precision 20.6%\n",
      "Model: Logistic (t=18) avg cross val score=0.7299\n",
      "\n",
      "\tLogistic Accuracy: 71.8%, Recall 82.5%, Precision 20.4%\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stand_transformer = StandardScaler()\n",
    "\n",
    "cwt = { 0:1, 1:20 }\n",
    "\n",
    "\n",
    "\n",
    "for r in [ 1, 10, 12, 13, 15, 18]:\n",
    "    cwt = { 0:1, 1:r }\n",
    "    \n",
    "    logistic_clf = linear_model.LogisticRegression(\n",
    "        class_weight = cwt,\n",
    "        solver = 'liblinear', max_iter = 10000)\n",
    "    svm_clf = SVC(class_weight = cwt,\n",
    "              gamma=\"auto\", C=.1)\n",
    "    \n",
    "    for name, clf in { \"SVM\": svm_clf,\n",
    "                       \"Logistic\": logistic_clf\n",
    "                     }.items():\n",
    "\n",
    "        pipe = Pipeline([(\"imputer\", impute_transformer), \n",
    "                         (\"Standardize\", stand_transformer),\n",
    "                         (\"PCA\", PCA(n_components = 20)),\n",
    "                         (\"model\", clf)\n",
    "                         ]\n",
    "                        )\n",
    "        scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "        print(\"Model: {m:s} (t={r:d}) avg cross val score={s:3.4f}\\n\".format(m=name, r=r, s=scores.mean()) )\n",
    "\n",
    "        # Out of sample prediction\n",
    "        _= pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "\n",
    "        accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # recall_\n",
    "        recall_test = recall_score(y_test, y_pred, pos_label=1, average=\"binary\")\n",
    "        precision_test = precision_score(y_test,   y_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "        \n",
    "        print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                                    a=accuracy_test,\n",
    "                                                                                    r=recall_test,\n",
    "                                                                                    p=precision_test\n",
    "                                                                                    )\n",
    "             )\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Submission guidelines\n",
    "\n",
    "- You will implement the body of a subroutine `MyModel`\n",
    "    - That takes as argument a Pandas DataFrame \n",
    "        - Each row is an example on which to predict\n",
    "        - The features of the example are elements of the row\n",
    "    - Performs predictions on each example\n",
    "    - Returns an array or predictions with a one-to-one correspondence with the examples in the test set\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We will evaluate your model against the holdout data\n",
    "- By reading the holdout examples `X_hold` (as above)\n",
    "- Calling `y_hold_pred = MyModel(X_hold)` to get the predictions\n",
    "- Comparing the predicted values `y_hold_pred` against the true labels `y_hold` which are known only to the instructors\n",
    "\n",
    "See the following cell as an illustration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "X_hold = pd.read_csv('../resource/asnlib/publicdata/test.csv')\n",
    "\n",
    "# Predict using MyModel\n",
    "y_hold_pred = MyModel(X_hold)\n",
    "\n",
    "# Compute metrics\n",
    "# accuracy\n",
    "accuracy_hold = accuracy_score(y_hold, y_hold_pred)\n",
    "\n",
    "# recall_\n",
    "recall_hold = recall_score(y_hold, y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "# precision\n",
    "precision_hold = precision_score(y_hold,   y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "\n",
    "print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                            a=accuracy_hold,\n",
    "                                                                            r=recall_hold,\n",
    "                                                                            p=precision_hold\n",
    "                                                                            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Remember**\n",
    "\n",
    "The holdout data is in the same format as the one we used for training\n",
    "- Except that it has no attribute for the target\n",
    "- So you will need to **perform all the transformations on the holdout data**\n",
    "    - As you did on the training data\n",
    "    - Including turning the string representation of numbers into actual numeric data types\n",
    "\n",
    "All of this work *must* be performed within the body of the `MyModel` routine you will write\n",
    "\n",
    "We will grade you by comparing the predictions array you create to the answers known to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def MyModel(X):\n",
    "    # It should create an array of predictions; we initialize it to the empty array for convenience\n",
    "    predictions = []\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    # Relative weight of Bankrupt class to Non Bankrupt class\n",
    "    r = 13\n",
    "    \n",
    "    # Class weights\n",
    "    cwt = { 0:1, 1:r }\n",
    "    \n",
    "    logistic_clf = linear_model.LogisticRegression(\n",
    "        class_weight = cwt,\n",
    "        solver = 'liblinear', max_iter = 10000)\n",
    "    name = \"Logistic\"\n",
    "   \n",
    "    pipe = Pipeline([(\"imputer\", impute_transformer), \n",
    "                     (\"Standardize\", stand_transformer),\n",
    "                     (\"PCA\", PCA(n_components = 20)),\n",
    "                     (\"model\", logistic_clf)\n",
    "                     ]\n",
    "                   )\n",
    "   \n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "    print(\"Model: {m:s} (t={r:d}) avg cross val score={s:3.4f}\\n\".format(m=name, r=r, s=scores.mean()) )\n",
    "\n",
    "    # Fit the model\n",
    "    _= pipe.fit(X_train, y_train)\n",
    "                    \n",
    "    # Out of sample prediction \n",
    "    y_pred = pipe.predict(X)\n",
    "    \n",
    " \n",
    "    predictions = y_pred\n",
    "    \n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Check your work: predict and evaluate metrics on *your* test examples\n",
    "- Test whether your implementation of `MyModel` works\n",
    "- See the metrics  your model produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic (t=13) avg cross val score=0.8270\n",
      "\n",
      "\tLogistic Accuracy: 81.1%, Recall 62.5%, Precision 24.8%\n"
     ]
    }
   ],
   "source": [
    "# Predict the data using X_test\n",
    "y_test_pred = MyModel(X_test)\n",
    "\n",
    "# Get the accuracy, recall and precision of your model\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred, pos_label=1, average=\"binary\")\n",
    "precision_test = precision_score(y_test,   y_test_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                            a=accuracy_test,\n",
    "                                                                            r=recall_test,\n",
    "                                                                            p=precision_test\n",
    "                                                                            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check accuracy\n",
    "assert(accuracy_test > 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check recall and precision\n",
    "assert( ( (recall_test  > 0.50) and (precision_test > 0.15) )\n",
    "       or\n",
    "        ( (recall_test  > 0.20) and (precision_test > 0.50) )\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Extra points\n",
    "assert(accuracy_test > .80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Extra points\n",
    "assert( ( (recall_test > .60) and (precision_test > 0.20) )\n",
    "       or\n",
    "        ( (recall_test  > 0.20) and (precision_test > 0.60) )\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# This is how we will evaluate your model on the holdout examples"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "X_hold = pd.read_csv('../resource/asnlib/publicdata/test.csv')\n",
    "\n",
    "print(\"Data shape: \", X_hold.shape)\n",
    "\n",
    "if False: # Only teacher can evaluate the rest: Needs true targets y_hold\n",
    "    y_hold_pred = MyModel(X_hold)\n",
    "    accuracy_hold = accuracy_score(y_hold, y_hold_pred)\n",
    "\n",
    "    # recall_\n",
    "    recall_hold = recall_score(y_hold, y_hold_pred, pos_label=1, average=\"binary\")\n",
    "    precision_hold = precision_score(y_hold,   y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "\n",
    "    print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                                a=accuracy_hold,\n",
    "                                                                                r=recall_hold,\n",
    "                                                                                p=precision_hold\n",
    "                                                                                )\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-accuracy",
     "locked": true,
     "points": "50",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "DATA_DIR = './Data'\n",
    "file_name = 'test_with_labels.csv'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    DATA_DIR = '../resource/asnlib'\n",
    "y_hold = pd.read_csv(os.path.join(DATA_DIR, file_name))\n",
    "y_hold_pred = MyModel(X_hold)\n",
    "\n",
    "# accuracy\n",
    "accuracy_hold = accuracy_score(y_hold, y_hold_pred)\n",
    "\n",
    "# recall & precision\n",
    "recall_hold = recall_score(y_hold, y_hold_pred, pos_label=1, average=\"binary\")\n",
    "precision_hold = precision_score(y_hold,   y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "# check accuracy\n",
    "assert(accuracy_hold > 0.75)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-recall-precision",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "assert( ( (recall_hold  > 0.50) and (precision_hold > 0.15) )\n",
    "       or\n",
    "        ( (recall_hold  > 0.20) and (precision_hold > 0.50) )\n",
    "      )\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-higher-accuracy",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Extra points\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert(accuracy_hold > .80)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-higher-recall-precision",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Extra points\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert( ( (recall_hold > .60) and (precision_hold > 0.20) )\n",
    "       or\n",
    "        ( (recall_hold  > 0.20) and (precision_hold > 0.60) )\n",
    "      )\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "- Most of the features are expressed as ratios: why is that a good idea ?\n",
    "- Even if you don't understand all of the financial concepts behind the names of the attributes\n",
    "    - You should be able to infer some relationships.  For example, here are some definitions of terms\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "X1   & = & \\frac{\\text{net profit} }{ \\text{total assets} } \\\\\n",
    "X9   & = & \\frac{\\text{sales}     }{ \\text{total assets} } \\\\\n",
    "X23  & = & \\frac{\\text{net profit} }{ \\text{sales} } \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "    - Therefore\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "X23  & = & \\frac{X1}{X9} & \\text{Algebra !}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "    - You might speculate that `net profit` is closely related to `gross profit`\n",
    "        - The difference between \"net\" and \"gross\" is usually some type of additions/subtractions\n",
    "    - Is this theory reflected in which features are most highly correlated with `X1` ?\n",
    "- If you perform dimensionality reduction using PCA (the topic of the Unsupervised Learning lecture)\n",
    "    - PCA is scale sensitive\n",
    "    - If you *don't* scale the features: how many do you need to capture 95% of the variance ?\n",
    "    - If you *do* scale the features: how many do you need to capture 95% of the variance ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
