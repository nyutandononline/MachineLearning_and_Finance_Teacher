{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description\n",
    "\n",
    "You are to predict whether a company will go bankrupt in the following year, based on financial attributes of the company.\n",
    "\n",
    "Perhaps you are contemplating lending money to a company, and need to know whether the company\n",
    "is in near-term danger of not being able to repay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Demonstrate mastery on solving a classification problem and presenting\n",
    "the entire Recipe for Machine Learning process in a notebook.\n",
    "- We will make suggestions for ways to approach the problem\n",
    "    - But there will be little explicit direction for this task.\n",
    "- It is meant to be analogous to a pre-interview task that a potential employer might assign\n",
    "to verify your skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API for students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the bankruptcy_helper module\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Import bankruptcy_helper module\n",
    "import bankruptcy_helper\n",
    "%aimport bankruptcy_helper\n",
    "\n",
    "helper = bankruptcy_helper.Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "\n",
    "The first step in our Recipe is Get the Data.\n",
    "\n",
    "- Each example is a row of data corresponding to a single company\n",
    "- There are 64 attributes, described in the section below\n",
    "- The column `Bankrupt` is 1 if the company subsequently went bankrupt; 0 if it did not go bankrupt\n",
    "- The column `Id` is a Company Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date shape:  (4818, 66)\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "DATA_DIR = \"./Data\"\n",
    "\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    DATA_DIR = \"../resource/asnlib/publicdata/bankruptcy/data\"\n",
    "\n",
    "data_file = \"5th_yr.csv\"\n",
    "data = pd.read_csv( os.path.join(DATA_DIR, \"train\", data_file) )\n",
    "\n",
    "target_attr = \"Bankrupt\"\n",
    "\n",
    "n_samples, n_attrs = data.shape\n",
    "print(\"Date shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data\n",
    "\n",
    "We will not go through all steps in the Recipe, nor in depth.\n",
    "\n",
    "But here's a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.41769</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>1.1605</td>\n",
       "      <td>-126.39</td>\n",
       "      <td>0.41355</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>1.2395</td>\n",
       "      <td>1.16500</td>\n",
       "      <td>0.51773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049094</td>\n",
       "      <td>0.85835</td>\n",
       "      <td>0.12322</td>\n",
       "      <td>5.6167</td>\n",
       "      <td>7.4042</td>\n",
       "      <td>164.310</td>\n",
       "      <td>2.2214</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0</td>\n",
       "      <td>4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.023834</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.50839</td>\n",
       "      <td>4.2374</td>\n",
       "      <td>22.034</td>\n",
       "      <td>0.058412</td>\n",
       "      <td>-0.027621</td>\n",
       "      <td>3.6579</td>\n",
       "      <td>0.98183</td>\n",
       "      <td>0.76855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031011</td>\n",
       "      <td>1.01850</td>\n",
       "      <td>0.069047</td>\n",
       "      <td>5.7996</td>\n",
       "      <td>7.7529</td>\n",
       "      <td>26.446</td>\n",
       "      <td>13.802</td>\n",
       "      <td>6.4782</td>\n",
       "      <td>0</td>\n",
       "      <td>3537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030515</td>\n",
       "      <td>0.44606</td>\n",
       "      <td>0.19569</td>\n",
       "      <td>1.565</td>\n",
       "      <td>35.766</td>\n",
       "      <td>0.28196</td>\n",
       "      <td>0.039264</td>\n",
       "      <td>0.88456</td>\n",
       "      <td>1.05260</td>\n",
       "      <td>0.39457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077337</td>\n",
       "      <td>0.95006</td>\n",
       "      <td>0.25266</td>\n",
       "      <td>15.049</td>\n",
       "      <td>2.8179</td>\n",
       "      <td>104.730</td>\n",
       "      <td>3.4852</td>\n",
       "      <td>2.6361</td>\n",
       "      <td>0</td>\n",
       "      <td>3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.052318</td>\n",
       "      <td>0.056366</td>\n",
       "      <td>0.54562</td>\n",
       "      <td>10.68</td>\n",
       "      <td>438.2</td>\n",
       "      <td>0.13649</td>\n",
       "      <td>0.058164</td>\n",
       "      <td>10.853</td>\n",
       "      <td>1.02790</td>\n",
       "      <td>0.61173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085524</td>\n",
       "      <td>0.97282</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0157</td>\n",
       "      <td>7.4626</td>\n",
       "      <td>48.756</td>\n",
       "      <td>7.4863</td>\n",
       "      <td>1.0602</td>\n",
       "      <td>0</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.49712</td>\n",
       "      <td>0.12316</td>\n",
       "      <td>1.3036</td>\n",
       "      <td>-71.398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>1.0116</td>\n",
       "      <td>1.29210</td>\n",
       "      <td>0.50288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.99925</td>\n",
       "      <td>0.019736</td>\n",
       "      <td>3.4819</td>\n",
       "      <td>8.582</td>\n",
       "      <td>114.580</td>\n",
       "      <td>3.1854</td>\n",
       "      <td>2.742</td>\n",
       "      <td>0</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2       X3      X4       X5        X6         X7  \\\n",
       "0   0.025417   0.41769   0.0568  1.1605  -126.39   0.41355   0.025417   \n",
       "1  -0.023834    0.2101  0.50839  4.2374   22.034  0.058412  -0.027621   \n",
       "2   0.030515   0.44606  0.19569   1.565   35.766   0.28196   0.039264   \n",
       "3   0.052318  0.056366  0.54562   10.68    438.2   0.13649   0.058164   \n",
       "4   0.000992   0.49712  0.12316  1.3036  -71.398         0   0.001007   \n",
       "\n",
       "        X8       X9      X10  ...        X57      X58       X59     X60  \\\n",
       "0   1.2395  1.16500  0.51773  ...   0.049094  0.85835   0.12322  5.6167   \n",
       "1   3.6579  0.98183  0.76855  ...  -0.031011  1.01850  0.069047  5.7996   \n",
       "2  0.88456  1.05260  0.39457  ...   0.077337  0.95006   0.25266  15.049   \n",
       "3   10.853  1.02790  0.61173  ...   0.085524  0.97282         0  6.0157   \n",
       "4   1.0116  1.29210  0.50288  ...   0.001974  0.99925  0.019736  3.4819   \n",
       "\n",
       "      X61      X62     X63     X64  Bankrupt    Id  \n",
       "0  7.4042  164.310  2.2214   1.334         0  4510  \n",
       "1  7.7529   26.446  13.802  6.4782         0  3537  \n",
       "2  2.8179  104.730  3.4852  2.6361         0  3920  \n",
       "3  7.4626   48.756  7.4863  1.0602         0  1806  \n",
       "4   8.582  114.580  3.1854   2.742         0  1529  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty *unhelpful* !\n",
    "\n",
    "What are these mysteriously named features ?\n",
    "\n",
    "## Description of attributes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "Id Company Identifier \n",
    "X1 net profit / total assets\n",
    "X2 total liabilities / total assets\n",
    "X3 working capital / total assets\n",
    "X4 current assets / short-term liabilities\n",
    "X5 [(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365\n",
    "X6 retained earnings / total assets\n",
    "X7 EBIT / total assets\n",
    "X8 book value of equity / total liabilities\n",
    "X9 sales / total assets\n",
    "X10 equity / total assets\n",
    "X11 (gross profit + extraordinary items + financial expenses) / total assets\n",
    "X12 gross profit / short-term liabilities\n",
    "X13 (gross profit + depreciation) / sales\n",
    "X14 (gross profit + interest) / total assets\n",
    "X15 (total liabilities * 365) / (gross profit + depreciation)\n",
    "X16 (gross profit + depreciation) / total liabilities\n",
    "X17 total assets / total liabilities\n",
    "X18 gross profit / total assets\n",
    "X19 gross profit / sales\n",
    "X20 (inventory * 365) / sales\n",
    "X21 sales (n) / sales (n-1)\n",
    "X22 profit on operating activities / total assets\n",
    "X23 net profit / sales\n",
    "X24 gross profit (in 3 years) / total assets\n",
    "X25 (equity - share capital) / total assets\n",
    "X26 (net profit + depreciation) / total liabilities\n",
    "X27 profit on operating activities / financial expenses\n",
    "X28 working capital / fixed assets\n",
    "X29 logarithm of total assets\n",
    "X30 (total liabilities - cash) / sales\n",
    "X31 (gross profit + interest) / sales\n",
    "X32 (current liabilities * 365) / cost of products sold\n",
    "X33 operating expenses / short-term liabilities\n",
    "X34 operating expenses / total liabilities\n",
    "X35 profit on sales / total assets\n",
    "X36 total sales / total assets\n",
    "X37 (current assets - inventories) / long-term liabilities\n",
    "X38 constant capital / total assets\n",
    "X39 profit on sales / sales\n",
    "X40 (current assets - inventory - receivables) / short-term liabilities\n",
    "X41 total liabilities / ((profit on operating activities + depreciation) * (12/365))\n",
    "X42 profit on operating activities / sales\n",
    "X43 rotation receivables + inventory turnover in days\n",
    "X44 (receivables * 365) / sales\n",
    "X45 net profit / inventory\n",
    "X46 (current assets - inventory) / short-term liabilities\n",
    "X47 (inventory * 365) / cost of products sold\n",
    "X48 EBITDA (profit on operating activities - depreciation) / total assets\n",
    "X49 EBITDA (profit on operating activities - depreciation) / sales\n",
    "X50 current assets / total liabilities\n",
    "X51 short-term liabilities / total assets\n",
    "X52 (short-term liabilities * 365) / cost of products sold)\n",
    "X53 equity / fixed assets\n",
    "X54 constant capital / fixed assets\n",
    "X55 working capital\n",
    "X56 (sales - cost of products sold) / sales\n",
    "X57 (current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)\n",
    "X58 total costs /total sales\n",
    "X59 long-term liabilities / equity\n",
    "X60 sales / inventory\n",
    "X61 sales / receivables\n",
    "X62 (short-term liabilities *365) / sales\n",
    "X63 sales / short-term liabilities\n",
    "X64 sales / fixed assets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may still be somewhat unhelpful for those of you not used to reading Financial Statements.\n",
    "\n",
    "But that's partially the point of the exercise\n",
    "- You can *still* perform Machine Learning *even if* you are not an expert in the problem domain\n",
    "    - That's what makes this a good interview exercise: you can demonstrate your thought process even if you don't know the exact meaning of the terms\n",
    "- Of course: becoming an expert in the domain *will improve* your ability to create better models\n",
    "    - Feature engineering is easier if you understand the features, their inter-relationships, and the relationship to the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a feel for the data\n",
    "- What is the type of each attribute ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      "X1          4818 non-null object\n",
      "X2          4818 non-null object\n",
      "X3          4818 non-null object\n",
      "X4          4818 non-null object\n",
      "X5          4818 non-null object\n",
      "X6          4818 non-null object\n",
      "X7          4818 non-null object\n",
      "X8          4818 non-null object\n",
      "X9          4818 non-null float64\n",
      "X10         4818 non-null object\n",
      "X11         4818 non-null object\n",
      "X12         4818 non-null object\n",
      "X13         4818 non-null float64\n",
      "X14         4818 non-null object\n",
      "X15         4818 non-null object\n",
      "X16         4818 non-null object\n",
      "X17         4818 non-null object\n",
      "X18         4818 non-null object\n",
      "X19         4818 non-null float64\n",
      "X20         4818 non-null float64\n",
      "X21         4818 non-null object\n",
      "X22         4818 non-null object\n",
      "X23         4818 non-null float64\n",
      "X24         4818 non-null object\n",
      "X25         4818 non-null object\n",
      "X26         4818 non-null object\n",
      "X27         4818 non-null object\n",
      "X28         4818 non-null object\n",
      "X29         4818 non-null object\n",
      "X30         4818 non-null float64\n",
      "X31         4818 non-null float64\n",
      "X32         4818 non-null object\n",
      "X33         4818 non-null object\n",
      "X34         4818 non-null object\n",
      "X35         4818 non-null object\n",
      "X36         4818 non-null object\n",
      "X37         4818 non-null object\n",
      "X38         4818 non-null object\n",
      "X39         4818 non-null float64\n",
      "X40         4818 non-null object\n",
      "X41         4818 non-null object\n",
      "X42         4818 non-null float64\n",
      "X43         4818 non-null float64\n",
      "X44         4818 non-null float64\n",
      "X45         4818 non-null object\n",
      "X46         4818 non-null object\n",
      "X47         4818 non-null object\n",
      "X48         4818 non-null object\n",
      "X49         4818 non-null float64\n",
      "X50         4818 non-null object\n",
      "X51         4818 non-null object\n",
      "X52         4818 non-null object\n",
      "X53         4818 non-null object\n",
      "X54         4818 non-null object\n",
      "X55         4818 non-null float64\n",
      "X56         4818 non-null float64\n",
      "X57         4818 non-null object\n",
      "X58         4818 non-null float64\n",
      "X59         4818 non-null object\n",
      "X60         4818 non-null object\n",
      "X61         4818 non-null object\n",
      "X62         4818 non-null float64\n",
      "X63         4818 non-null object\n",
      "X64         4818 non-null object\n",
      "Bankrupt    4818 non-null int64\n",
      "Id          4818 non-null int64\n",
      "dtypes: float64(16), int64(2), object(48)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be puzzled:\n",
    "- Most attributes are `object` and *not* numeric (`float64`)\n",
    "- But looking at the data via `data.head()` certainly gives the impression that all attributes are numeric\n",
    "\n",
    "Welcome to the world of messy data !  The dataset has represented numbers as strings.\n",
    "- These little unexpected challenges are common in the real-word\n",
    "- Data is rarely perfect and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will first have to convert all attributes to numeric\n",
    "\n",
    "**Question**\n",
    "\n",
    "Create an all-numeric version of the data.  Assign it to the variable `data` (replacing the original)\n",
    "\n",
    "**Hint**\n",
    "- Look up the Pandas method `to_numeric`\n",
    "    - We suggest you use the option `errors='coerce'`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "non_numeric_cols = data.select_dtypes(exclude=['float', 'int']).columns\n",
    "data[ non_numeric_cols] = data[ non_numeric_cols ].apply(pd.to_numeric, downcast='float', errors='coerce')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data again, now that it is numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      "X1          4816 non-null float32\n",
      "X2          4816 non-null float32\n",
      "X3          4816 non-null float32\n",
      "X4          4803 non-null float32\n",
      "X5          4808 non-null float32\n",
      "X6          4816 non-null float32\n",
      "X7          4816 non-null float32\n",
      "X8          4804 non-null float32\n",
      "X9          4818 non-null float64\n",
      "X10         4816 non-null float32\n",
      "X11         4816 non-null float32\n",
      "X12         4803 non-null float32\n",
      "X13         4818 non-null float64\n",
      "X14         4816 non-null float32\n",
      "X15         4812 non-null float32\n",
      "X16         4804 non-null float32\n",
      "X17         4804 non-null float32\n",
      "X18         4816 non-null float32\n",
      "X19         4818 non-null float64\n",
      "X20         4818 non-null float64\n",
      "X21         4744 non-null float32\n",
      "X22         4816 non-null float32\n",
      "X23         4818 non-null float64\n",
      "X24         4702 non-null float32\n",
      "X25         4816 non-null float32\n",
      "X26         4804 non-null float32\n",
      "X27         4513 non-null float32\n",
      "X28         4735 non-null float32\n",
      "X29         4816 non-null float32\n",
      "X30         4818 non-null float64\n",
      "X31         4818 non-null float64\n",
      "X32         4776 non-null float32\n",
      "X33         4803 non-null float32\n",
      "X34         4804 non-null float32\n",
      "X35         4816 non-null float32\n",
      "X36         4816 non-null float32\n",
      "X37         2750 non-null float32\n",
      "X38         4816 non-null float32\n",
      "X39         4818 non-null float64\n",
      "X40         4803 non-null float32\n",
      "X41         4756 non-null float32\n",
      "X42         4818 non-null float64\n",
      "X43         4818 non-null float64\n",
      "X44         4818 non-null float64\n",
      "X45         4598 non-null float32\n",
      "X46         4803 non-null float32\n",
      "X47         4787 non-null float32\n",
      "X48         4816 non-null float32\n",
      "X49         4818 non-null float64\n",
      "X50         4804 non-null float32\n",
      "X51         4816 non-null float32\n",
      "X52         4786 non-null float32\n",
      "X53         4735 non-null float32\n",
      "X54         4735 non-null float32\n",
      "X55         4818 non-null float64\n",
      "X56         4818 non-null float64\n",
      "X57         4816 non-null float32\n",
      "X58         4818 non-null float64\n",
      "X59         4816 non-null float32\n",
      "X60         4598 non-null float32\n",
      "X61         4806 non-null float32\n",
      "X62         4818 non-null float64\n",
      "X63         4803 non-null float32\n",
      "X64         4735 non-null float32\n",
      "Bankrupt    4818 non-null int64\n",
      "Id          4818 non-null int64\n",
      "dtypes: float32(48), float64(16), int64(2)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you will see that all the attributes are now numeric.\n",
    "\n",
    "Surprise !\n",
    "\n",
    "Looks like there are some examples with undefined values for some features !\n",
    "- Why didn't we see this when the data was not encoded as numbers ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "List all the attributes of `data` that are missing from at least one example.\n",
    "\n",
    "Set list `attrs_missing` to either a list or array of attributes that are missing from at least one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "num_examples = data.shape[0]\n",
    "num_examples_undefined = data.isnull().sum(axis=0)\n",
    "attrs_missing = num_examples_undefined[ num_examples_undefined > 0 ].index.tolist()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes with values missing for at least some examples\t:\n",
      "\tX1\n",
      "\tX2\n",
      "\tX3\n",
      "\tX4\n",
      "\tX5\n",
      "\tX6\n",
      "\tX7\n",
      "\tX8\n",
      "\tX10\n",
      "\tX11\n",
      "\tX12\n",
      "\tX14\n",
      "\tX15\n",
      "\tX16\n",
      "\tX17\n",
      "\tX18\n",
      "\tX21\n",
      "\tX22\n",
      "\tX24\n",
      "\tX25\n",
      "\tX26\n",
      "\tX27\n",
      "\tX28\n",
      "\tX29\n",
      "\tX32\n",
      "\tX33\n",
      "\tX34\n",
      "\tX35\n",
      "\tX36\n",
      "\tX37\n",
      "\tX38\n",
      "\tX40\n",
      "\tX41\n",
      "\tX45\n",
      "\tX46\n",
      "\tX47\n",
      "\tX48\n",
      "\tX50\n",
      "\tX51\n",
      "\tX52\n",
      "\tX53\n",
      "\tX54\n",
      "\tX57\n",
      "\tX59\n",
      "\tX60\n",
      "\tX61\n",
      "\tX63\n",
      "\tX64\n"
     ]
    }
   ],
   "source": [
    "print(\"Attributes with values missing for at least some examples\\t:\\n\\t\" + \"\\n\\t\".join(attrs_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like you will have to deal with missing data at some point.\n",
    "\n",
    "We won't do this just now; you will need to address the issue yourself later.\n",
    "\n",
    "But you will hopefully see that our target (`Bankrupt`) is not missing in any example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( not target_attr in set(attrs_missing) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label/target is included in this dataset\n",
    "- It is the attribute `Bankrupt`\n",
    "- Let's separate it from the feature attributes so we don't accidentally train the model with a feature that **is** the target !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (4818, 65)\n"
     ]
    }
   ],
   "source": [
    "data, labels = data.drop(columns=[target_attr]), data[target_attr]\n",
    "print(\"Data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will shuffle the examples before doing anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape:  (4818,)\n",
      "Label values:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data first\n",
    "data, labels = sklearn.utils.shuffle(data, labels, random_state=42)\n",
    "\n",
    "print(\"Labels shape: \", labels.shape)\n",
    "print(\"Label values: \", np.unique(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate your submission on a test dataset that we provide\n",
    "- It has no labels, so **you** can't use it to evaluate your model, but **we** have the labels\n",
    "- We will call this evaluation dataset the \"holdout\" data\n",
    "\n",
    "Let's get it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (1092, 65)\n"
     ]
    }
   ],
   "source": [
    "holdout_data = pd.read_csv( os.path.join(DATA_DIR, \"holdout\", '5th_yr.csv') )\n",
    "\n",
    "print(\"Data shape: \", holdout_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:150%;background-color:black;\" color='white' >Question</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a test set \n",
    "\n",
    "To train and evaluate a model, we need to split the original dataset into\n",
    "a training subset (in-sample) and a test subset (out of sample).\n",
    "\n",
    "Although **we** are the only ones with the holdout dataset, you probably want\n",
    "to perform out of sample evaluation of your model.\n",
    "\n",
    "**Question**\n",
    "\n",
    "<font style=\"font-size:250%;background-color:green;\" color='white' >Question</font>\n",
    "\n",
    "Split the data \n",
    "- 90% will be used for training the model\n",
    "- 10% will be used as validation (out of sample) examples\n",
    "- Use `train_test_split()` from `sklearn` to perform this split\n",
    "    -  Set the `random_state` parameter of `train_test_split()` to be 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "# Create variables X_train, X_test, y_train, y_test\n",
    "#   X_train: training examples\n",
    "#   y_train: labels of the training examples\n",
    "#   X_test:  test examples\n",
    "#   y_test:  labels of test examples\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4336, 65)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(482, 65)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "You may want to analyze potential relationships\n",
    "- Between features and the target\n",
    "- Between pairs/groups of features\n",
    "\n",
    "We'll make some suggestions but, ultimately it is up to you.\n",
    "\n",
    "**Warning**\n",
    "\n",
    "We will perform *our* exploration using the raw data\n",
    "- Thus, there may be features with missing values\n",
    "- This may affect your analysis\n",
    "- For example: how is the correlation of 2 features computed when their are missing values ?\n",
    "- For the purpose of answering the questions: leave the missing values in place\n",
    "- For *your* model: feel free to deal with missing features before doing Exploratory Data Analysis\n",
    "\n",
    "**Remember**\n",
    "\n",
    "- Base your analysis on `X_train`, don't peek at your out of sample data !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features correlated with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "List the 5 features whose correlations with the target are largest (most positive).\n",
    "\n",
    "\n",
    "Set variable `corr_features`\n",
    "- To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "- Most highly correlated with `Bankrupt`\n",
    "- *In *descending order*\n",
    "\n",
    "**Hint**\n",
    "- Look up the Pandas `corr` method\n",
    "- Look up the Pandas `sort_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "# Put target back with data to facilitate correlation\n",
    "df = X_train.copy()\n",
    "df[ target_attr ] = y_train\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "target_corr = corr_matrix['Bankrupt'].sort_values(ascending = False)\n",
    "corr_features = target_corr.index[ 1:6 ].tolist()\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features most correlated with target:  ['X2', 'X51', 'X32', 'X9', 'X36']\n"
     ]
    }
   ],
   "source": [
    "print(\"Features most correlated with target: \", corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutually correlated features\n",
    "\n",
    "When you have a lot of features, you might discover that some of them convey little information\n",
    "- Pairs of highly correlated features\n",
    "- A small number of features that adequately represent the whole\n",
    "    - In the Unsupervised Learning lecture, we will learn about PCA, a way to discover a small set of synthetic features that capture the whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "- List the 5 features whose correlations with the `X1` are largest (most positive).\n",
    "    - Set variable `X1_corr_p`\n",
    "    - To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "    - Most highly correlated\n",
    "    - *In *descending order*\n",
    "    \n",
    "- List the 5 features whose correlations with the `X1` are *most negative*.\n",
    "    - Set variable `X1_corr_n`\n",
    "    - To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "    - Most highly *negatively* correlated\n",
    "    - *In *ascending order* (most negative first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "# Put target back with data to facilitate correlation\n",
    "df = X_train.copy()\n",
    "df[ target_attr ] = y_train\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "X1_corr = corr_matrix['X1'].sort_values(ascending = False)\n",
    "\n",
    "X1_corr_p = X1_corr.index[ 1: 6].tolist()\n",
    "X1_corr_n = X1_corr.index[ -1: - 6 : -1 ].tolist()\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features most positively correlated with X1 ['X7', 'X14', 'X11', 'X22', 'X35']\n",
      "Features most negatively correlated with X1 ['X36', 'X38', 'X10', 'X25', 'X53']\n"
     ]
    }
   ],
   "source": [
    "print(\"Features most positively correlated with X1\", X1_corr_p)\n",
    "print(\"Features most negatively correlated with X1\", X1_corr_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to consider (we saw something similar in the lecture topic on Influential Points)\n",
    "- Outliers (feature values that are at the extremes of the distribution) can affect correlation\n",
    "\n",
    "To illustrate:\n",
    "- We will show the distribution of one feature, conditional on the value of the associated target value\n",
    "- Here we overlay two distributions\n",
    "    - The distribution of the feature value, conditioned on examples having target 0 (colored green)\n",
    "    - The distribution of the feature value, conditioned on examples having target 1 (colored red)\n",
    "    - When the two distributions overlap: the color will be a blend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_attr(df, attr, trunc=.01):\n",
    "    X = df[attr]\n",
    "    \n",
    "    # Remove outliers, to improve clarity\n",
    "    mask = (X > X.quantile(trunc)) & (X < X.quantile(1-trunc))\n",
    "    X_trunc, y_trunc = X[ mask  ], y_train[ mask ]\n",
    "\n",
    "    bins = np.linspace( int(X_trunc.min()), int(X_trunc.max() +1), 30)\n",
    "    \n",
    "    fig, ax = plt.subplots( figsize=(8,4))\n",
    "    color = 'tab:green'\n",
    "    ax.set_xlabel(attr)\n",
    "    ax.set_ylabel('count', color=color)\n",
    "    data = X_trunc[ y_trunc == 0 ]\n",
    "    ax.hist( data, bins, alpha=0.5, label='0', color=color, weights=np.ones(len(data)) / len(data))\n",
    "    ax.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax2.set_xlabel(attr)\n",
    "    ax2.set_ylabel('count', color=color)\n",
    "    data =  X_trunc[ y_trunc == 1 ]\n",
    "    ax2.hist( data, bins, alpha=0.5, label='1', color=color, weights=np.ones(len(data)) / len(data))\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attr(X_train, \"X51\", trunc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph is not very informative\n",
    "- The distributions overlap for the bins chosen\n",
    "- But there seem to be many bins with very few values (i.e. X51 > 2)\n",
    "\n",
    "But let's perform the same plot while *eliminating* extreme values of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAEICAYAAACNqfTZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dfZgdV33Y8e9BQo5ZAhjbKWA7QamVzsgdlxdZpElKCC5g0wcrCXYsOyRD6kZJQE4obVJIqCECEpGSGtcvCaqBjknBGLXkUYuC4+AkTXmLBBgP8rkhQuixhaEYS4FYDpi1T/+4s+Lqald7d7Wzs3v1/TzPPp6Xc/b+jkbX89M5Z86ElBKSJEldeVzXAUiSpJObyYgkSeqUyYgkSeqUyYgkSeqUyYgkSeqUyYgkSerUyq4DkCRJ7YhZfhFwHbACuDnvxa1D558PvAM4H9iY9+L25vizgD8AngQ8Crw178UPtBXn2CQjj3vc49Kpp57adRiSJC2ahx9+OKWUph3liFm+ArgReBFwANgVs3xH3ov3DBS7F3gl8O+HfzXw83kv/m3M8mcAn45Zfnvei3+34I1gjJKRU089lcOHD3cdhiRJiyaE8A/HOb0e2Jv34j6AmOW3AhuAI8lI3ov7m3OPDVbMe/ELA9v3xyz/GnAm0Eoy4pwRSZLG01nAfQP7B5pjcxKzfD2wCvjiAsV1jLHpGZEk6SS0MoSwe2B/W0ppW7Mdpik/p3fAxCx/OvBeoMx78bHZys+XyYgkScvXZEpp3QznDgDnDOyfDdw/6i+OWf4k4MPAG/Je/OT8Q5ydyYgkSeNpF7AmZvlq4MvARuDKUSrGLF8FfAi4Je/FD7YXYl8Yl7f2TkxMJCewSpJOJiGEh1NKEzOdj1n+UvqP7q4A3p334ltjlm8Bdue9uCNm+QX0k47TgG8BX8178byY5a8A3gPsGfh1r8x78a5W2mEyIknS8jRbMrJc+DSNJEnqlMmIJEnqlMmIJEnqlE/TjIGb7rppXvVe9axXLXAkx/fA9TfMq96ZV29e4EgkSUuJPSOSJKlT9owsIfPt4ZAkaTmzZ0SSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHWq1eXgi6q4CLgOWAHcXJf11qHzzwfeAZwPbKzLentz/FnAHwBPAh4F3lqX9QfajFWSJHWjtZ6RoipWADcCFwNrgSuKqlg7VOxe4JXA+4aOPwz8fF3W5wEXAe8oquIpbcUqSZK602bPyHpgb13W+wCKqrgV2ADcM1WgLuv9zbnHBivWZf2Fge37i6r4GnAm8HctxitJkjrQ5pyRs4D7BvYPNMfmpKiK9cAq4IsLFJckSVpC2uwZCdMcS3P5BUVVPB14L1DWZf3Y8PkQwiZgE8CqVavmE+NJ7aa7bppXvVc961ULHIkk6WTWZs/IAeCcgf2zgftHrVxUxZOADwNvqMv6k9OVSSltSymtSymtW7my1bm4kiSpJW3ewXcBa4qqWA18GdgIXDlKxaIqVgEfAm6py/qD7YUoSZK61lrPSF3Wk8Bm4HYgArfVZb2nqIotRVVcAlBUxQVFVRwALgPeWVTFnqb6zwDPB15ZVMVdzc+z2opVkiR1J6Q0p2kcS9bExEQ6fPhw12GckPnO4Vhs850z8sD1N8yr3plXb55XPUkadyGEh1NKE13HcaKcaKElzyRGksaby8FLkqRO2TMiSdKYill+1GtZ8l7cOnT+qNey5L24feBcCbyh2X1L3otVW3HaMyJJ0hiKWX7Ma1lilo/0WpaY5U8F3gg8j/6K6m+MWX5aW7GajEiSNJ7WA3vzXtyX9+IjwNRrWY7Ie3F/3ot3A8MLi74EuCPvxYN5Lx4C7qD/rrhWmIxIkjSeTuS1LAvySpdROWdEkqTla2UIYffA/raU0rZm+0Rey3LCr3SZC5MRSZKWr8mU0roZzp3Ia1kOAC8YqvsXcw1uVCYjkiSNp13Ampjlc34tC/3V039nYNLqi4HXL3yIfc4ZkSRpDOW9eMxrWfJe3BOzfEvM8ksAYpZfELP8yGtZYpbvaeoeBN5MP6HZBWxpjrXCnhFJksZU3os7gZ1Dx64Z2N5FfwhmurrvBt7daoANe0YkSVKnTEYkSVKnTEYkSVKnTEYkSVKnnMDagpvuuqnrECRJWjbsGZEkSZ0yGZEkSZ0yGZEkSZ0yGZEkSZ0yGZEkSZ0yGZEkSZ0yGZEkSZ1qdZ2RoiouAq4DVgA312W9dej884F3AOcDG+uy3j5wrgTe0Oy+pS7rqs1YNbr5rqNy2QLHIUkaD631jBRVsQK4EbgYWAtcUVTF2qFi9wKvBN43VPepwBuB5wHrgTcWVXFaW7FKkqTutDlMsx7YW5f1vrqsHwFuBTYMFqjLen9d1ncDjw3VfQlwR13WB+uyPgTcAVzUYqySJKkjbSYjZwH3DewfaI61XVeSJC0jbc4ZCdMcSwtZN4SwCdgEsGrVqtEjkyRJS0abPSMHgHMG9s8G7l/IuimlbSmldSmldStX+s4/SZKWozbv4LuANUVVrAa+DGwErhyx7u3A7wxMWn0x8PqFD1GSJHWttZ6Ruqwngc30E4sI3FaX9Z6iKrYUVXEJQFEVFxRVcYD+U5/vLKpiT1P3IPBm+gnNLmBLc0ySJI2ZkNKo0ziWtomJiXT48OGuwwDmvw7HuLvsr4YfmmrXmVdvXtTPk6TFFkJ4OKU00XUcJ8oVWCVJUqdMRiRJUqdMRiRJUqdMRiRJUqdMRiRJUqdMRiRJUqdctlSSpDEVs/wi4DpgBXBz3otbh86fAtwCPBd4ELg878X9McsfD9wMPId+rnBL3ou/21ac9oxIkjSGYpavAG4ELgbWAlfELF87VOwq4FDei+cC1wJva45fBpyS92JBP1H5pZjlz2wrVpMRSZLG03pgb96L+/JefAS4FdgwVGYDUDXb24ELY5YH+i+nnYhZvhI4FXgE+GZbgZqMSJI0ns4C7hvYP9Acm7ZM3ouTwDeA0+knJoeBrwD3Am/Pe7G117KYjEiStHytDCHsHvjZNHAuTFN++B0wM5VZDzwKPANYDfy7mOU/uCART8MJrJIkLV+TKaV1M5w7AJwzsH82cP8MZQ40QzJPBg4CVwIfyXvxO8DXYpZ/DFgH7FvI4KeYjEgL5IHrb5hXPV/oJ6klu4A1MctXA18GNtJPMgbtAErgE8ClwJ15L6aY5fcCL4xZ/kfAE4AfBt7RVqAO00iSNIaaOSCbgduBCNyW9+KemOVbYpZf0hR7F3B6zPK9wGuB1zXHbwSeCHyeflLznrwX724rVntGJEkaU3kv7gR2Dh27ZmD7W/Qf4x2u99B0x9tiz4gkSeqUyYgkSeqUyYgkSeqUyYgkSeqUyYgkSeqUT9NobLnuhyQtDyYjWjS7vrprXvUueNoFCxyJJGkpcZhGkiR1qtWekaIqLgKuA1YAN9dlvXXo/CnALcBzgQeBy+uy3l9UxeOBm4HnNDHeUpf177YZqyRJ6kZrPSNFVaygv5zsxcBa4IqiKtYOFbsKOFSX9bnAtcDbmuOXAafUZV3QT1R+qaiKZ7YVqyRJ6k6bwzTrgb11We+ry/oR4FZgw1CZDUDVbG8HLiyqItB/ffFEURUrgVOBR4BvthirJEnqSJvJyFnAfQP7B5pj05apy3oS+AZwOv3E5DDwFeBe4O11WR8c/oAQwqYQwu4Qwu7JycmFb4EkSWpdm3NGwjTH0ohl1gOPAs8ATgP+qqiKP6vLet9RBVPaBmwDmJiYGP7daskzP/iprkOQJI2RNntGDgDnDOyfDdw/U5lmSObJwEHgSuAjdVl/py7rrwEfA9a1GKskSepIm8nILmBNURWri6pYBWwEdgyV2QGUzfalwJ11WSf6QzMvLKoiFFUxAfww0GsxVkmS1JHWkpFmDshm4HYgArfVZb2nqIotRVVc0hR7F3B6URV7gdcCr2uO3wg8Efg8/aTmPXVZ391WrJIkqTutrjNSl/VOYOfQsWsGtr9F/zHe4XoPTXdckiSNn5GSkaIqPlqX9YWzHZPa4DLykrT0xSz/aN6LF852bDrHTUaKqvge4AnAGUVVnMZ3n355Ev0nXSRJ0kksZvmRXCFm+bxyhdl6Rn4JeE3zyz498AHfpD+vQ0vAfB+13X/Z8xY4EknSSeiEc4XjJiN1WV8HXFdUxdV1WV9/AoFKkqQxlPfidcB1McuvzntxXrnCSHNG6rK+vqiKHwGeOVinLutb5vOhkiRpvOS9eH3M8mNyhbwXZ80VRp3A+l7gHwN30V8ZFforpZqMSJIkYpbPO1cY9dHedcDaZkEySZKkYeuAtXkvzjlXGHXRs88DT5vrL5ckSSeNeecKo/aMnAHcU1TFXwPfnjpYl/UlM1eRJEknkTOAe2KWH5Ur5L04a64wajLypvnFJUmSThJvmm/FUZ+m+cv5foBGN9/1QiRJmk7M8ouA64AVwM15L24dOn8K/QmmzwUeBC7Pe3F/c+584J30Fy97DLgg78VvzfRZeS/OO1cY9Wmav6c/IxZgFfB44HBd1k+a7wdLkqT2xCxfQX/RsRcBB4BdMct35L14z0Cxq4BDeS+eG7N8I/A24PKY5SuBPwJ+Lu/Fz8UsPx34ziyfN22ukPfirLnCqD0j3zu4X1TFTwLrR6krSZI6sR7Ym/fiPoCY5bcCG4DBZGQD3x1e2Q7cELM8AC8G7s578XMAeS8+ONuH5b14VK4Qs3zkXGHUp2mOUpf1HwMvnE9dSZK0YFaGEHYP/GwaOHcWcN/A/oHmGNOVyXtxEvgGcDrwQ0CKWX57zPLPxCz/jbkGlvfiyLnCqMM0Pz2w+zj6zxK75ogkSd2aTCmtm+FcmObY8L17pjIrgR8DLgAeBj4as/zTeS9+dKZAYpbPO1cY9Wmalw1sTwL76XftSJKkpekAcM7A/tnA/TOUOdDME3kycLA5/pd5L34dIGb5TuA5wIzJCCeQK4w6Z+QXRiknSZKWjF3Ampjlq4EvAxuBK4fK7ABK4BPApcCdeS+mmOW3A78Rs/wJwCPAjwPXHu/D8l6cd64w6jDN2cD1wI/S73L5v8Cv1WV9YL4frO75KPHS8MD1Nyzq55159eZF/TxJ3ch7cTJm+WbgdvqP9r4778U9Mcu3ALvzXtwBvAt4b8zyvfR7RDY2dQ/FLP/P9BOaBOzMe/HDx/u8mOXT5gp5L86aK4w6TPMe4H3AZc3+K5pjLxqxviRJWmR5L+4Edg4du2Zg+1t8994+XPeP6D/eO6p55wqjJiNn1mX9noH9/1ZUxWvmEKAkSRpvZ+a9eFSuELN8pFxh1GTk60VVvAJ4f7N/Bf2V2iRJkgC+HrN8XrnCqOuM/GvgZ4CvAl+hP8nFSa2SJGnKvHOFUXtG3gyUdVkfAiiq4qnA25sPnlFRFUetiV+X9dah88esiV+X9f7m3DFr4tdlPeOa+JIkqVNvBsq8Fw8BxCwfKVeA0XtGzp9KRADqsj4IPPt4FYqqmFoT/2JgLXBFURVrh4pdBRyqy/pc+o8Mva2pO7Um/i/XZX0e8AJmWRNfkiR16vypRAQg78VZc4UpoyYjjyuq4rSpnaZnZLZelfXA3rqs99Vl/QgwtSb+oA1A1WxvBy4squLImvh1WX8OoC7rB+uyfnTEWCVJ0uJ7XMzyI7lC0zMy0gjMqMM0vw98vKiK7fSfHf4Z4K2z1JluTfznzVSmLuvJoiqOWhO/qIrbgTOBW+uy/r0RY5UkSYvv94GPxyyfS64AjNgzUpf1LcDLgf8HPAD8dF3W752l2kKsif+zzX9/qqiKC4/5gBA2Tb0caHJycpZwJElSW/JePCZXyHtxtlwBGL1nhLqs7+Ho1w7PZk5r4jfzRI5aE78u668DFFUx7Zr4KaVtwDaAiYkJX9wnSVKH8l6ca64AjD5nZD52AWuKqlhdVMUq+kvM7hgqM7UmPjRr4tdlnegvXXt+URVPaJKUH2cejZMkSUtfa8lIXdaTwNSa+BG4rS7rPUVVbCmq4pKm2LuA04uq2Au8FnhdU/cQMLUm/l3AZ+qyPu6a+JIkaXkaeZhmPuqyPmZN/LqsrxnYnnFN/Lqs57omviRJWobaHKaRJEmaVas9I1KXdn1117zqvXSB45AkHZ89I5IkqVMmI5IkqVMmI5IkqVPOGTmOm+66qesQJEkae/aMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTrnomSRJYypm+UXAdcAK4Oa8F7cOnT8FuAV4LvAgcHnei/sHzn8/cA/wprwX395WnPaMSJI0hmKWrwBuBC4G1gJXxCxfO1TsKuBQ3ovnAtcCbxs6fy3wJ23Has+INOSB62/oOgRJWgjrgb15L+4DiFl+K7CBfk/HlA3Am5rt7cANMctD3ospZvlPAvuAw20Has+IJEnj6SzgvoH9A82xacvkvTgJfAM4PWb5BPAfgN9ehDhNRiRJWsZWhhB2D/xsGjgXpimfhvZnKvPbwLV5Lz60UIEej8M0kiQtX5MppXUznDsAnDOwfzZw/wxlDsQsXwk8GTgIPA+4NGb57wFPAR6LWf6tvBdbGcc2GZEkaTztAtbELF8NfBnYCFw5VGYHUAKfAC4F7sx7MQH/YqpAzPI3AQ+1lYiAwzSSJI2lZg7IZuB2IAK35b24J2b5lpjllzTF3kV/jshe4LXA67qINaQ0PHy0PE1MTKTDhxd2wu9Nd920oL9vNs/84KcW9fM0vQuedkHXIbTqzKs3dx2CpAUSQng4pTTRdRwnqtVhmqIqjlpspS7rrUPnj1lspS7r/QPnjyy2Upd1a4utzMTkQJKk9rWWjBRVMbXYyovoT5DZVVTFjrqsB59vvgo4VJf1uUVVbKS/2MrlA+cXZbEVadCur+6aV71x71GRpLa0OWdkPbC3Lut9dVk/AkwttjJoA1A129uBC4uqCABFVUwttrKnxRglSVLH2kxG5rTYSl3WRxZbKapiURdbkSRJ3WkzGTnhxVbqsj7uYishhE1TC71MTk7OM0xJktSlNpORuSy2QlEVw4ut/F5RFfuB1wC/WVTFMY8ApJS2pZTWpZTWrVzpkimSJC1Hbd7BdwFriqqY02IrdVkftdhKURVvAh6qy9q3l0mSNIZa6xlp5oActdhKXdZ7iqrYUlTFUYutFFXR6WIrkiSpOy56dhw7f6tc0N+n8bZcHu110TNpfIzLomcuBy9JkjplMiJJkjplMiJJkjplMiJJkjplMiJJkjplMiJJkjrlsqXSSeaB6+e3fqCPBEtqiz0jkiSpUyYjkiSpUyYjkiSpUyYjkiSpUyYjkiSpUz5NIy2QXV/dNa96y+UFe5LUFpMRSa3yUWJJs3GYRpIkdcpkRJIkdcpkRJIkdcpkRJIkdcoJrJIkjamY5RcB1wErgJvzXtw6dP4U4BbgucCDwOV5L+6PWf4iYCuwCngE+PW8F+9sK057RiRJGkMxy1cANwIXA2uBK2KWrx0qdhVwKO/Fc4Frgbc1x78OvCzvxQIogfe2GavJiCRJ42k9sDfvxX15Lz4C3ApsGCqzAaia7e3AhTHLQ96Ln8178f7m+B7ge5pelFY4TCNJJ8B1VLSEnQXcN7B/AHjeTGXyXpyMWf4N4HT6PSNTXg58Nu/Fb7cVaKvJSFEVR41V1WW9dej8MWNVdVnvL6rimLGquqxbG6uSuuTKrZJOwMoQwu6B/W0ppW3NdpimfBraP26ZmOXn0R+6efEJRTmL1oZpiqo4ZqyqqIppx6rqsp52rKou60UZq5IkaZmaTCmtG/jZNnDuAHDOwP7ZwP1HV/9umZjlK4EnAweb/bOBDwE/n/fiF9tqALQ7Z2Q9sLcu6311WY88VlVURajL+rN1WR81VtX0okiSpNHsAtbELF8ds3wVsBHYMVRmB/1/9ANcCtyZ92KKWf4U4MPA6/Ne/FjbgbaZjEw3VnXWTGXqsp4EpsaqBr0c+Gxd1q2NVUmSNG7yXpwENgO3AxG4Le/FPTHLt8Qsv6Qp9i7g9Jjle4HXAq9rjm8GzgX+Y8zyu5qf72sr1jbnjJzwWFVRFccdqwohbAI2AaxatWp+UUqSNKbyXtwJ7Bw6ds3A9reAy6ap9xbgLa0H2GizZ2ROY1VFVRw1VlVUxZGxqrqspx2rSiltmxonW7nSB4MkSVqO2ryD7wLWFFWxGvgy/bGqK4fKTI1VfYJmrKou61RUxZGxqrqsWx+rkjS7+T7CKkmzaa1npJkDctRYVV3We4qq2FJUxVFjVUVVzDhWVVTFXc1Pa2NVkiSpOyGl4Wkcy9PExEQ6fPjwgv7Onb9Vzl5I6si4rzOyXBYFc9EzdSmE8HBKaaLrOE6UEy2kZcrF0iSNC99NI0mSOmUyIkmSOmUyIkmSOmUyIkmSOuUEVknqgE/hSN9lz4gkSeqUyYgkSeqUyYgkSeqUyYgkSeqUyYgkSeqUyYgkSeqUj/ZKGivj/sjsfNs3X8vlz0XLm8mIdJLxBXuSlhqHaSRJUqdMRiRJUqdMRiRJUqecMyJpJM41kdQWe0YkSVKn7BmR1Kp596gs8iOsmp6PEmsx2DMiSZI6ZTIiSZI65TCNpCXJCbPSyaPVZKSoiouA64AVwM11WW8dOn8KcAvwXOBB4PK6rPc3514PXAU8CvxqXda3txmrJEnjJmb5UffhvBe3Dp0/5j6c9+L+5txR9+G8F1u7D7eWjBRVsQK4EXgRcADYVVTFjrqs7xkodhVwqC7rc4uq2Ai8Dbi8qIq1wEbgPOAZwJ8VVfFDdVk/2la8ksbDfHtUXrrAcUhdi1l+zH04ZvmOvBePuQ/nvXhuzPIj9+GY5cfch2OW/1Dei63ch9vsGVkP7K3Leh9AURW3AhuAwT+EDcCbmu3twA1FVYTm+K11WX8b+FJRFXub3/eJFuOVdBK76a6b5lXvsnl+3nIZhppvnPNlUrig1gN7817cBxCzfKT7cMzyI/fhvBe/DXwpZnmr9+E2k5GzgPsG9g8Az5upTF3Wk0VVfAM4vTn+yaG6Z7UXqiTNz2LfrBf78xbbfJPCVz3rVQscyViY030478XJmOWd3IfbTEbCNMfSiGVGqUsIYROwaep8COEf5hTh7FYCkwv8O7swLu0A27JULf+2/M4tMA7t+K7l2Zb+dRg2a1tezatbCacFC31dTg0h7B7Y35ZS2tZst34fXihtJiMHgHMG9s8G7p+hzIGiKlYCTwYOjliX5g982/DxhRJC2J1SWtfW718s49IOsC1L1bi0ZVzaAbZlqVrktszpPhyzfM734YXS5joju4A1RVWsLqpiFf2JMDuGyuwAymb7UuDOuqxTc3xjURWnFFWxGlgD/HWLsUqSNG52AWtilq+OWT7yfTjvxSP34Zjlp8Qsb/0+3FoyUpf1JLAZuB2IwG11We8pqmJLURWXNMXeBZzeTFB9LfC6pu4e4Db6k2w+ArzaJ2kkSRpd3ovH3IfzXtwTs3xLzPKj7sPNBNUj9+G8F4+5D7f1JA1ASKm1IaBlL4SwaWDsbdkal3aAbVmqxqUt49IOsC1L1Ti1ZSGZjEiSpE75bhpJktSpkzIZCSFcFEL4mxDC3hDC66Y5f0oI4QPN+U+FEJ45cO71zfG/CSG8ZDHjns4IbXltCOGeEMLdIYSPhhB+YODcoyGEu5qf4UlNi26EtrwyhPDAQMz/ZuBcGUL42+anHK67mEZox7UDbfhCCOHvBs4ttWvy7hDC10IIn5/hfAgh/JemrXeHEJ4zcG4pXZPZ2vGzTfx3hxA+HkL4ZwPn9ocQ6uaa7J6u/mIaoS0vCCF8Y+Dv0TUD5477d3OxjdCWXx9ox+eb78dTm3NL5rqEEM4JIfx5CCGGEPaEEH5tmjLL4rvSmZTSSfVDf33+LwI/CKwCPgesHSrzKuAPm+2NwAea7bVN+VOA1c3vWbHE2/ITwBOa7V+Zakuz/1DX12OObXklcMM0dZ8K7Gv+e1qzfdpSbcdQ+auBdy/Fa9LE83zgOcDnZzj/UuBP6K9J8MPAp5baNRmxHT8yFR9w8VQ7mv39wBldX4s5tOUFwP+e5vic/m4uhbYMlX0ZcOdSvC7A04HnNNvfC3xhmv9/LYvvSlc/J2PPyHpgb0ppX0rpEWBqedxBG4Cq2d4OXBhCOLI8bkrp2ymlLwFTy+N2Zda2pJT+PKX0cLP7SfrPii9Fo1yXmbwEuCOldDCldAi4A7iopThnM9d2XAG8f1Eim4eU0v+hv+bATDYAt6S+TwJPCSE8naV1TWZtR0rp402csLS/J6Nck5mcyHesFXNsy5L9rqSUvpJS+kyz/ff0n1wZXq10WXxXunIyJiPTLY87/JfmSJmU0iQwuDzubHUX01zjuYp+Zj7le0IIu0MInwwh/GQbAc7BqG15edPFuT2EMLUgz1K6LiPH0gyZrQbuHDi8lK7JKGZq71K6JnM1/D1JwJ+GED4d+qs+Lwf/PITwuRDCn4QQzmuOLdtrEkJ4Av0b9P8YOLwkr0voD+s/G/jU0Klx/K4smDZXYF2qls3yuCMYOZ4QwiuAdcCPDxz+/pTS/SGEHwTuDCHUKaUvthDnKEZpy/8C3p9S+nYI4Zfp9169cMS6i2UusWwEtqeUBp/dX0rXZBTL5bsykhDCT9BPRn5s4PCPNtfk+4A7Qgi95l/0S9VngB9IKT0UQngp8Mf0F6xaltek8TLgYymlwV6UJXddQghPpJ8wvSal9M3h09NUWbbflYV2MvaMzGV5XEIInS2PO4KR4gkh/Evgt4BLUkrfnjqeUrq/+e8+4C/oZ/NdmbUtKaUHB+L/r8BzR627iOYSy0aGup2X2DUZxUztXUrXZCQhhPOBm4ENKaUHp44PXJOvAR+i26HZWaWUvplSeqjZ3gk8PoRwBsvwmgw43ndlSVyXEMLj6Sci/z2l9D+nKTI235VWdD1pZbF/6PcG7aPfPT41ieu8oTKv5ugJrLc12+dx9ATWfXQ7gXWUtjyb/qS1NUPHTwNOabbPAP6WDiezjdiWpw9s/xTwyWb7qcCXmjad1mw/dam2oyn3T+hPwAtL9ZoMxPVMZp4s+a84elLeXy+1azJiO76f/hywHxk6PgF878D2x/okfOYAAAKxSURBVIGLlvg1edrU3yv6N+h7m+sz0t/NpdSW5vzUPwYnlup1af58bwHecZwyy+a70sXPSTdMk1KaDCFMLY+7gv6TDHtCCFuA3SmlHfSXx31vCGEv/S/BxqbunhDC1PK4k8Cr09Fd7ItqxLb8J+CJwAf7c3C5N6V0CZAD7wwhPEa/h2xrSumeThrCyG351RDCJfT/7A/Sf7qGlNLBEMKb6b+HAWBLOro7d9GM2A7oT8a7NTX/N2osqWsCEEJ4P/2nM84IIRwA3gg8HiCl9IfATvpPCewFHgZ+oTm3ZK4JjNSOa+jPC7up+Z5Mpv7LzP4R8KHm2ErgfSmljyx6AwaM0JZLgV8JIUwC/wBsbP6eTft3s4MmHDFCW6D/D48/TSkdHqi61K7LjwI/B9QhhLuaY79JP8ldVt+VrrgCqyRJ6tTJOGdEkiQtISYjkiSpUyYjkiSpUyYjkiSpUyYjkiSpUyYjkmbUvI30SwNvSj2t2f+BMMMbhkMIm5s3k6ZmsS1JOi4f7ZV0XCGE3wDOTSltCiG8E9ifUvrdEMJDKaUnTlP+2cAh+ivIrkspfX1xI5a03JiMSDquZpnrTwPvBn4ReHZK6ZGZkpGBevsxGZE0gpNuBVZJc5NS+k4I4deBjwAvTv3Xz0PzhmH6K+JuTSn9cWdBSlrWTEYkjeJi4CvAPwXuaI4ttzcMS1qinMAq6bhCCM8CXkT/5V7/NoTwdFiWbxiWtESZjEiaUei/iewPgNeklO6l/+LFtzdP1ZzSlDmD/ovCOn2pn6Tly2RE0vH8Iv03PU8NzdwEZMD5wO4QwueAP2fgDcMhhF9t3sB6NnB3COHmDuKWtIz4NI0kSeqUPSOSJKlTJiOSJKlTJiOSJKlTJiOSJKlTJiOSJKlTJiOSJKlTJiOSJKlTJiOSJKlT/x83x1XV6pniewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attr(X_train, \"X51\", trunc=.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that\n",
    "- When the feature value is greater than 1.25\n",
    "- The associated example indicates the company will go Bankrupt (`Bankrupt` = 1)\n",
    "\n",
    "Just something to keep in mind in performing your own analysis and building your models\n",
    "- Is there value in creating a synthetic feature: `X51 > t` for some threshold `t` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "- Let `t = 1.1`\n",
    "- Set variable `cond_frac_pos` to the fraction of examples that go Bankrupt where `X51 > t`\n",
    "$$\n",
    "\\frac{ \\text{count(Bankrupt == 1 and X51 > t} )} { \\text{count(Bankrupt == 1)} }\n",
    "$$\n",
    "\n",
    "- Set variable `cond_frac_pneg` to the fraction of examples that *do not* go Bankrupt where `X51 > t`\n",
    "$$\n",
    "\\frac{ \\text{count(Bankrupt == 0 and X51 > t} )} { \\text{count(Bankrupt == 0)} }\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of training examples that go Bankrupt, with (X51 > 1.10) is 14.4%\n",
      "The fraction of training examples that DO NOT go Bankrupt, with (X51 > 1.10) is 1.6%\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "def cond_attr(df, attr, trunc=.01, thresh=1):\n",
    "    X = df[attr]\n",
    "    \n",
    "    # Remove outliers, to improve clarity\n",
    "    mask = (X > X.quantile(trunc)) & (X < X.quantile(1-trunc))\n",
    "    X_trunc, y_trunc = X[ mask  ], y_train[ mask ]\n",
    "    \n",
    "    # Condition on value of target and thresh\n",
    "    cp = X_trunc[ (y_trunc == 1) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 1].size\n",
    "    cn = X_trunc[ (y_trunc == 0) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 0].size\n",
    "      \n",
    "    return cp, cn\n",
    "\n",
    "attr = \"X51\"\n",
    "t = 1.1\n",
    "trunc=0\n",
    "cond_frac_pos, cond_frac_neg = cond_attr(X_train, attr, trunc=trunc, thresh=t)\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"The fraction of training examples that go Bankrupt, with ({attr:s} > {t:2.2f}) is {frac:3.1%}\".format(attr=attr, \n",
    "                                                                                        t=t,\n",
    "                                                                                        frac=cond_frac_pos)\n",
    "     )\n",
    "\n",
    "print(\"The fraction of training examples that DO NOT go Bankrupt, with ({attr:s} > {t:2.2f}) is {frac:3.1%}\".format(attr=attr, \n",
    "                                                                                        t=t,\n",
    "                                                                                        frac=cond_frac_neg)\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we can discover a large fraction of examples that go Bankrupt by examining \n",
    "one feature and threshold.\n",
    "\n",
    "But using this alone will result in some number of False Positives (non Bankrupt examples)\n",
    "- And although the percent is small, we will see that the non Bankrupt examples are more numerous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced data\n",
    "\n",
    "We have a binary classification problem.\n",
    "\n",
    "Do we have roughly the same number of examples associated with each of the two targets ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "How many training examples do we have that became Bankrupt ?\n",
    "- Set variable `num_bankrupt` to this value\n",
    "\n",
    "How many training examples do we have that *did not become* Bankrupt ?\n",
    "- Set variable `num_nonbankrupt` to this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = X_train.shape[0]\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "bankrupt = X_train[ y_train == 1 ] \n",
    "nonbankrupt = X_train[ y_train == 0 ]\n",
    "\n",
    "num_bankrupt    = bankrupt.shape[0]\n",
    "num_nonbankrupt = nonbankrupt.shape[0]\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 4336 total examples: 268 became bankrupt and 4068 did not become bankrupt\n"
     ]
    }
   ],
   "source": [
    "print(\"Of the {t:d} total examples: {b:d} became bankrupt and {nb:d} did not become bankrupt\".format(t=num_examples,\n",
    "                                                                                                    b=num_bankrupt,\n",
    "                                                                                                    nb=num_nonbankrupt)\n",
    "\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( num_bankrupt + num_nonbankrupt == num_examples )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is highly imbalanced: many more examples of one class than the other.\n",
    "\n",
    "Why might this be a problem ?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a naive model that ignores the features and always predicts the *most frequent* value of the target.\n",
    "\n",
    "Assuming the out of sample data has the same distribution as the training data:\n",
    "- We will have perfect conditional accuracy for the examples with target in the majority class\n",
    "- We will have zero conditional accuracy for the examples with target in the non-majority class\n",
    "- Because the number of examples in the majority class is so much larger:\n",
    "    - We might get good unconditional accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our lecture on Recall and Precision.\n",
    "\n",
    "These are metrics that will help us evaluate our model's ability to correctly predict Bankruptcy.\n",
    "\n",
    "We think that you will find that your model may have\n",
    "- High Accuracy\n",
    "- Low Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways for you to deal with imbalanced data\n",
    "- Class sensitive weights\n",
    "    - Many models in `sklearn` take an optional argument `class_weight`\n",
    "    - For each target class: you can assign a weight\n",
    "    - The Loss will be computed on a class-weighted basis\n",
    "    - You can choose weights that increase the influence of the non-majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is re-sampling the training set\n",
    "- Expand the number of training examples\n",
    "- By increasing the number of examples of the non-majority class\n",
    "    - Randomly sample examples in the non-majority class\n",
    "    - So you will have duplicates\n",
    "- This creates a more balanced dataset on which to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just some ideas for you to achieve a model with better\n",
    "conditional metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your model\n",
    "\n",
    "Time for you to continue the Recipe for Machine Learning on your own.\n",
    "\n",
    "Follow the steps and submit your *best* model.\n",
    "\n",
    "For your best model, using the test set you created, report\n",
    "- Accuracy \n",
    "- Recall\n",
    "- Precision\n",
    "\n",
    "We will evaluate your model using the holdout data.  Grades will be based on\n",
    "the following metrics meeting certain thresholds\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "\n",
    "We will evaluate the metric using 3 increasing values for the threshold\n",
    "- You will get points for each threshold that you surpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM (t=None) avg cross val score=0.9382\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kjp/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSVM Accuracy: 91.7%, Recall 0.0%, Precision 0.0%\n",
      "Model: Random Forest (t=None) avg cross val score=0.9412\n",
      "\n",
      "\tRandom Forest Accuracy: 93.2%, Recall 25.0%, Precision 76.9%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, classification_report\n",
    "\n",
    "impute_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# logistic_clf = linear_model.LogisticRegression(solver = 'liblinear', max_iter = 10000)\n",
    "svm_clf = SVC(gamma=\"auto\", C=.1)\n",
    "forest_clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "r = \"None\"\n",
    "\n",
    "for name, clf in { \"SVM\": svm_clf,\n",
    "                   \"Random Forest\": forest_clf\n",
    "                 }.items():\n",
    "    \n",
    "    pipe = Pipeline([(\"imputer\", impute_transformer), \n",
    "                      (\"model\", clf)\n",
    "                     ]\n",
    "                    )\n",
    "    \n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "    print(\"Model: {m:s} (t={r:s}) avg cross val score={s:3.4f}\\n\".format(m=name, r=r, s=scores.mean()) )\n",
    "\n",
    "    # Out of sample prediction\n",
    "    _= pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # recall_\n",
    "    recall_test = recall_score(y_test, y_pred, pos_label=1, average=\"binary\")\n",
    "    precision_test = precision_score(y_test,   y_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "\n",
    "    print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                                a=accuracy_test,\n",
    "                                                                                r=recall_test,\n",
    "                                                                                p=precision_test\n",
    "                                                                                )\n",
    "         )\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4336,), 15.17910447761194)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15.179104470330453"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,  y_train[ y_train == 0].shape[0]/y_train[ y_train == 1].shape[0]\n",
    "8.08955224/0.53294002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = sklearn.utils.class_weight.compute_class_weight(\"balanced\", np.unique(y_train), y_train)\n",
    "cwn = cw/cw.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models wih Dimensionality reduction\n",
    "\n",
    "- Reduce the number of features\n",
    "    -Try other models\n",
    "- Cost sensitive training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVM (t=1) avg cross val score=0.9382\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kjp/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSVM Accuracy: 91.7%, Recall 0.0%, Precision 0.0%\n",
      "Model: Logistic (t=1) avg cross val score=0.9350\n",
      "\n",
      "\tLogistic Accuracy: 91.5%, Recall 0.0%, Precision 0.0%\n",
      "Model: SVM (t=10) avg cross val score=0.8727\n",
      "\n",
      "\tSVM Accuracy: 85.7%, Recall 47.5%, Precision 28.4%\n",
      "Model: Logistic (t=10) avg cross val score=0.8761\n",
      "\n",
      "\tLogistic Accuracy: 85.3%, Recall 47.5%, Precision 27.5%\n",
      "Model: SVM (t=12) avg cross val score=0.8487\n",
      "\n",
      "\tSVM Accuracy: 82.6%, Recall 55.0%, Precision 25.0%\n",
      "Model: Logistic (t=12) avg cross val score=0.8450\n",
      "\n",
      "\tLogistic Accuracy: 83.4%, Recall 62.5%, Precision 27.8%\n",
      "Model: SVM (t=13) avg cross val score=0.8319\n",
      "\n",
      "\tSVM Accuracy: 81.3%, Recall 60.0%, Precision 24.5%\n",
      "Model: Logistic (t=13) avg cross val score=0.8275\n",
      "\n",
      "\tLogistic Accuracy: 81.1%, Recall 62.5%, Precision 24.8%\n",
      "Model: SVM (t=15) avg cross val score=0.7980\n",
      "\n",
      "\tSVM Accuracy: 78.4%, Recall 65.0%, Precision 22.4%\n",
      "Model: Logistic (t=15) avg cross val score=0.7892\n",
      "\n",
      "\tLogistic Accuracy: 78.2%, Recall 75.0%, Precision 24.0%\n",
      "Model: SVM (t=18) avg cross val score=0.7422\n",
      "\n",
      "\tSVM Accuracy: 72.2%, Recall 82.5%, Precision 20.6%\n",
      "Model: Logistic (t=18) avg cross val score=0.7309\n",
      "\n",
      "\tLogistic Accuracy: 71.8%, Recall 82.5%, Precision 20.4%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stand_transformer = StandardScaler()\n",
    "\n",
    "cwt = { 0:1, 1:20 }\n",
    "\n",
    "\n",
    "\n",
    "for r in [ 1, 10, 12, 13, 15, 18]:\n",
    "    cwt = { 0:1, 1:r }\n",
    "    \n",
    "    logistic_clf = linear_model.LogisticRegression(\n",
    "        class_weight = cwt,\n",
    "        solver = 'liblinear', max_iter = 10000)\n",
    "    svm_clf = SVC(class_weight = cwt,\n",
    "              gamma=\"auto\", C=.1)\n",
    "    \n",
    "    for name, clf in { \"SVM\": svm_clf,\n",
    "                       \"Logistic\": logistic_clf\n",
    "                     }.items():\n",
    "\n",
    "        pipe = Pipeline([(\"imputer\", impute_transformer), \n",
    "                         (\"Standardize\", stand_transformer),\n",
    "                         (\"PCA\", PCA(n_components = 20)),\n",
    "                         (\"model\", clf)\n",
    "                         ]\n",
    "                        )\n",
    "        scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "        print(\"Model: {m:s} (t={r:d}) avg cross val score={s:3.4f}\\n\".format(m=name, r=r, s=scores.mean()) )\n",
    "\n",
    "        # Out of sample prediction\n",
    "        _= pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "\n",
    "        accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # recall_\n",
    "        recall_test = recall_score(y_test, y_pred, pos_label=1, average=\"binary\")\n",
    "        precision_test = precision_score(y_test,   y_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "        \n",
    "        print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                                    a=accuracy_test,\n",
    "                                                                                    r=recall_test,\n",
    "                                                                                    p=precision_test\n",
    "                                                                                    )\n",
    "             )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[ y_test == 1 ].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission guidelines\n",
    "\n",
    "- You will implement the body of a subroutine `MyModel`\n",
    "    - That takes as argument a Pandas DataFrame \n",
    "        - Each row is an example on which to predict\n",
    "        - The features of the example are elements of the row\n",
    "    - Performs predictions on each example\n",
    "    - Returns an array or predictions with a one-to-one correspondence with the examples in the test set\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate your model against the holdout data\n",
    "- By reading the holdout examples `X_hold` (as above)\n",
    "- Calling `y_hold_pred = MyModel(X_hold)` to get the predictions\n",
    "- Comparing the predicted values `y_hold_pred` against the true labels `y_hold` which are known only to the instructors\n",
    "\n",
    "See the following cell as an illustration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_hold = pd.read_csv( os.path.join(DATA_DIR, \"holdout\", '5th_yr.csv') )\n",
    "\n",
    "# Predict using MyModel\n",
    "y_hold_pred = MyModel(X_hold)\n",
    "\n",
    "# Compute metrics\n",
    "# accuracy\n",
    "accuracy_hold = accuracy_score(y_hold, y_hold_pred)\n",
    "\n",
    "# recall_\n",
    "recall_hold = recall_score(y_hold, y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "# precision\n",
    "precision_hold = precision_score(y_hold,   y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "\n",
    "print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                            a=accuracy_hold,\n",
    "                                                                            r=recall_hold,\n",
    "                                                                            p=precision_hold\n",
    "                                                                            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember**\n",
    "\n",
    "The holdout data is in the same format as the one we used for training\n",
    "- Except that it has no attribute for the target\n",
    "- So you will need to perform all the transformations on the holdout data\n",
    "    - As you did on the training data\n",
    "    - Including turning the string representation of numbers into actual numeric data types\n",
    "\n",
    "All of this work *must* be performed within the body of the `MyModel` routine you will write\n",
    "\n",
    "We will grade you by comparing the predictions array you create to the answers known to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def MyModel(X):\n",
    "    # It should create an array of predictions; we initialize it to the empty array for convenience\n",
    "    predictions = []\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    # Relative weight of Bankrupt class to Non Bankrupt class\n",
    "    r = 13\n",
    "    \n",
    "    # Class weights\n",
    "    cwt = { 0:1, 1:r }\n",
    "    \n",
    "    logistic_clf = linear_model.LogisticRegression(\n",
    "        class_weight = cwt,\n",
    "        solver = 'liblinear', max_iter = 10000)\n",
    "    name = \"Logistic\"\n",
    "   \n",
    "    pipe = Pipeline([(\"imputer\", impute_transformer), \n",
    "                     (\"Standardize\", stand_transformer),\n",
    "                     (\"PCA\", PCA(n_components = 20)),\n",
    "                     (\"model\", logistic_clf)\n",
    "                     ]\n",
    "                   )\n",
    "   \n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "    print(\"Model: {m:s} (t={r:d}) avg cross val score={s:3.4f}\\n\".format(m=name, r=r, s=scores.mean()) )\n",
    "\n",
    "    # Fit the model\n",
    "    _= pipe.fit(X_train, y_train)\n",
    "                    \n",
    "    # Out of sample prediction \n",
    "    y_pred = pipe.predict(X)\n",
    "    \n",
    " \n",
    "    predictions = y_pred\n",
    "### END SOLUTION\n",
    "    \n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your work: predict and evaluate metrics on *your* test examples\n",
    "- Test whether your implementation of `MyModel` works\n",
    "- See the metrics  your model produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic (t=13) avg cross val score=0.8273\n",
      "\n",
      "\tLogistic Accuracy: 81.1%, Recall 62.5%, Precision 24.8%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = MyModel(X_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred, pos_label=1, average=\"binary\")\n",
    "precision_test = precision_score(y_test,   y_test_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                            a=accuracy_test,\n",
    "                                                                            r=recall_test,\n",
    "                                                                            p=precision_test\n",
    "                                                                            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(accuracy_test > 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( ( (recall_test  > 0.50) and (precision_test > 0.15) )\n",
    "       or\n",
    "        ( (recall_test  > 0.20) and (precision_test > 0.50) )\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra points\n",
    "assert(accuracy_test > .80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra points\n",
    "assert( ( (recall_test > .60) and (precision_test > 0.20) )\n",
    "       or\n",
    "        ( (recall_test  > 0.20) and (precision_test > 0.60) )\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is how we will evaluate your model on the holdout examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (1092, 65)\n"
     ]
    }
   ],
   "source": [
    "X_hold = pd.read_csv( os.path.join(DATA_DIR, \"holdout\", '5th_yr.csv') )\n",
    "\n",
    "print(\"Data shape: \", X_hold.shape)\n",
    "\n",
    "if False: # Only teacher can evaluate the rest: Needs true targets y_hold\n",
    "    y_hold_pred = MyModel(X_hold)\n",
    "    accuracy_hold = accuracy_score(y_hold, y_hold_pred)\n",
    "\n",
    "    # recall_\n",
    "    recall_hold = recall_score(y_hold, y_hold_pred, pos_label=1, average=\"binary\")\n",
    "    precision_hold = precision_score(y_hold,   y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "\n",
    "    print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                                a=accuracy_hold,\n",
    "                                                                                r=recall_hold,\n",
    "                                                                                p=precision_hold\n",
    "                                                                                )\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "- Most of the features are expressed as ratios: why is that a good idea ?\n",
    "- Even if you don't understand all of the financial concepts behind the names of the attributes\n",
    "    - You should be able to infer some relationships.  For example, here are some definitions of terms\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "X1   & = & \\frac{\\text{net profit} }{ \\text{total assets} } \\\\\n",
    "X9   & = & \\frac{\\text{sales}     }{ \\text{total assets} } \\\\\n",
    "X23  & = & \\frac{\\text{net profit} }{ \\text{sales} } \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "    - Therefore\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "X23  & = & \\frac{X1}{X9} & \\text{Algebra !}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "    - You might speculate that `net profit` is closely related to `gross profit`\n",
    "        - The difference between \"net\" and \"gross\" is usually some type of additions/subtractions\n",
    "    - Is this theory reflected in which features are most highly correlated with `X1` ?\n",
    "- If you perform dimensionality reduction using PCA (the topic of the Unsupervised Learning lecture)\n",
    "    - PCA is scale sensitive\n",
    "    - If you *don't* scale the features: how many do you need to capture 95% of the variance ?\n",
    "    - If you *do* scale the features: how many do you need to capture 95% of the variance ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
