{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem description\n",
    "\n",
    "You are to predict whether a company will go bankrupt in the following year, based on financial attributes of the company.\n",
    "\n",
    "Perhaps you are contemplating lending money to a company, and need to know whether the company\n",
    "is in near-term danger of not being able to repay.\n",
    "\n",
    "This task is divided in to two parts,\n",
    "- Part 1 is this Assignment 3\n",
    "- Part 2 will be your final project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Goal\n",
    "\n",
    "In the previous 2 assignments, we helped you to deal with data in order to make you focus on the model building and evaluation. But in this assignment, we want you to go through the first few but very important steps to solve a machine learning problem.\n",
    "\n",
    "You will need to prepare the data you need and get some ideas for your final projcet in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Demonstrate mastery on solving a classification problem and presenting\n",
    "the entire Recipe for Machine Learning process in a notebook.\n",
    "- We will make suggestions for ways to approach the problem\n",
    "    - But there will be little explicit direction for this task.\n",
    "- It is meant to be analogous to a pre-interview task that a potential employer might assign\n",
    "to verify your skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Load the bankruptcy_helper module\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Import bankruptcy_helper module\n",
    "import bankruptcy_helper\n",
    "%aimport bankruptcy_helper\n",
    "\n",
    "helper = bankruptcy_helper.Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# API for students\n",
    "\n",
    "We have defined some utility routines in a file `bankruptcy_helper.py`. There is a class named `Helper` in it.  \n",
    "\n",
    "This will simplify problem solving\n",
    "\n",
    "\n",
    "\n",
    "`helper = bankruptcy_helper.Helper()`\n",
    "\n",
    "- getData: get the train data and holdout data (without label)\n",
    "  > `train, holdout = getData()`\n",
    "\n",
    "- plot_attr: plot the distribution of one feature `attr` from DataFrame `X`, conditional on the value of the associated target value `y`\n",
    "  > `X`: DataFrame, features            \n",
    "  > `y`: DataFrame/ndarray, labels       \n",
    "  > `attr`: string, condition feature        \n",
    "  > `trunc`: scalar number, percentage of outliers you want to remove  \n",
    "  \n",
    "  >`helper.plot_attr(X, y, attr, trunc)`       \n",
    "\n",
    "- save_data: save the training and test data into a folder named \"my_data\"\n",
    "  > `helper.save_data(X_train, X_test, y_train, y_test)`\n",
    " \n",
    "- load_data: load the training and test data from a folder named \"my_data\"\n",
    "  > `X_train, X_test, y_train, y_test = helper.load_data()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Get the data\n",
    "\n",
    "The first step in our Recipe is Get the Data. \n",
    "\n",
    "There are two datasets in this assignment, which are stored in two different directories.\n",
    "- training data: include all features and labels, stored as `train/5th_yr.csv`\n",
    "- holdout data: include only features, **no label**, used to test your model performance. we will grade your work in final project based on your predicting labels. Stored as `holdout/5th_yr.csv`\n",
    "\n",
    "\n",
    "For the training data\n",
    "- Each example is a row of data corresponding to a single company\n",
    "- There are 64 attributes, described in the section below\n",
    "- The column `Bankrupt` is 1 if the company subsequently went bankrupt; 0 if it did not go bankrupt\n",
    "- The column `Id` is a Company Identifier\n",
    "\n",
    "The holdout data is similar with the training data. The olny difference is that it doesn't have attribute for the target, and you need to predict them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Get the data\n",
    "data, holdout = helper.getData()\n",
    "\n",
    "target_attr = \"Bankrupt\" # target attribute in training data, 1 for bankrupt and 0 for not bankrupt\n",
    "\n",
    "n_samples, n_attrs = data.shape\n",
    "print(\"Date shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Have a look at the data\n",
    "\n",
    "We will not go through all steps in the Recipe, nor in depth.\n",
    "\n",
    "But here's a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# holdout data\n",
    "holdout.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Pretty *unhelpful* !\n",
    "\n",
    "What are these mysteriously named features ?\n",
    "\n",
    "## Description of attributes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Attribute Information:\n",
    "\n",
    "Id Company Identifier \n",
    "X1 net profit / total assets\n",
    "X2 total liabilities / total assets\n",
    "X3 working capital / total assets\n",
    "X4 current assets / short-term liabilities\n",
    "X5 [(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365\n",
    "X6 retained earnings / total assets\n",
    "X7 EBIT / total assets\n",
    "X8 book value of equity / total liabilities\n",
    "X9 sales / total assets\n",
    "X10 equity / total assets\n",
    "X11 (gross profit + extraordinary items + financial expenses) / total assets\n",
    "X12 gross profit / short-term liabilities\n",
    "X13 (gross profit + depreciation) / sales\n",
    "X14 (gross profit + interest) / total assets\n",
    "X15 (total liabilities * 365) / (gross profit + depreciation)\n",
    "X16 (gross profit + depreciation) / total liabilities\n",
    "X17 total assets / total liabilities\n",
    "X18 gross profit / total assets\n",
    "X19 gross profit / sales\n",
    "X20 (inventory * 365) / sales\n",
    "X21 sales (n) / sales (n-1)\n",
    "X22 profit on operating activities / total assets\n",
    "X23 net profit / sales\n",
    "X24 gross profit (in 3 years) / total assets\n",
    "X25 (equity - share capital) / total assets\n",
    "X26 (net profit + depreciation) / total liabilities\n",
    "X27 profit on operating activities / financial expenses\n",
    "X28 working capital / fixed assets\n",
    "X29 logarithm of total assets\n",
    "X30 (total liabilities - cash) / sales\n",
    "X31 (gross profit + interest) / sales\n",
    "X32 (current liabilities * 365) / cost of products sold\n",
    "X33 operating expenses / short-term liabilities\n",
    "X34 operating expenses / total liabilities\n",
    "X35 profit on sales / total assets\n",
    "X36 total sales / total assets\n",
    "X37 (current assets - inventories) / long-term liabilities\n",
    "X38 constant capital / total assets\n",
    "X39 profit on sales / sales\n",
    "X40 (current assets - inventory - receivables) / short-term liabilities\n",
    "X41 total liabilities / ((profit on operating activities + depreciation) * (12/365))\n",
    "X42 profit on operating activities / sales\n",
    "X43 rotation receivables + inventory turnover in days\n",
    "X44 (receivables * 365) / sales\n",
    "X45 net profit / inventory\n",
    "X46 (current assets - inventory) / short-term liabilities\n",
    "X47 (inventory * 365) / cost of products sold\n",
    "X48 EBITDA (profit on operating activities - depreciation) / total assets\n",
    "X49 EBITDA (profit on operating activities - depreciation) / sales\n",
    "X50 current assets / total liabilities\n",
    "X51 short-term liabilities / total assets\n",
    "X52 (short-term liabilities * 365) / cost of products sold)\n",
    "X53 equity / fixed assets\n",
    "X54 constant capital / fixed assets\n",
    "X55 working capital\n",
    "X56 (sales - cost of products sold) / sales\n",
    "X57 (current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)\n",
    "X58 total costs /total sales\n",
    "X59 long-term liabilities / equity\n",
    "X60 sales / inventory\n",
    "X61 sales / receivables\n",
    "X62 (short-term liabilities *365) / sales\n",
    "X63 sales / short-term liabilities\n",
    "X64 sales / fixed assets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This may still be somewhat unhelpful for those of you not used to reading Financial Statements.\n",
    "\n",
    "But that's partially the point of the exercise\n",
    "- You can *still* perform Machine Learning *even if* you are not an expert in the problem domain\n",
    "    - That's what makes this a good interview exercise: you can demonstrate your thought process even if you don't know the exact meaning of the terms\n",
    "- Of course: becoming an expert in the domain *will improve* your ability to create better models\n",
    "    - Feature engineering is easier if you understand the features, their inter-relationships, and the relationship to the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's get a feel for the data\n",
    "- What is the type of each attribute ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "You may be puzzled:\n",
    "- Most attributes are `object` and *not* numeric (`float64`)\n",
    "- But looking at the data via `data.head()` certainly gives the impression that all attributes are numeric\n",
    "\n",
    "Welcome to the world of messy data !  The dataset has represented numbers as strings.\n",
    "- These little unexpected challenges are common in the real-word\n",
    "- Data is rarely perfect and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "So we will first have to convert all attributes to numeric\n",
    "\n",
    "**Question:**\n",
    "\n",
    "Create an all-numeric version of the data.  Assign it to the variable `data` (replacing the original)\n",
    "\n",
    "**Hint:**\n",
    "- Look up the Pandas method `to_numeric`\n",
    "    - We suggest you use the option `errors='coerce'`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "non_numeric_cols = data.select_dtypes(exclude=['float', 'int']).columns\n",
    "data[ non_numeric_cols] = data[ non_numeric_cols ].apply(pd.to_numeric, downcast='float', errors='coerce')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-numeric-data",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "assert 'object' not in data.dtypes\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's look at the data again, now that it is numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Hopefully you will see that all the attributes are now numeric.\n",
    "\n",
    "Surprise !\n",
    "\n",
    "Looks like there are some examples with undefined values for some features !\n",
    "- Why didn't we see this when the data was not encoded as numbers ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "List all the attributes of `data` that are missing from at least one example.\n",
    "- Set list `attrs_missing` to either a list or array of attributes that are missing from at least one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set variable\n",
    "#  attrs_missing: list or array, attributes that are missing from at least one example\n",
    "attrs_missing = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "num_examples = data.shape[0]\n",
    "num_examples_undefined = data.isnull().sum(axis=0)\n",
    "attrs_missing = num_examples_undefined[ num_examples_undefined > 0 ].index.tolist()\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Attributes with values missing for at least some examples\\t:\\n\\t\" + \"\\n\\t\".join(attrs_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-missing-data",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "tmp = np.sum(data.isna())\n",
    "attrs_missing_test = tmp[tmp>0].index.tolist()\n",
    "assert set(attrs_missing_test) == set(attrs_missing)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "So it looks like you will have to deal with missing data at some point.\n",
    "\n",
    "We won't do this just now; you will need to address the issue yourself later.\n",
    "\n",
    "But you will hopefully see that our target (`Bankrupt`) is not missing in any example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check if you target is missing any example\n",
    "assert( not target_attr in set(attrs_missing) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The label/target is included in this dataset\n",
    "- It is the attribute `Bankrupt`\n",
    "- Let's separate it from the feature attributes so we don't accidentally train the model with a feature that **is** the target !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data, labels = data.drop(columns=[target_attr]), data[target_attr]\n",
    "print(\"Data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We will shuffle the examples before doing anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle the data first\n",
    "data, labels = sklearn.utils.shuffle(data, labels, random_state=42)\n",
    "\n",
    "print(\"Labels shape: \", labels.shape)\n",
    "print(\"Label values: \", np.unique(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Create a test set \n",
    "\n",
    "To train and evaluate a model, we need to split the original dataset into\n",
    "a training subset (in-sample) and a test subset (out of sample).\n",
    "\n",
    "Although **we** are the only ones with the holdout dataset, you probably want\n",
    "to perform out of sample evaluation of your model.\n",
    "\n",
    "**Question:**\n",
    "\n",
    "Split the data \n",
    "- Set `X_train`, `X_test`, `y_train` and `y_test` to match the description in the comment\n",
    "- 90% will be used for training the model\n",
    "- 10% will be used as validation (out of sample) examples\n",
    "- Use `train_test_split()` from `sklearn` to perform this split\n",
    "    -  Set the `random_state` parameter of `train_test_split()` to be 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "# Create variables X_train, X_test, y_train, y_test\n",
    "#   X_train: training examples\n",
    "#   y_train: labels of the training examples\n",
    "#   X_test:  test examples\n",
    "#   y_test:  labels of test examples\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.10, random_state=42)\n",
    "### END SOLUTION\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-create-test",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(data, labels, test_size=0.10, random_state=42)\n",
    "assert np.allclose(X_train_, X_train, equal_nan=True)\n",
    "assert np.allclose(y_train_, y_train, equal_nan=True)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Save the data for your final project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Save X_train, X_test, y_train, y_test for final project\n",
    "helper.save_data(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "You may want to analyze potential relationships\n",
    "- Between features and the target\n",
    "- Between pairs/groups of features\n",
    "\n",
    "We'll make some suggestions but, ultimately it is up to you.\n",
    "\n",
    "**Warning**\n",
    "\n",
    "We will perform *our* exploration using the **raw** data\n",
    "- Thus, there may be features with missing values\n",
    "- This may affect your analysis\n",
    "- For example: how is the correlation of 2 features computed when their are missing values ?\n",
    "- For the purpose of answering the questions: *leave the missing values in place*\n",
    "- For *your* model: feel free to deal with missing features before doing Exploratory Data Analysis\n",
    "\n",
    "**Remember**\n",
    "\n",
    "- Base your analysis on `X_train`, don't peek at your out of sample data !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Features correlated with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "List the 5 features whose correlations with the target are largest (most positive).\n",
    "\n",
    "\n",
    "- Set variable `corr_features`\n",
    "    - To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "    - Most highly correlated with `Bankrupt`\n",
    "    - In *descending order*\n",
    "\n",
    "**Hint:**\n",
    "- Look up the Pandas `corr` method\n",
    "- Look up the Pandas `sort_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set variable\n",
    "#  corr_features: list or array, 5 features whose correlations with target are largest\n",
    "corr_features = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# Put target back with data to facilitate correlation\n",
    "df = X_train.copy()\n",
    "df[ target_attr ] = y_train\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "target_corr = corr_matrix['Bankrupt'].sort_values(ascending = False)\n",
    "corr_features = target_corr.index[ 1:6 ].tolist()\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Features most correlated with target: \", corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-target-correlation",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "df_test = X_train.copy()\n",
    "df_test[ target_attr ] = y_train\n",
    "corr_matrix_test = df_test.corr()\n",
    "\n",
    "target_corr_test = corr_matrix_test['Bankrupt'].sort_values(ascending = False)\n",
    "corr_features_test = target_corr_test.index[ 1:6 ].tolist()\n",
    "\n",
    "assert list(corr_features) == corr_features_test\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Mutually correlated features\n",
    "\n",
    "When you have a lot of features, you might discover that some of them convey little information\n",
    "- Pairs of highly correlated features\n",
    "- A small number of features that adequately represent the whole\n",
    "    - In the Unsupervised Learning lecture, we will learn about PCA, a way to discover a small set of synthetic features that capture the whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Questions:**\n",
    "\n",
    "- List the 5 features whose correlations with the `X1` are largest (most positive).\n",
    "    - Set variable `X1_corr_p`\n",
    "        - To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "        - Most highly correlated\n",
    "        - In *descending order*\n",
    "    \n",
    "- List the 5 features whose correlations with the `X1` are *most negative*.\n",
    "    - Set variable `X1_corr_n`\n",
    "        - To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "        - Most highly *negatively* correlated\n",
    "        - In *ascending order* (most negative first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set varaibels\n",
    "#  X1_corr_p: list or array, 5 features whose correlations with target are most positive\n",
    "#  X1_corr_n: list or array, 5 features whose correlations with target are most negative\n",
    "X1_corr_p = None\n",
    "X1_corr_n = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# Put target back with data to facilitate correlation\n",
    "df = X_train.copy()\n",
    "df[ target_attr ] = y_train\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "X1_corr = corr_matrix['X1'].sort_values(ascending = False)\n",
    "\n",
    "X1_corr_p = X1_corr.index[ 1: 6].tolist()\n",
    "X1_corr_n = X1_corr.index[ -1: - 6 : -1 ].tolist()\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Features most positively correlated with X1\", X1_corr_p)\n",
    "print(\"Features most negatively correlated with X1\", X1_corr_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-X1-correlation",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "X1_corr_test = corr_matrix_test['X1'].sort_values(ascending = False)\n",
    "\n",
    "X1_corr_p_test = X1_corr_test.index[ 1: 6].tolist()\n",
    "X1_corr_n_test = X1_corr_test.index[ -1: - 6 : -1 ].tolist()\n",
    "\n",
    "assert X1_corr_p_test == list(X1_corr_p)\n",
    "assert X1_corr_n_test == list(X1_corr_n)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "One thing to consider (we saw something similar in the lecture topic on Influential Points)\n",
    "- Outliers (feature values that are at the extremes of the distribution) can affect correlation\n",
    "\n",
    "To illustrate:\n",
    "- We will show the distribution of one feature, conditional on the value of the associated target value\n",
    "- Here we overlay two distributions\n",
    "    - The distribution of the feature value, conditioned on examples having target 0 (colored green)\n",
    "    - The distribution of the feature value, conditioned on examples having target 1 (colored red)\n",
    "    - When the two distributions overlap: the color will be a blend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "helper.plot_attr(X_train, y_train, \"X51\", trunc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The above graph is not very informative\n",
    "- The distributions overlap for the bins chosen\n",
    "- But there seem to be many bins with very few values (i.e. X51 > 2)\n",
    "\n",
    "But let's perform the same plot while *eliminating* extreme values of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "helper.plot_attr(X_train, y_train, \"X51\", trunc=.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We can now see that\n",
    "- When the feature value is greater than 1.25\n",
    "- The associated example indicates the company will go Bankrupt (`Bankrupt` = 1)\n",
    "\n",
    "Just something to keep in mind in performing your own analysis and building your models\n",
    "- Is there value in creating a synthetic feature: `X51 > t` for some threshold `t` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "- Let `t = 1.1`\n",
    "- Set variable `cond_frac_pos` to the fraction of examples that go Bankrupt where `X51 > t`\n",
    "$$\n",
    "\\frac{ \\text{count(Bankrupt == 1 and X51 > t} )} { \\text{count(Bankrupt == 1)} }\n",
    "$$\n",
    "\n",
    "- Set variable `cond_frac_neg` to the fraction of examples that *do not* go Bankrupt where `X51 > t`\n",
    "$$\n",
    "\\frac{ \\text{count(Bankrupt == 0 and X51 > t} )} { \\text{count(Bankrupt == 0)} }\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set variables\n",
    "#  t: scalar number, threshold\n",
    "#  cond_frac_pos: scalar number, fraction of examples that go bankrupt where X51 > t\n",
    "#  Cond_frac_neg: scalar number, fraction of examples that do not go bankrupt where X51 > t\n",
    "t = 1.1\n",
    "cond_frac_pos = None\n",
    "cond_frac_neg = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def cond_attr(df, attr, trunc=.01, thresh=1):\n",
    "    X = df[attr]\n",
    "    \n",
    "    # Remove outliers, to improve clarity\n",
    "    mask = (X > X.quantile(trunc)) & (X < X.quantile(1-trunc))\n",
    "    X_trunc, y_trunc = X[ mask  ], y_train[ mask ]\n",
    "    \n",
    "    # Condition on value of target and thresh\n",
    "    cp = X_trunc[ (y_trunc == 1) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 1].size\n",
    "    cn = X_trunc[ (y_trunc == 0) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 0].size\n",
    "      \n",
    "    return cp, cn\n",
    "\n",
    "attr = \"X51\"\n",
    "trunc = 0\n",
    "cond_frac_pos, cond_frac_neg = cond_attr(X_train, attr, trunc=trunc, thresh=t)\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"The fraction of training examples that go Bankrupt, with ({attr:s} > {t:2.2f}) is {frac:3.1%}\".format(attr=attr, \n",
    "                                                                                        t=t,\n",
    "                                                                                        frac=cond_frac_pos)\n",
    "     )\n",
    "\n",
    "print(\"The fraction of training examples that DO NOT go Bankrupt, with ({attr:s} > {t:2.2f}) is {frac:3.1%}\".format(attr=attr, \n",
    "                                                                                        t=t,\n",
    "                                                                                        frac=cond_frac_neg)\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-fraction",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "def cond_attr_test(df, attr, trunc=.01, thresh=1):\n",
    "    X = df[attr]\n",
    "    \n",
    "    # Remove outliers, to improve clarity\n",
    "    mask = (X > X.quantile(trunc)) & (X < X.quantile(1-trunc))\n",
    "    X_trunc, y_trunc = X[ mask  ], y_train[ mask ]\n",
    "    \n",
    "    # Condition on value of target and thresh\n",
    "    cp = X_trunc[ (y_trunc == 1) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 1].size\n",
    "    cn = X_trunc[ (y_trunc == 0) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 0].size\n",
    "      \n",
    "    return cp, cn\n",
    "\n",
    "cond_frac_pos_test, cond_frac_neg_test = cond_attr_test(X_train, 'X51', trunc=0, thresh=1.1)\n",
    "\n",
    "assert np.allclose(cond_frac_pos_test, cond_frac_pos)\n",
    "assert np.allclose(cond_frac_neg_test, cond_frac_neg)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "It seems that we can discover a large fraction of examples that go Bankrupt by examining \n",
    "one feature and threshold.\n",
    "\n",
    "But using this alone will result in some number of False Positives (non Bankrupt examples)\n",
    "- And although the percent is small, we will see that the non Bankrupt examples are more numerous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Imbalanced data\n",
    "\n",
    "We have a binary classification problem.\n",
    "\n",
    "Do we have roughly the same number of examples associated with each of the two targets ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "How many training examples do we have that became Bankrupt ?\n",
    "- Set variable `num_bankrupt` to this value\n",
    "\n",
    "How many training examples do we have that *did not become* Bankrupt ?\n",
    "- Set variable `num_nonbankrupt` to this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set variables\n",
    "#  num_examples: scalar number, number of examples in the training dataset\n",
    "#  num_bankrupt: scalar number, number of examples that became bankrupt\n",
    "#  num_nonbankrupt: scalar number, number of examples that did not become bankrupt\n",
    "num_examples = X_train.shape[0]\n",
    "num_bankrupt = None\n",
    "num_nonbankrupt = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "bankrupt = X_train[ y_train == 1 ] \n",
    "nonbankrupt = X_train[ y_train == 0 ]\n",
    "\n",
    "num_bankrupt    = bankrupt.shape[0]\n",
    "num_nonbankrupt = nonbankrupt.shape[0]\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Of the {t:d} total examples: {b:d} became bankrupt and {nb:d} did not become bankrupt\".format(t=num_examples,\n",
    "                                                                                                    b=num_bankrupt,\n",
    "                                                                                                    nb=num_nonbankrupt)\n",
    "\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-imbalance",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "bankrupt_test = X_train[ y_train == 1 ] \n",
    "nonbankrupt_test = X_train[ y_train == 0 ]\n",
    "\n",
    "num_bankrupt_test = bankrupt_test.shape[0]\n",
    "num_nonbankrupt_test = nonbankrupt_test.shape[0]\n",
    "\n",
    "assert num_bankrupt == num_bankrupt_test\n",
    "assert num_nonbankrupt == num_nonbankrupt_test\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This dataset is highly imbalanced: many more examples of one class than the other.\n",
    "\n",
    "Why might this be a problem ?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Consider a naive model that ignores the features and always predicts the *most frequent* value of the target.\n",
    "\n",
    "Assuming the out of sample data has the same distribution as the training data:\n",
    "- We will have perfect conditional accuracy for the examples with target in the majority class\n",
    "- We will have zero conditional accuracy for the examples with target in the non-majority class\n",
    "- Because the number of examples in the majority class is so much larger:\n",
    "    - We might get good unconditional accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Recall our lecture on Recall and Precision.\n",
    "\n",
    "These are metrics that will help us evaluate our model's ability to correctly predict Bankruptcy.\n",
    "\n",
    "We think that you will find that your model may have\n",
    "- High Accuracy\n",
    "- Low Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "There are several ways for you to deal with imbalanced data\n",
    "- Class sensitive weights\n",
    "    - Many models in `sklearn` take an optional argument `class_weight`\n",
    "    - For each target class: you can assign a weight\n",
    "    - The Loss will be computed on a class-weighted basis\n",
    "    - You can choose weights that increase the influence of the non-majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Another way is re-sampling the training set\n",
    "- Expand the number of training examples\n",
    "- By increasing the number of examples of the non-majority class\n",
    "    - Randomly sample examples in the non-majority class\n",
    "    - So you will have duplicates\n",
    "- This creates a more balanced dataset on which to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "These are just some ideas for you to achieve a model with better\n",
    "conditional metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Now submit your assignment!\n",
    "\n",
    "Up to now, you have prepared the data you need, generate some ideas about what the feature correlation is like and how to handle imbalanced labels. Next you will need to build your own Machine Learning model and do evaluation in your final project.\n",
    "\n",
    "Please click on the blue button <span style=\"color: blue;\"> **Submit** </span> in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
