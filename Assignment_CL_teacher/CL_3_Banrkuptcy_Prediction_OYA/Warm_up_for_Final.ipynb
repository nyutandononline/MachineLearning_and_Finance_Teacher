{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem description\n",
    "\n",
    "You are to predict whether a company will go bankrupt in the following year, based on financial attributes of the company.\n",
    "\n",
    "Perhaps you are contemplating lending money to a company and need to know whether the company is in near-term danger of not being able to repay.\n",
    "\n",
    "This task is divided in to two parts,\n",
    "- Part 1 is this Assignment 3, which is a warm-up exercise for your final project\n",
    "- Part 2 will be your Final Project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Goal\n",
    "\n",
    "In previous assignments we provided code that tamed the problem of unruly data, in order to allow you to focus on the *other* steps in the Recipe.  There was also little Exploratory Data Analysis.\n",
    "\n",
    "This assignment will require you to deal with data issues.  It will also make some \"suggestions\" for\n",
    "exploring the data.\n",
    "\n",
    "These are intended to serve as inspiration for the\n",
    "preliminary steps in what will become your Final Project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Demonstrate mastery on solving a classification problem and presenting\n",
    "the entire Recipe for Machine Learning process in a notebook.\n",
    "- We will make suggestions for ways to approach the problem\n",
    "    - But there will be little explicit direction for this task.\n",
    "- It is meant to be analogous to a pre-interview task that a potential employer might assign\n",
    "to verify your skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Load the bankruptcy_helper module\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Import bankruptcy_helper module\n",
    "import bankruptcy_helper\n",
    "%aimport bankruptcy_helper\n",
    "\n",
    "helper = bankruptcy_helper.Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# API for students\n",
    "\n",
    "We have defined some utility routines in a file `bankruptcy_helper.py`. There is a class named `Helper` in it.  \n",
    "\n",
    "This will simplify problem solving\n",
    "\n",
    "\n",
    "`helper = bankruptcy_helper.Helper()`\n",
    "\n",
    "\n",
    "\n",
    "- getData: get the training data and holdout data\n",
    "  > `train, holdout = getData()`\n",
    "\n",
    "- plot_attr: Create multiple plots of the distribution of the feature names `attr`, one plot per possible value of target/label `y`\n",
    "  >`helper.plot_attr(X, y, attr, trunc)`       \n",
    "\n",
    "  > `X`: DataFrame of features. Each row is an example          \n",
    "  > `y`: DataFrame/ndarray. Label of each example.,      \n",
    "  > `attr`: string.  Name of feature whose distribution will be plotted      \n",
    "  > `trunc`: Scalar. Optional parameter to truncate distribution at a threshold percentage.\n",
    "\n",
    "\n",
    "- save_data: save the training and test data into a folder named \"my_data\"\n",
    "  > `helper.save_data(X_train, X_test, y_train, y_test)`\n",
    " \n",
    "- load_data: load the training and test data from a folder named \"my_data\"\n",
    "  > `X_train, X_test, y_train, y_test = helper.load_data()`\n",
    "  \n",
    "where\n",
    "- `X_train, y_train` are the features/labels of the training data\n",
    "- `X_test, y_test` are the features/labels of the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Get the data\n",
    "\n",
    "The first step in our Recipe is Get the Data. \n",
    "\n",
    "There are two datasets in this assignment, which are stored in two different directories.\n",
    "\n",
    "- The training data (examples consisting of feature vector/label pairs)\n",
    "    - Stored in the file `train/data.csv`\n",
    "- Holdout data (examples consisting of feature vectors **without** labels)\n",
    "    - Stored in the file `holdout/data.csv`\n",
    "    - Only the instructors now the labels.\n",
    "    - We will evaluate your model performance on this dataset.\n",
    "\n",
    "For the training data\n",
    "- Each example is a row of data corresponding to a single company\n",
    "- There are 64 attributes, described in the section below\n",
    "- The column `Bankrupt`. the label, is 1 if the company subsequently went bankrupt; 0 if it did not go bankrupt\n",
    "- The column `Id` is a Company Identifier\n",
    "\n",
    "The holdout data is identical to the training data with the exception of the absence of `Bankrupt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date shape:  (4818, 66)\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "#  data: training dataset\n",
    "#  holdout: hold out dataset without targets\n",
    "data, holdout = helper.getData()\n",
    "\n",
    "target_attr = \"Bankrupt\" # target attribute in training data, 1 for bankrupt and 0 for not bankrupt\n",
    "\n",
    "n_samples, n_attrs = data.shape\n",
    "print(\"Date shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Have a look at the data\n",
    "\n",
    "We will not go through all steps in the Recipe, nor in depth.\n",
    "\n",
    "But here's a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.41769</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>1.1605</td>\n",
       "      <td>-126.39</td>\n",
       "      <td>0.41355</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>1.2395</td>\n",
       "      <td>1.16500</td>\n",
       "      <td>0.51773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049094</td>\n",
       "      <td>0.85835</td>\n",
       "      <td>0.12322</td>\n",
       "      <td>5.6167</td>\n",
       "      <td>7.4042</td>\n",
       "      <td>164.310</td>\n",
       "      <td>2.2214</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0</td>\n",
       "      <td>4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.023834</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.50839</td>\n",
       "      <td>4.2374</td>\n",
       "      <td>22.034</td>\n",
       "      <td>0.058412</td>\n",
       "      <td>-0.027621</td>\n",
       "      <td>3.6579</td>\n",
       "      <td>0.98183</td>\n",
       "      <td>0.76855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031011</td>\n",
       "      <td>1.01850</td>\n",
       "      <td>0.069047</td>\n",
       "      <td>5.7996</td>\n",
       "      <td>7.7529</td>\n",
       "      <td>26.446</td>\n",
       "      <td>13.802</td>\n",
       "      <td>6.4782</td>\n",
       "      <td>0</td>\n",
       "      <td>3537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030515</td>\n",
       "      <td>0.44606</td>\n",
       "      <td>0.19569</td>\n",
       "      <td>1.565</td>\n",
       "      <td>35.766</td>\n",
       "      <td>0.28196</td>\n",
       "      <td>0.039264</td>\n",
       "      <td>0.88456</td>\n",
       "      <td>1.05260</td>\n",
       "      <td>0.39457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077337</td>\n",
       "      <td>0.95006</td>\n",
       "      <td>0.25266</td>\n",
       "      <td>15.049</td>\n",
       "      <td>2.8179</td>\n",
       "      <td>104.730</td>\n",
       "      <td>3.4852</td>\n",
       "      <td>2.6361</td>\n",
       "      <td>0</td>\n",
       "      <td>3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052318</td>\n",
       "      <td>0.056366</td>\n",
       "      <td>0.54562</td>\n",
       "      <td>10.68</td>\n",
       "      <td>438.2</td>\n",
       "      <td>0.13649</td>\n",
       "      <td>0.058164</td>\n",
       "      <td>10.853</td>\n",
       "      <td>1.02790</td>\n",
       "      <td>0.61173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085524</td>\n",
       "      <td>0.97282</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0157</td>\n",
       "      <td>7.4626</td>\n",
       "      <td>48.756</td>\n",
       "      <td>7.4863</td>\n",
       "      <td>1.0602</td>\n",
       "      <td>0</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.49712</td>\n",
       "      <td>0.12316</td>\n",
       "      <td>1.3036</td>\n",
       "      <td>-71.398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>1.0116</td>\n",
       "      <td>1.29210</td>\n",
       "      <td>0.50288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.99925</td>\n",
       "      <td>0.019736</td>\n",
       "      <td>3.4819</td>\n",
       "      <td>8.582</td>\n",
       "      <td>114.580</td>\n",
       "      <td>3.1854</td>\n",
       "      <td>2.742</td>\n",
       "      <td>0</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2       X3      X4       X5        X6         X7  \\\n",
       "0   0.025417   0.41769   0.0568  1.1605  -126.39   0.41355   0.025417   \n",
       "1  -0.023834    0.2101  0.50839  4.2374   22.034  0.058412  -0.027621   \n",
       "2   0.030515   0.44606  0.19569   1.565   35.766   0.28196   0.039264   \n",
       "3   0.052318  0.056366  0.54562   10.68    438.2   0.13649   0.058164   \n",
       "4   0.000992   0.49712  0.12316  1.3036  -71.398         0   0.001007   \n",
       "\n",
       "        X8       X9      X10  ...        X57      X58       X59     X60  \\\n",
       "0   1.2395  1.16500  0.51773  ...   0.049094  0.85835   0.12322  5.6167   \n",
       "1   3.6579  0.98183  0.76855  ...  -0.031011  1.01850  0.069047  5.7996   \n",
       "2  0.88456  1.05260  0.39457  ...   0.077337  0.95006   0.25266  15.049   \n",
       "3   10.853  1.02790  0.61173  ...   0.085524  0.97282         0  6.0157   \n",
       "4   1.0116  1.29210  0.50288  ...   0.001974  0.99925  0.019736  3.4819   \n",
       "\n",
       "      X61      X62     X63     X64  Bankrupt    Id  \n",
       "0  7.4042  164.310  2.2214   1.334         0  4510  \n",
       "1  7.7529   26.446  13.802  6.4782         0  3537  \n",
       "2  2.8179  104.730  3.4852  2.6361         0  3920  \n",
       "3  7.4626   48.756  7.4863  1.0602         0  1806  \n",
       "4   8.582  114.580  3.1854   2.742         0  1529  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.20839</td>\n",
       "      <td>0.26185</td>\n",
       "      <td>0.41039</td>\n",
       "      <td>2.5692</td>\n",
       "      <td>69.704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20839</td>\n",
       "      <td>2.819</td>\n",
       "      <td>1.641</td>\n",
       "      <td>0.73815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193390</td>\n",
       "      <td>0.28231</td>\n",
       "      <td>0.81043</td>\n",
       "      <td>0</td>\n",
       "      <td>52.04</td>\n",
       "      <td>4.6463</td>\n",
       "      <td>58.171</td>\n",
       "      <td>6.2747</td>\n",
       "      <td>5.0017</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.19877</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>-0.15579</td>\n",
       "      <td>0.83309</td>\n",
       "      <td>-57.414</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.19877</td>\n",
       "      <td>0.067309</td>\n",
       "      <td>0.93406</td>\n",
       "      <td>0.063054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159470</td>\n",
       "      <td>-3.1524</td>\n",
       "      <td>1.20510</td>\n",
       "      <td>0</td>\n",
       "      <td>56.348</td>\n",
       "      <td>1.3163</td>\n",
       "      <td>364.730</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>4.202</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.35741</td>\n",
       "      <td>0.57153</td>\n",
       "      <td>0.34081</td>\n",
       "      <td>1.5991</td>\n",
       "      <td>4.4819</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35741</td>\n",
       "      <td>0.74968</td>\n",
       "      <td>2.6993</td>\n",
       "      <td>0.42847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.83415</td>\n",
       "      <td>0.86775</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6285</td>\n",
       "      <td>7.8131</td>\n",
       "      <td>76.926</td>\n",
       "      <td>4.7448</td>\n",
       "      <td>29.896</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024312</td>\n",
       "      <td>0.45219</td>\n",
       "      <td>0.011469</td>\n",
       "      <td>1.0393</td>\n",
       "      <td>-831.06</td>\n",
       "      <td>0.006914</td>\n",
       "      <td>0.031273</td>\n",
       "      <td>1.2114</td>\n",
       "      <td>0.88188</td>\n",
       "      <td>0.54781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193770</td>\n",
       "      <td>0.044381</td>\n",
       "      <td>0.82091</td>\n",
       "      <td>0.29244</td>\n",
       "      <td>21.306</td>\n",
       "      <td>3.4388</td>\n",
       "      <td>120.850</td>\n",
       "      <td>3.0202</td>\n",
       "      <td>1.2661</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075494</td>\n",
       "      <td>0.088948</td>\n",
       "      <td>0.56492</td>\n",
       "      <td>7.6065</td>\n",
       "      <td>74.299</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10304</td>\n",
       "      <td>10.243</td>\n",
       "      <td>2.1253</td>\n",
       "      <td>0.91105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037832</td>\n",
       "      <td>0.082864</td>\n",
       "      <td>0.95227</td>\n",
       "      <td>0</td>\n",
       "      <td>15.437</td>\n",
       "      <td>8.391</td>\n",
       "      <td>14.685</td>\n",
       "      <td>24.855</td>\n",
       "      <td>6.0797</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3       X4       X5        X6        X7  \\\n",
       "0   0.20839   0.26185   0.41039   2.5692   69.704         0   0.20839   \n",
       "1  -0.19877    0.9368  -0.15579  0.83309  -57.414         0  -0.19877   \n",
       "2   0.35741   0.57153   0.34081   1.5991   4.4819         0   0.35741   \n",
       "3  0.024312   0.45219  0.011469   1.0393  -831.06  0.006914  0.031273   \n",
       "4  0.075494  0.088948   0.56492   7.6065   74.299         0   0.10304   \n",
       "\n",
       "         X8       X9       X10  ...       X56       X57      X58      X59  \\\n",
       "0     2.819    1.641   0.73815  ...  0.193390   0.28231  0.81043        0   \n",
       "1  0.067309  0.93406  0.063054  ... -0.159470   -3.1524  1.20510        0   \n",
       "2   0.74968   2.6993   0.42847  ...  0.160800   0.83415  0.86775        0   \n",
       "3    1.2114  0.88188   0.54781  ...  0.193770  0.044381  0.82091  0.29244   \n",
       "4    10.243   2.1253   0.91105  ...  0.037832  0.082864  0.95227        0   \n",
       "\n",
       "      X60     X61      X62     X63     X64   Id  \n",
       "0   52.04  4.6463   58.171  6.2747  5.0017  699  \n",
       "1  56.348  1.3163  364.730  1.0007   4.202  539  \n",
       "2  8.6285  7.8131   76.926  4.7448  29.896  867  \n",
       "3  21.306  3.4388  120.850  3.0202  1.2661  595  \n",
       "4  15.437   8.391   14.685  24.855  6.0797  632  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# holdout data\n",
    "holdout.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Pretty *unhelpful* !\n",
    "\n",
    "What are these mysteriously named features ?\n",
    "\n",
    "## Description of attributes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Attribute Information:\n",
    "\n",
    "Id Company Identifier \n",
    "X1 net profit / total assets\n",
    "X2 total liabilities / total assets\n",
    "X3 working capital / total assets\n",
    "X4 current assets / short-term liabilities\n",
    "X5 [(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365\n",
    "X6 retained earnings / total assets\n",
    "X7 EBIT / total assets\n",
    "X8 book value of equity / total liabilities\n",
    "X9 sales / total assets\n",
    "X10 equity / total assets\n",
    "X11 (gross profit + extraordinary items + financial expenses) / total assets\n",
    "X12 gross profit / short-term liabilities\n",
    "X13 (gross profit + depreciation) / sales\n",
    "X14 (gross profit + interest) / total assets\n",
    "X15 (total liabilities * 365) / (gross profit + depreciation)\n",
    "X16 (gross profit + depreciation) / total liabilities\n",
    "X17 total assets / total liabilities\n",
    "X18 gross profit / total assets\n",
    "X19 gross profit / sales\n",
    "X20 (inventory * 365) / sales\n",
    "X21 sales (n) / sales (n-1)\n",
    "X22 profit on operating activities / total assets\n",
    "X23 net profit / sales\n",
    "X24 gross profit (in 3 years) / total assets\n",
    "X25 (equity - share capital) / total assets\n",
    "X26 (net profit + depreciation) / total liabilities\n",
    "X27 profit on operating activities / financial expenses\n",
    "X28 working capital / fixed assets\n",
    "X29 logarithm of total assets\n",
    "X30 (total liabilities - cash) / sales\n",
    "X31 (gross profit + interest) / sales\n",
    "X32 (current liabilities * 365) / cost of products sold\n",
    "X33 operating expenses / short-term liabilities\n",
    "X34 operating expenses / total liabilities\n",
    "X35 profit on sales / total assets\n",
    "X36 total sales / total assets\n",
    "X37 (current assets - inventories) / long-term liabilities\n",
    "X38 constant capital / total assets\n",
    "X39 profit on sales / sales\n",
    "X40 (current assets - inventory - receivables) / short-term liabilities\n",
    "X41 total liabilities / ((profit on operating activities + depreciation) * (12/365))\n",
    "X42 profit on operating activities / sales\n",
    "X43 rotation receivables + inventory turnover in days\n",
    "X44 (receivables * 365) / sales\n",
    "X45 net profit / inventory\n",
    "X46 (current assets - inventory) / short-term liabilities\n",
    "X47 (inventory * 365) / cost of products sold\n",
    "X48 EBITDA (profit on operating activities - depreciation) / total assets\n",
    "X49 EBITDA (profit on operating activities - depreciation) / sales\n",
    "X50 current assets / total liabilities\n",
    "X51 short-term liabilities / total assets\n",
    "X52 (short-term liabilities * 365) / cost of products sold)\n",
    "X53 equity / fixed assets\n",
    "X54 constant capital / fixed assets\n",
    "X55 working capital\n",
    "X56 (sales - cost of products sold) / sales\n",
    "X57 (current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)\n",
    "X58 total costs /total sales\n",
    "X59 long-term liabilities / equity\n",
    "X60 sales / inventory\n",
    "X61 sales / receivables\n",
    "X62 (short-term liabilities *365) / sales\n",
    "X63 sales / short-term liabilities\n",
    "X64 sales / fixed assets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This may still be somewhat unhelpful for those of you not used to reading Financial Statements.\n",
    "\n",
    "But that's partially the point of the exercise\n",
    "- You can *still* perform Machine Learning *even if* you are not an expert in the problem domain\n",
    "    - That's what makes this a good interview exercise: you can demonstrate your thought process even if you don't know the exact meaning of the terms\n",
    "- Of course: becoming an expert in the domain *will improve* your ability to create better models\n",
    "    - Feature engineering is easier if you understand the features, their inter-relationships, and the relationship to the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's get a feel for the data\n",
    "- What is the type of each attribute ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   X1        4818 non-null   object \n",
      " 1   X2        4818 non-null   object \n",
      " 2   X3        4818 non-null   object \n",
      " 3   X4        4818 non-null   object \n",
      " 4   X5        4818 non-null   object \n",
      " 5   X6        4818 non-null   object \n",
      " 6   X7        4818 non-null   object \n",
      " 7   X8        4818 non-null   object \n",
      " 8   X9        4818 non-null   float64\n",
      " 9   X10       4818 non-null   object \n",
      " 10  X11       4818 non-null   object \n",
      " 11  X12       4818 non-null   object \n",
      " 12  X13       4818 non-null   float64\n",
      " 13  X14       4818 non-null   object \n",
      " 14  X15       4818 non-null   object \n",
      " 15  X16       4818 non-null   object \n",
      " 16  X17       4818 non-null   object \n",
      " 17  X18       4818 non-null   object \n",
      " 18  X19       4818 non-null   float64\n",
      " 19  X20       4818 non-null   float64\n",
      " 20  X21       4818 non-null   object \n",
      " 21  X22       4818 non-null   object \n",
      " 22  X23       4818 non-null   float64\n",
      " 23  X24       4818 non-null   object \n",
      " 24  X25       4818 non-null   object \n",
      " 25  X26       4818 non-null   object \n",
      " 26  X27       4818 non-null   object \n",
      " 27  X28       4818 non-null   object \n",
      " 28  X29       4818 non-null   object \n",
      " 29  X30       4818 non-null   float64\n",
      " 30  X31       4818 non-null   float64\n",
      " 31  X32       4818 non-null   object \n",
      " 32  X33       4818 non-null   object \n",
      " 33  X34       4818 non-null   object \n",
      " 34  X35       4818 non-null   object \n",
      " 35  X36       4818 non-null   object \n",
      " 36  X37       4818 non-null   object \n",
      " 37  X38       4818 non-null   object \n",
      " 38  X39       4818 non-null   float64\n",
      " 39  X40       4818 non-null   object \n",
      " 40  X41       4818 non-null   object \n",
      " 41  X42       4818 non-null   float64\n",
      " 42  X43       4818 non-null   float64\n",
      " 43  X44       4818 non-null   float64\n",
      " 44  X45       4818 non-null   object \n",
      " 45  X46       4818 non-null   object \n",
      " 46  X47       4818 non-null   object \n",
      " 47  X48       4818 non-null   object \n",
      " 48  X49       4818 non-null   float64\n",
      " 49  X50       4818 non-null   object \n",
      " 50  X51       4818 non-null   object \n",
      " 51  X52       4818 non-null   object \n",
      " 52  X53       4818 non-null   object \n",
      " 53  X54       4818 non-null   object \n",
      " 54  X55       4818 non-null   float64\n",
      " 55  X56       4818 non-null   float64\n",
      " 56  X57       4818 non-null   object \n",
      " 57  X58       4818 non-null   float64\n",
      " 58  X59       4818 non-null   object \n",
      " 59  X60       4818 non-null   object \n",
      " 60  X61       4818 non-null   object \n",
      " 61  X62       4818 non-null   float64\n",
      " 62  X63       4818 non-null   object \n",
      " 63  X64       4818 non-null   object \n",
      " 64  Bankrupt  4818 non-null   int64  \n",
      " 65  Id        4818 non-null   int64  \n",
      "dtypes: float64(16), int64(2), object(48)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "You may be puzzled:\n",
    "- Most attributes are `object` and *not* numeric (`float` or `int`)\n",
    "- But looking at the data via `data.head()` certainly gives the impression that all attributes are numeric\n",
    "\n",
    "Welcome to the world of messy data !  The dataset has represented numbers as strings.\n",
    "- These little unexpected challenges are common in the real-word\n",
    "- Data is rarely perfect and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "So we will first have to convert all attributes to numeric\n",
    "\n",
    "**Question:**\n",
    "\n",
    "Create an all-numeric version of the data.  Assign it to the variable `data` (replacing the original)\n",
    "\n",
    "**Hint:**\n",
    "- Look up the Pandas method `to_numeric`\n",
    "    - We suggest you use the option `errors='coerce'`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "non_numeric_cols = data.select_dtypes(exclude=['float', 'int']).columns\n",
    "data[ non_numeric_cols] = data[ non_numeric_cols ].apply(pd.to_numeric, downcast='float', errors='coerce')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-numeric-data",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "assert 'object' not in data.dtypes\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's look at the data again, now that it is numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   X1        4816 non-null   float32\n",
      " 1   X2        4816 non-null   float32\n",
      " 2   X3        4816 non-null   float32\n",
      " 3   X4        4803 non-null   float32\n",
      " 4   X5        4808 non-null   float32\n",
      " 5   X6        4816 non-null   float32\n",
      " 6   X7        4816 non-null   float32\n",
      " 7   X8        4804 non-null   float32\n",
      " 8   X9        4818 non-null   float64\n",
      " 9   X10       4816 non-null   float32\n",
      " 10  X11       4816 non-null   float32\n",
      " 11  X12       4803 non-null   float32\n",
      " 12  X13       4818 non-null   float64\n",
      " 13  X14       4816 non-null   float32\n",
      " 14  X15       4812 non-null   float32\n",
      " 15  X16       4804 non-null   float32\n",
      " 16  X17       4804 non-null   float32\n",
      " 17  X18       4816 non-null   float32\n",
      " 18  X19       4818 non-null   float64\n",
      " 19  X20       4818 non-null   float64\n",
      " 20  X21       4744 non-null   float32\n",
      " 21  X22       4816 non-null   float32\n",
      " 22  X23       4818 non-null   float64\n",
      " 23  X24       4702 non-null   float32\n",
      " 24  X25       4816 non-null   float32\n",
      " 25  X26       4804 non-null   float32\n",
      " 26  X27       4513 non-null   float32\n",
      " 27  X28       4735 non-null   float32\n",
      " 28  X29       4816 non-null   float32\n",
      " 29  X30       4818 non-null   float64\n",
      " 30  X31       4818 non-null   float64\n",
      " 31  X32       4776 non-null   float32\n",
      " 32  X33       4803 non-null   float32\n",
      " 33  X34       4804 non-null   float32\n",
      " 34  X35       4816 non-null   float32\n",
      " 35  X36       4816 non-null   float32\n",
      " 36  X37       2750 non-null   float32\n",
      " 37  X38       4816 non-null   float32\n",
      " 38  X39       4818 non-null   float64\n",
      " 39  X40       4803 non-null   float32\n",
      " 40  X41       4756 non-null   float32\n",
      " 41  X42       4818 non-null   float64\n",
      " 42  X43       4818 non-null   float64\n",
      " 43  X44       4818 non-null   float64\n",
      " 44  X45       4598 non-null   float32\n",
      " 45  X46       4803 non-null   float32\n",
      " 46  X47       4787 non-null   float32\n",
      " 47  X48       4816 non-null   float32\n",
      " 48  X49       4818 non-null   float64\n",
      " 49  X50       4804 non-null   float32\n",
      " 50  X51       4816 non-null   float32\n",
      " 51  X52       4786 non-null   float32\n",
      " 52  X53       4735 non-null   float32\n",
      " 53  X54       4735 non-null   float32\n",
      " 54  X55       4818 non-null   float64\n",
      " 55  X56       4818 non-null   float64\n",
      " 56  X57       4816 non-null   float32\n",
      " 57  X58       4818 non-null   float64\n",
      " 58  X59       4816 non-null   float32\n",
      " 59  X60       4598 non-null   float32\n",
      " 60  X61       4806 non-null   float32\n",
      " 61  X62       4818 non-null   float64\n",
      " 62  X63       4803 non-null   float32\n",
      " 63  X64       4735 non-null   float32\n",
      " 64  Bankrupt  4818 non-null   int64  \n",
      " 65  Id        4818 non-null   int64  \n",
      "dtypes: float32(48), float64(16), int64(2)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Hopefully you will see that all the attributes are now numeric.\n",
    "\n",
    "Surprise !\n",
    "\n",
    "Looks like there are some examples with undefined values for some features !\n",
    "- Why didn't we see this when the data was not encoded as numbers ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "List all the attributes of `data` that are missing from at least one example.\n",
    "- Set list `attrs_missing` to either a list or array of attributes that are missing from at least one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes with values missing for at least some examples\t:\n",
      "\tX1\n",
      "\tX2\n",
      "\tX3\n",
      "\tX4\n",
      "\tX5\n",
      "\tX6\n",
      "\tX7\n",
      "\tX8\n",
      "\tX10\n",
      "\tX11\n",
      "\tX12\n",
      "\tX14\n",
      "\tX15\n",
      "\tX16\n",
      "\tX17\n",
      "\tX18\n",
      "\tX21\n",
      "\tX22\n",
      "\tX24\n",
      "\tX25\n",
      "\tX26\n",
      "\tX27\n",
      "\tX28\n",
      "\tX29\n",
      "\tX32\n",
      "\tX33\n",
      "\tX34\n",
      "\tX35\n",
      "\tX36\n",
      "\tX37\n",
      "\tX38\n",
      "\tX40\n",
      "\tX41\n",
      "\tX45\n",
      "\tX46\n",
      "\tX47\n",
      "\tX48\n",
      "\tX50\n",
      "\tX51\n",
      "\tX52\n",
      "\tX53\n",
      "\tX54\n",
      "\tX57\n",
      "\tX59\n",
      "\tX60\n",
      "\tX61\n",
      "\tX63\n",
      "\tX64\n"
     ]
    }
   ],
   "source": [
    "# Set variable\n",
    "#  attrs_missing: list or array, attributes that are missing from at least one example\n",
    "attrs_missing = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "num_examples = data.shape[0]\n",
    "num_examples_undefined = data.isnull().sum(axis=0)\n",
    "attrs_missing = num_examples_undefined[ num_examples_undefined > 0 ].index.tolist()\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Attributes with values missing for at least some examples\\t:\\n\\t\" + \"\\n\\t\".join(attrs_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-missing-data",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "tmp = np.sum(data.isna())\n",
    "attrs_missing_test = tmp[tmp>0].index.tolist()\n",
    "assert set(attrs_missing_test) == set(attrs_missing)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "So it looks like you will have to deal with missing data at some point.\n",
    "\n",
    "We won't do this just now; you will need to address the issue yourself later.\n",
    "\n",
    "But you will hopefully see that our target (`Bankrupt`) is not missing in any example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check if you target is missing any example\n",
    "assert( not target_attr in set(attrs_missing) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The label/target is included in this dataset\n",
    "- It is the attribute `Bankrupt`\n",
    "- Let's separate it from the feature attributes so we don't accidentally train the model with a feature that **is** the target !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (4818, 65)\n"
     ]
    }
   ],
   "source": [
    "data, labels = data.drop(columns=[target_attr]), data[target_attr]\n",
    "print(\"Data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We will shuffle the examples before doing anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape:  (4818,)\n",
      "Label values:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data first\n",
    "data, labels = sklearn.utils.shuffle(data, labels, random_state=42)\n",
    "\n",
    "print(\"Labels shape: \", labels.shape)\n",
    "print(\"Label values: \", np.unique(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Create a test set \n",
    "\n",
    "To train and evaluate a model, we need to split the original dataset into\n",
    "a training subset (in-sample) and a test subset (out of sample).\n",
    "\n",
    "Although **we** are the only ones with the holdout dataset, you probably want\n",
    "to perform out of sample evaluation of your model.\n",
    "So please create a test data set.\n",
    "\n",
    "**Question:**\n",
    "\n",
    "Split the data \n",
    "- Set \n",
    "    - `X_train`: training examples\n",
    "    - `y_train`: labels of the training examples\n",
    "    - `X_test`: test examples\n",
    "    - `y_test`: labels of test examples\n",
    "- 90% will be used for training the model\n",
    "- 10% will be used as validation (out of sample) examples\n",
    "- Use `train_test_split()` from `sklearn` to perform this split\n",
    "    -  Set the `random_state` parameter of `train_test_split()` to be 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (4336, 65)\n",
      "X_test shape: (482, 65)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "# Create variables X_train, X_test, y_train, y_test\n",
    "#   X_train: training examples\n",
    "#   y_train: labels of the training examples\n",
    "#   X_test:  test examples\n",
    "#   y_test:  labels of test examples\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.10, random_state=42)\n",
    "### END SOLUTION\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-create-test",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(data, labels, test_size=0.10, random_state=42)\n",
    "assert np.allclose(X_train_, X_train, equal_nan=True)\n",
    "assert np.allclose(y_train_, y_train, equal_nan=True)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "You may want to analyze potential relationships\n",
    "- Between features and the target\n",
    "- Between pairs/groups of features\n",
    "\n",
    "We'll make some suggestions but, ultimately it is up to you.\n",
    "\n",
    "**Warning**\n",
    "\n",
    "We will perform *our* exploration using the **raw** data\n",
    "- Thus, there may be features with missing values\n",
    "- This may affect your analysis\n",
    "- For example: how is the correlation of 2 features computed when there are missing values ?\n",
    "- For the purpose of answering the questions: *leave the missing values in place*\n",
    "- For *your* model: feel free to deal with missing features before doing Exploratory Data Analysis\n",
    "\n",
    "**Remember**\n",
    "\n",
    "- Base your analysis on `X_train`, don't peek at your out of sample data !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Features correlated with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "List the 5 features whose correlations with the target are largest (most positive).\n",
    "\n",
    "\n",
    "- Set variable `corr_features`\n",
    "    - To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "    - Most highly correlated with `Bankrupt`\n",
    "    - In *descending order*\n",
    "\n",
    "**Hint:**\n",
    "- Look up the Pandas `corr` method\n",
    "- Look up the Pandas `sort_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features most correlated with target:  ['X2', 'X51', 'X32', 'X9', 'X36']\n"
     ]
    }
   ],
   "source": [
    "# Set variable\n",
    "#  corr_features: list or array, 5 features whose correlations with target are largest\n",
    "corr_features = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# Put target back with data to facilitate correlation\n",
    "df = X_train.copy()\n",
    "df[ target_attr ] = y_train\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "target_corr = corr_matrix['Bankrupt'].sort_values(ascending = False)\n",
    "corr_features = target_corr.index[ 1:6 ].tolist()\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Features most correlated with target: \", corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-target-correlation",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "df_test = X_train.copy()\n",
    "df_test[ target_attr ] = y_train\n",
    "corr_matrix_test = df_test.corr()\n",
    "\n",
    "target_corr_test = corr_matrix_test['Bankrupt'].sort_values(ascending = False)\n",
    "corr_features_test = target_corr_test.index[ 1:6 ].tolist()\n",
    "\n",
    "assert list(corr_features) == corr_features_test\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Mutually correlated features\n",
    "\n",
    "When you have a lot of features, you might discover that some of them convey little information\n",
    "- Pairs of highly correlated features\n",
    "- A small number of features that adequately represent the whole\n",
    "    - In the Unsupervised Learning lecture, we will learn about PCA, a way to discover a small set of synthetic features that capture the whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Questions:**\n",
    "\n",
    "- List the 5 features whose correlations with feature `X1` are largest (most positive).\n",
    "    - Set variable `X1_corr_p`\n",
    "        - To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "        - Most highly correlated\n",
    "        - In *descending order*\n",
    "    \n",
    "- List the 5 features whose correlations with feature `X1` are *most negative*.\n",
    "    - Set variable `X1_corr_n`\n",
    "        - To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "        - Most highly *negatively* correlated\n",
    "        - In *ascending order* (most negative first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features most positively correlated with X1 ['X7', 'X14', 'X11', 'X22', 'X35']\n",
      "Features most negatively correlated with X1 ['X36', 'X38', 'X10', 'X25', 'X53']\n"
     ]
    }
   ],
   "source": [
    "# Set varaibels\n",
    "#  X1_corr_p: list or array, 5 features whose correlations with target are most positive\n",
    "#  X1_corr_n: list or array, 5 features whose correlations with target are most negative\n",
    "X1_corr_p = None\n",
    "X1_corr_n = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# Put target back with data to facilitate correlation\n",
    "df = X_train.copy()\n",
    "df[ target_attr ] = y_train\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "X1_corr = corr_matrix['X1'].sort_values(ascending = False)\n",
    "\n",
    "X1_corr_p = X1_corr.index[ 1: 6].tolist()\n",
    "X1_corr_n = X1_corr.index[ -1: - 6 : -1 ].tolist()\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Features most positively correlated with X1\", X1_corr_p)\n",
    "print(\"Features most negatively correlated with X1\", X1_corr_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-X1-correlation",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "X1_corr_test = corr_matrix_test['X1'].sort_values(ascending = False)\n",
    "\n",
    "X1_corr_p_test = X1_corr_test.index[ 1: 6].tolist()\n",
    "X1_corr_n_test = X1_corr_test.index[ -1: - 6 : -1 ].tolist()\n",
    "\n",
    "assert X1_corr_p_test == list(X1_corr_p)\n",
    "assert X1_corr_n_test == list(X1_corr_n)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "One thing to consider (we saw something similar in the lecture topic on Influential Points)\n",
    "- Outliers (feature values that are at the extremes of the distribution) can affect correlation\n",
    "\n",
    "To illustrate:\n",
    "- We will show the distribution of one feature, conditional on the value of the associated target value\n",
    "- Here we overlay two distributions\n",
    "    - The distribution of the feature value, conditioned on examples having target 0 (colored green)\n",
    "    - The distribution of the feature value, conditioned on examples having target 1 (colored red)\n",
    "    - When the two distributions overlap: the color will be a blend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot_attr(X_train, y_train, \"X51\", trunc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The above graph is not very informative\n",
    "- The distributions overlap for the bins chosen\n",
    "- But there seem to be many bins with very few values (i.e. X51 > 2)\n",
    "\n",
    "But let's perform the same plot while *eliminating* extreme values of the feature\n",
    "- Eliminate examples with the value of the feature in the upper and lower 1 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAEICAYAAACNqfTZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3df7ReVXng8e82MRSvVRHoqMCUdEjX2WEOgxqi03asLaOCsyT9ASVQ20OHaZwqtI4z7WDtQibVNnZskeFHaxbqvNBRRGbsyoyplEo77bJqEy1yDPutjTELQnVUSLWEKl7c88d7bvrmzU3y3ss999z75vtZ6y7O2Wef9302517Ow9777BNyzkiSJHXlaV0HIEmSjm8mI5IkqVMmI5IkqVMmI5IkqVMmI5IkqVMmI5IkqVMruw5AkiS1IxXxAuAGYAVwa+ynLSPHXwa8CzgH2Bj76a6m/Fzgd4FnAU8Cb4/99MG24pyYZORpT3taPvHEE7sOQ5KkRfP444/nnPOsoxypiCuAm4FXAPuAHamI22I/PTBU7UHgCuA/jX408LOxn/4mFfEFwKdTEe+O/fR3C94IJigZOfHEEzlw4EDXYUiStGhCCP9wlMPrgd2xn/YApCLeAWwADiYjsZ/2Nse+M3xi7KfPD23/bSriV4BTgVaSEeeMSJI0mU4DHhra39eUzUkq4npgFfCFBYrrMBPTMyJJ0nFoZQhh59D+1pzz1oX68FTE5wO3A1Xsp+8cq/58mYxIkrR8Teec1x3h2MPAGUP7pzdlY0lFfBbwEeAtsZ8+Of8Qj81kRJKkybQDWJOKuJpBErIRuHycE1MRVwEfBm6becKmTWFS3to7NTWVncAqSTqehBAezzlPHel4KuKrGTy6uwJ4b+ynt6cibgZ2xn7alop4HoOk4yTgm8CXYz+dnYr4WuB9wK6hj7si9tN9rbTDZESSpOXpWMnIcuHTNJIkqVMmI5IkqVMmI5IkqVM+TTMBbrnvlnmd9/pzX7/AkRzdV2+8aV7nnXr1VQsciSRpKbFnRJIkdcqekSVkvj0ckiQtZ/aMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTrW6HHzZKy8AbgBWALfWVb1l5PjLgHcB5wAb66q+qyk/F/hd4FnAk8Db66r+YJuxSpKkbrTWM1L2yhXAzcCFwFrgsrJXrh2p9iBwBfD+kfLHgZ+tq/ps4ALgXWWvfE5bsUqSpO602TOyHthdV/UegLJX3gFsAB6YqVBX9d7m2HeGT6yr+vND239b9sqvAKcCf9divJIkqQNtzhk5DXhoaH9fUzYnZa9cD6wCvrBAcUmSpCWk1TkjT1XZK58P3A5UdVV/Z/R4CGETsAlg1apVixzd8nfLfbfM67zXn/v6BY5EknQ8a7Nn5GHgjKH905uysZS98lnAR4C31FX9ydnq5Jy35pzX5ZzXrVy5pPMqSZJ0BG3ewXcAa8peuZpBErIRuHycE8teuQr4MHDbzBM2kiRpMrXWM1JX9TRwFXA3kIA766reVfbKzWWvvAig7JXnlb1yH3AJ8O6yV+5qTv8p4GXAFWWvvK/5ObetWCVJUndCzrnrGBbE1NRUPnDgQNdhPCXzncOx2OY7Z+SrN940r/NOvfqqeZ0nSZMuhPB4znmq6zieKidaaMkziZGkyeZy8JIkqVP2jEiSNKFSEQ95LUvspy0jxw95LUvsp7uGjlXArzW7b4v91GsrTntGJEmaQKmIh72WJRVxrNeypCI+F3gr8BIGK6q/NRXxpLZiNRmRJGkyrQd2x37aE/vpCWDmtSwHxX7aG/vpfmB0YdFXAffEfno09tN+4B4G74prhcmIJEmT6am8lmVBXukyLueMSJK0fK0MIewc2t+ac97aWTTzZDIiSdLyNZ1zXneEY0/ltSwPAy8fOfdP5xrcuExGJEmaTDuANamIc34tC4PV039jaNLqK4E3L3yIA84ZkSRpAsV+Ouy1LLGfdqUibk5FvAggFfG8VMSDr2VJRdzVnPso8OsMEpodwOamrBX2jEiSNKFiP20Hto+UXTu0vYPBEMxs574XeG+rATbsGZEkSZ0yGZEkSZ0yGZEkSZ0yGZEkSZ1yAmsLbrnvlq5DkCRp2bBnRJIkdcpkRJIkdcpkRJIkdcpkRJIkdcpkRJIkdcpkRJIkdcpkRJIkdarVdUbKXnkBcAOwAri1ruotI8dfBrwLOAfYWFf1XUPHKuDXmt231VXdazNWjW++66hcssBxSJImQ2s9I2WvXAHcDFwIrAUuK3vl2pFqDwJXAO8fOfe5wFuBlwDrgbeWvfKktmKVJEndaXOYZj2wu67qPXVVPwHcAWwYrlBX9d66qu8HvjNy7quAe+qqfrSu6v3APcAFLcYqSZI60mYychrw0ND+vqas7XMlSdIysqzfTRNC2ARsAli1alXH0UiSpPlos2fkYeCMof3Tm7IFOzfnvDXnvC7nvG7lymWdV0mSdNxq8w6+A1hT9srVDBKJjcDlY557N/AbQ5NWXwm8eeFDlCRJXWutZ6Su6mngKgaJRQLurKt6V9krN5e98iKAsleeV/bKfQye+nx32St3Nec+Cvw6g4RmB7C5KZMkSRMm5Jy7jmFBTE1N5QMHDnQdBjD/dTgm3SV/PvrQVLtOvfqqRf0+SVpsIYTHc85TXcfxVLkCqyRJ6pTJiCRJ6pTJiCRJ6pTJiCRJ6pTJiCRJ6pTJiCRJ6pTLlkqSNKFSES8AbgBWALfGftoycvwE4DbgxcAjwKWxn/amIj4duBV4EYNc4bbYT7/ZVpz2jEiSNIFSEVcANwMXAmuBy1IR145UuxLYH/vpLOB64B1N+SXACbGfSgaJyutSEc9sK1aTEUmSJtN6YHfspz2xn54A7gA2jNTZAPSa7buA81MRA5CBqVTElcCJwBPAN9oK1GREkqTJdBrw0ND+vqZs1jqxn6aBrwMnM0hMDgBfAh4E3hn7qbXXspiMSJK0fK0MIewc+tm0QJ+7HngSeAGwGviPqYjft0CffRgnsEqStHxN55zXHeHYw8AZQ/unN2Wz1dnXDMk8m8FE1suBj8Z++jbwlVTEjwPrgD0LGfwMkxFpgXz1xpvmdZ4v9JPUkh3AmlTE1QySjo0Mkoxh24AK+ARwMXBv7Kecivgg8KPA7amIU8BLgXe1FajDNJIkTaBmDshVwN1AAu6M/bQrFXFzKuJFTbX3ACenIu4G3gRc05TfDDwzFXEXg6TmfbGf7m8rVntGJEmaULGftgPbR8quHdr+JoPHeEfPe2y28rbYMyJJkjplMiJJkjplMiJJkjplMiJJkjplMiJJkjrl0zSaWK77IUnLg8mIFs2OL++Y13nnPe+8BY5EkrSUOEwjSZI61WrPSNkrLwBuAFYAt9ZVvWXk+AnAbcCLGayFf2ld1XvLXvl04FbgRU2Mt9VV/ZttxipJkrrRWs9I2StXMFhO9kJgLXBZ2SvXjlS7EthfV/VZwPXAO5ryS4AT6qouGSQqryt75ZltxSpJkrrT5jDNemB3XdV76qp+ArgD2DBSZwPQa7bvAs4ve2UAMjBV9sqVwInAE8A3WoxVkiR1pM1k5DTgoaH9fU3ZrHXqqp4Gvg6czCAxOQB8CXgQeGdd1Y+OfkEIYVMIYWcIYef09PTCt0CSJLVuqT5Nsx54EngBcBLw52Wv/OO6qvcMV8o5bwW2AkxNTeVFj/I4deaHPtV1CJKkCdJmz8jDwBlD+6c3ZbPWaYZkns1gIuvlwEfrqv52XdVfAT4OrGsxVkmS1JE2k5EdwJqyV64ue+UqYCOwbaTONqBqti8G7q2rOjMYmvlRgLJXTgEvBfotxipJkjrSWjLSzAG5CrgbSMCddVXvKnvl5rJXXtRUew9wctkrdwNvAq5pym8Gnln2yl0Mkpr31VV9f1uxSpKk7rQ6Z6Su6u3A9pGya4e2v8ngMd7R8x6brVySJE2esZKRsld+rK7q849VJrXBZeQlaelLRfxY7Kfzj1U2m6MmI2Wv/C7gGcApZa88CQjNoWdx+GO6kiTpOJOKeDBXSEWcV65wrJ6R1wFvZPCI7aeHvuAbwPxeiaoFN99Hbfde8pIFjkSSdBx6yrnCUZORuqpvAG4oe+XVdVXf+BQClSRJEyj20w3ADamIV8d+mleuMNackbqqbyx75Q8AZw6fU1f1bfP5UkmSNFliP92YinhYrhD76Zi5wrgTWG8H/hlwH4OVUWHw/hiTEUmSRCrivHOFcR/tXQesbRYkkyRJGrUOWBv7ac65wriLnn0OeN5cP1ySJB035p0rjNszcgrwQNkr/xL41kxhXdUXHfkUSZJ0HDkFeCAV8ZBcIfbTMXOFcZOR6+YXlyRJOk5cN98Tx32a5v/O9ws0vvmuFyJJ0mxSES8AbgBWALfGftoycvwEBhNMXww8Alwa+2lvc+wc4N0MFi/7DnBe7KdvHum7Yj/NO1cY92mav2cwIxZgFfB04EBd1c+a7xdLkqT2pCKuYPDi2VcA+4AdqYjbYj89MFTtSmB/7KezUhE3Au8ALk1FXAn8PvAzsZ8+m4p4MvDtY3zfrLlC7Kdj5grj9ox898x22SsDsAF46TjnSpKkTqwHdsd+2gOQingHg/v3cDKygX8cXrkLuCkVMQCvBO6P/fRZgNhPjxzry2I/HcwVms8YO1cY92mag+qqznVV/wHwqrmeK0mSFtTKEMLOoZ9NQ8dOAx4a2t/H4e+KOVgn9tM08HXgZOD7gZyKeHcq4mdSEX9lLkHFfsqxn8bOFcYdpvmJod2nMXiW+IjjRpIkaVFM55zXtfC5K4EfAs4DHgc+lor46dhPHzvSCamI884Vxn2a5jVD29PAXgbdL5IkaWl6GDhjaP/0pmy2OvuaeSLPZjCRdR/wZ7GfvgaQirgdeBFwxGSEp5ArjDtn5OfGqSdJkpaMHcCaVMTVDJKOjcDlI3W2ARXwCeBi4N7YTzkV8W7gV1IRnwE8AfwwcP3Rviz207xzhXGHaU4HbgR+sCn6c+CX6qreN98vVvd8lHhp+OqNY71he8GcevVVi/p9kroR+2k6FfEq4G4Gj/a+N/bTrlTEzcDO2E/bgPcAt6ci7gYeZZCwEPtpfyri7zBIaDKwPfbTR472famIs+YKsZ+OmSuMO0zzPuD9wCXN/mubsleMeb4kSVpksZ+2A9tHyq4d2v4m/3hvHz339xk83juueecK4yYjp9ZV/b6h/f9e9so3ziFASZI02U6N/XRIrpCKOFauMG4y8kjZK18LfKDZv4zBBBdJkiSAR1IR55UrjLvOyL8Ffgr4MvAlBpNcrphbjJIkaYLNO1cYt2dkM1DVVb0foOyVzwXe2XzxEZW98pA18euq3jJy/LA18euq3tscO2xN/LqqXdtEkqSlaTNQxX7aD5CKOFauAOP3jJwzk4gA1FX9KPDCo51Q9sqZNfEvBNYCl5W9cu1ItSuB/XVVn8XgkaF3NOfOrIn/7+uqPht4OcdYE1+SJHXqnJlEBCD20zFzhRnjJiNPK3vlSTM7Tc/IsXpV1gO766reU1f1E8DMmvjDNgC9Zvsu4Pzm3TevBO6vq/qzAHVVP1JX9ZNjxipJkhbf01IRD+YKTc/IWCMw4w7T/DbwibJXfqjZvwR4+zHOmW1N/JccqU5d1dNlrzxkTfyyV94NnArcUVf1b40ZqyRJWny/DXwiFXEuuQIwZs9IXdW3AT8B/L/m5yfqqr59HoGOa2ZN/J9u/vnjZa88f7RSCGHTzMuBpqenWwxHkiQdTeynw3KF2E9j5Qrj9oxQV/UDHPra4WOZ05r4zTyRQ9bEr6v6awBlr5x1Tfyc81ZgK8DU1FSeQ2ySJGmBxX6aa64AjD9nZD52AGvKXrm67JWrGCwxu22kzsya+NCsiV9XdWawdG1Z9spnNEnKDzOPxkmSpKWvtWSkruppYGZN/ATcWVf1rrJXbi575UVNtfcAJ5e9cjfwJuCa5tz9wMya+PcBn6mr+qhr4kuSpOVp7GGa+air+rA18euqvnZo+4hr4tdVPdc18SVJ0jLU5jCNJEnSMbXaMyJ1aceXd8zrvFcvcBySpKOzZ0SSJHXKZESSJHXKZESSJHXKOSNHcct9t3QdgiRJE8+eEUmS1CmTEUmS1CmTEUmS1CmTEUmS1CmTEUmS1CmTEUmS1CmTEUmS1CmTEUmS1CkXPZMkaUKlIl4A3ACsAG6N/bRl5PgJwG3Ai4FHgEtjP+0dOv5PgQeA62I/vbOtOO0ZkSRpAqUirgBuBi4E1gKXpSKuHal2JbA/9tNZwPXAO0aO/w7wh23Has+INOKrN97UdQiStBDWA7tjP+0BSEW8A9jAoKdjxgbgumb7LuCmVMQQ+ymnIv4Y8EXgQNuB2jMiSdJkOg14aGh/X1M2a53YT9PA14GTUxGfCfxn4L8sQpwmI5IkLWMrQwg7h342LdDnXgdcH/vpsQX6vKNymEaSpOVrOue87gjHHgbOGNo/vSmbrc6+VMSVwLMZTGR9CXBxKuJvAc8BvpOK+M3YT62MY5uMSJI0mXYAa1IRVzNIOjYCl4/U2QZUwCeAi4F7Yz9l4F/NVEhFvA54rK1EBBymkSRpIjVzQK4C7gYScGfsp12piJtTES9qqr2HwRyR3cCbgGu6iDXknLv43gU3NTWVDxxY2Am/t9x3y4J+3rGc+aFPLer3aXbnPe+8rkNo1alXX9V1CJIWSAjh8ZzzVNdxPFWtDtOUvfKQxVbqqt4ycvywxVbqqt47dPzgYit1Vbe22MqRmBxIktS+1pKRslfOLLbyCgaPE+0oe+W2uqqHn2++EthfV/VZZa/cyGCxlUuHji/KYivSsB1f3jGv8ya9R0WS2tLmnJH1wO66qvfUVf0EMLPYyrANQK/Zvgs4v+yVAaDslTOLrexqMUZJktSxNpOROS22Ulf1wcVWyl65qIutSJKk7izVp2muA66vq/qoi62EEDbNLPQyPT29OJFJkqQF1WYyMpfFVih75ehiK79V9sq9wBuBXy175WGPAOSct+ac1+Wc161c6ZIpkiQtR23ewXcAa8peOafFVuqqPmSxlbJXXgc8Vle1by+TJGkCtdYz0swBOWSxlbqqd5W9cnPZKw9ZbKXslZ0utiJJkrrjomdHsf0t1YJ+nibbcnm010XPpMkxKYueLdUJrJIk6ThhMiJJkjplMiJJkjplMiJJkjplMiJJkjplMiJJkjrlsqXScearN85v/UAfCZbUFntGJElSp0xGJElSp0xGJElSp0xGJElSp0xGJElSp3yaRlogO768Y17nLZcX7ElSW0xGJLXKR4klHYvDNJIkqVMmI5IkqVMmI5IkqVMmI5IkqVNOYJUkaUKlIl4A3ACsAG6N/bRl5PgJwG3Ai4FHgEtjP+1NRXwFsAVYBTwB/HLsp3vbitOeEUmSJlAq4grgZuBCYC1wWSri2pFqVwL7Yz+dBVwPvKMp/xrwmthPJVABt7cZq8mIJEmTaT2wO/bTnthPTwB3ABtG6mwAes32XcD5qYgh9tNfxX7626Z8F3Bi04vSCodpJOkpcB0VLWGnAQ8N7e8DXnKkOrGfplMRvw6czKBnZMZPAp+J/fSttgJtNRkpe+UhY1V1VW8ZOX7YWFVd1XvLXnnYWFVd1a2NVUldcuVWSU/ByhDCzqH9rTnnrQv14amIZzMYunnlQn3mbFobpil75WFjVWWvnHWsqq7qWceq6qpelLEqSZKWqemc87qhn+FE5GHgjKH905syZquTirgSeDaDzgFSEU8HPgz8bOynL7TVAGh3zsh6YHdd1Xvqqh57rKrslaGu6r+qq/qQsaqmF0WSJI1nB7AmFXF1KuIqYCOwbaTONgb/0w9wMXBv7Kecivgc4CPANbGfPt52oG0mI7ONVZ12pDp1VU8DM2NVw34S+Exd1a2NVUmSNGliP00DVwF3Awm4M/bTrlTEzamIFzXV3gOcnIq4G3gTcE1TfhVwFnBtKuJ9zc/3tBXrkp7AWvbKo45VhRA2AZsAVq1atYiRSZK09MV+2g5sHym7dmj7m8Als5z3NuBtrQfYaLNnZE5jVWWvPGSsquyVB8eq6qqedawq57x1Zpxs5colnVdJkqQjaPMOvgNYU/bK1QySjo3A5SN1ZsaqPkEzVlVXdS575cGxqrqqWx+rknRs832EVZKOpbWekWYOyCFjVXVV7yp75eayVx4yVlX2yiOOVZW98r7mp7WxKkmS1J2Qc+46hgUxNTWVDxw4sKCfuf0t1bErSR2Z9HVGlsuiYC56pi6FEB7POU91HcdT5UQLaZlysTRJk8J300iSpE6ZjEiSpE6ZjEiSpE6ZjEiSpE45gVWSOuBTONI/smdEkiR1ymREkiR1ymREkiR1ymREkiR1ymREkiR1ymREkiR1ykd7JU2USX9kdr7tm6/l8u9Fy5vJiHSc8QV7kpYah2kkSVKnTEYkSVKnTEYkSVKnnDMiaSzONZHUFntGJElSp+wZkdSqefeoLPIjrJqdjxJrMdgzIkmSOmUyIkmSOuUwjaQlyQmz0vGj1WSk7JUXADcAK4Bb66reMnL8BOA24MXAI8CldVXvbY69GbgSeBL4xbqq724zVkmSJk0q4iH34dhPW0aOH3Yfjv20tzl2yH049lNr9+HWkpGyV64AbgZeAewDdpS9cltd1Q8MVbsS2F9X9Vllr9wIvAO4tOyVa4GNwNnAC4A/Lnvl99dV/WRb8UqaDPPtUXn1AschdS0V8bD7cCritthPh92HYz+dlYp48D6cinjYfTgV8ftjP7VyH26zZ2Q9sLuu6j0AZa+8A9gADP9L2ABc12zfBdxU9srQlN9RV/W3gC+WvXJ383mfaDFeScexW+67ZV7nXTLP71suw1DzjXO+TAoX1Hpgd+ynPQCpiGPdh1MRD96HYz99C/hiKmKr9+E2k5HTgIeG9vcBLzlSnbqqp8te+XXg5Kb8kyPnntZeqJI0P4t9s17s71ts800KX3/u6xc4kokwp/tw7KfpVMRO7sPLegJrCGETsKnZzSGEf1jgr1gJTC/wZ3ZhUtoBtmWpWv5t+Y3bYBLa8Y+WZ1sG12HUMdvyBt7QSjgtWOjrcmIIYefQ/tac89YF/PxF0WYy8jBwxtD+6U3ZbHX2lb1yJfBsBhNoxjmX5l94a//SQwg7c87r2vr8xTIp7QDbslRNSlsmpR1gW5aqRW7LnO7DqYhzvg8vlDbXGdkBrCl75eqyV65iMBFm20idbUDVbF8M3FtXdW7KN5a98oSyV64G1gB/2WKskiRNmh3AmlTE1amIY9+HYz8dvA+nIp6Qitj6fbi1ZKSu6mngKuBuIAF31lW9q+yVm8teeVFT7T3Ayc0E1TcB1zTn7gLuZDDJ5qPAG3ySRpKk8cV+Ouw+HPtpVyri5lTEQ+7DzQTVg/fh2E+H3YfbepIGIOSc2/rsZS+EsGk5jr2NmpR2gG1ZqialLZPSDrAtS9UktWUhmYxIkqRO+W4aSZLUqeMyGQkhXBBC+OsQwu4QwjWzHD8hhPDB5vinQghnDh17c1P+1yGEVy1m3LMZoy1vCiE8EEK4P4TwsRDC9w4dezKEcF/zMzqpadGN0ZYrQghfHYr53w0dq0IIf9P8VKPnLqYx2nH9UBs+H0L4u6FjS+2avDeE8JUQwueOcDyEEP5b09b7QwgvGjq2lK7Jsdrx0038dQjhL0II/2Lo2N6m/L6RRyg7MUZbXh5C+PrQ79G1Q8eO+ru52MZoyy8PteNzzd/Hc5tjS+a6hBDOCCH8SfPf2l0hhF+apc6y+FvpTM75uPphsD7/F4DvA1YBnwXWjtR5PfB7zfZG4IPN9tqm/gnA6uZzVizxtvwI8Ixm+xdm2tLsP9b19ZhjW64Abprl3OcCe5p/ntRsn7RU2zFS/2rgvUvxmjTxvAx4EfC5Ixx/NfCHQABeCnxqqV2TMdvxAzPxARfOtKPZ3wuc0vW1mENbXg78n1nK5/S7uRTaMlL3NcC9S/G6AM8HXtRsfzfw+Vn++7Us/la6+jkee0bWA7tzzntyzk8AM8vjDtsA9Jrtu4DzQwgHl8fNOX8r5/xFYGZ53K4csy055z/JOT/e7H6SwbPiS9E41+VIXgXck3N+NOe8H7gHuKClOI9lru24DPjAokQ2DznnPwMePUqVDcBteeCTwHNCCM9naV2TY7Yj5/wXTZywtP9OxrkmR/JU/sZaMce2LNm/lZzzl3LOn2m2/57Bkyujq5Uui7+VrhyPychsy+OO/tIcrJNzngaGl8c91rmLaa7xXMkgM5/xXSGEnSGET4YQfqyNAOdg3Lb8ZNPFeVcIYWZBnqV0XcaOpRkyWw3cO1S8lK7JOI7U3qV0TeZq9O8kA38UQvh0GKz6vBz8yxDCZ0MIfxhCOLspW7bXJITwDAY36P85VLwkr0sYDOu/EPjUyKFJ/FtZMMt6OXiNL4TwWmAd8MNDxd+bc344hPB9wL0hhDrn/IVuIhzL/wY+kHP+VgjhdQx6r36045ieio3AXTnn4Wf3l9s1mSghhB9hkIz80FDxDzXX5HuAe0II/eb/6JeqzzD4PXoshPBq4A8YLFi1nL0G+HjOebgXZcldlxDCMxkkTG/MOX+jy1iWm+OxZ2Quy+MSQuhsedwxjBVPCOFfA28BLso5f2umPOf8cPPPPcCfMsjmu3LMtuScHxmK/1bgxeOeu4jmEstGRrqdl9g1GceR2ruUrslYQgjnMPi92pBzfmSmfOiafAX4MN0OzR5TzvkbOefHmu3twNNDCKewDK/JkKP9rSyJ6xJCeDqDROR/5Jz/1yxVJuZvpRVdT1pZ7B8GvUF7GHSPz0ziOnukzhs4dALrnc322Rw6gXUP3U5gHactL2QwaW3NSPlJwAnN9inA39DhZLYx2/L8oe0fBz7ZbD8X+GLTppOa7ecu1XY09QoGE/DCUr0mQ3GdyZEnS/4bDp2U95dL7ZqM2Y5/ymAO2A+MlE8B3z20/RfABUv8mjxv5veKwQ36web6jPW7uZTa0hx/NoN5JVNL9bo0/35vA951lDrL5m+li5/jbpgm5zwdQphZHncFgycZdoUQNgM7c87bGCyPe3sIYTeDP4KNzbm7Qggzy+NOA+Ql63AAAAJVSURBVG/Ih3axL6ox2/JfgWcCHxrMweXBnPNFQATeHUL4DoMesi055wc6aQhjt+UXQwgXMfh3/yiDp2vIOT8aQvh1Bu9hANicD+3OXTRjtgMGv1N35Oa/Ro0ldU0AQggfYPB0xikhhH3AW4GnA+Scfw/YzuApgd3A48DPNceWzDWBsdpxLYN5Ybc0fyfTefAys38CfLgpWwm8P+f80UVvwJAx2nIx8AshhGngH4CNze/ZrL+bHTThoDHaAoP/8fijnPOBoVOX2nX5QeBngDqEcF9T9qsMktxl9bfSFVdglSRJnToe54xIkqQlxGREkiR1ymREkiR1ymREkiR1ymREkiR1ymRE0hE1byP94tCbUk9q9s8MR3jDcAjhqubNpLlZbEuSjspHeyUdVQjhV4Czcs6bQgjvBvbmnH8zhPBYzvmZs9R/IbCfwQqy63LOX1vciCUtNyYjko6qWeb608B7gZ8Hzs05f/tIycjQeXsxGZE0huNuBVZJc9MkHr8MfBR4Zc75282h7woh7GSwIu6WnPMfdBakpGXNZETSOC4EvgT8c+Cepux7s28YlrQAnMAq6ahCCOcCr2Dwcq//EEJ4PizLNwxLWqJMRiQdURi8iex3gTfmnB9k8OLFdzZP1ZzQ1DmFwYvCOn2pn6Tly2RE0tH8PIM3Pc8MzdzC4O3C5wA7QwifBf6EoTcMhxB+sXkD6+nA/SGEWzuIW9Iy4tM0kiSpU/aMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTv1/9/4w0Q8Ui74AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot_attr(X_train, y_train, \"X51\", trunc=.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We can now see that\n",
    "- When the feature value is greater than 1.25\n",
    "- The associated example indicates the company will go Bankrupt (`Bankrupt` = 1)\n",
    "\n",
    "Just something to keep in mind in performing your own analysis and building your models\n",
    "- Is there value in creating a synthetic feature: `X51 > t` for some threshold `t` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "- Let `t = 1.1`\n",
    "- Set variable `cond_frac_pos` to the fraction of examples that go Bankrupt where `X51 > t`\n",
    "$$\n",
    "\\frac{ \\text{count(Bankrupt == 1 and X51 > t} )} { \\text{count(Bankrupt == 1)} }\n",
    "$$\n",
    "\n",
    "- Set variable `cond_frac_neg` to the fraction of examples that *do not* go Bankrupt where `X51 > t`\n",
    "$$\n",
    "\\frac{ \\text{count(Bankrupt == 0 and X51 > t} )} { \\text{count(Bankrupt == 0)} }\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of training examples that go Bankrupt, with (X51 > 1.10) is 14.4%\n",
      "The fraction of training examples that DO NOT go Bankrupt, with (X51 > 1.10) is 1.6%\n"
     ]
    }
   ],
   "source": [
    "# Set variables\n",
    "#  t: scalar number, threshold\n",
    "#  cond_frac_pos: scalar number, fraction of examples that go bankrupt where X51 > t\n",
    "#  Cond_frac_neg: scalar number, fraction of examples that do not go bankrupt where X51 > t\n",
    "t = 1.1\n",
    "cond_frac_pos = None\n",
    "cond_frac_neg = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def cond_attr(df, attr, trunc=.01, thresh=1):\n",
    "    X = df[attr]\n",
    "    \n",
    "    # Remove outliers, to improve clarity\n",
    "    mask = (X > X.quantile(trunc)) & (X < X.quantile(1-trunc))\n",
    "    X_trunc, y_trunc = X[ mask  ], y_train[ mask ]\n",
    "    \n",
    "    # Condition on value of target and thresh\n",
    "    cp = X_trunc[ (y_trunc == 1) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 1].size\n",
    "    cn = X_trunc[ (y_trunc == 0) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 0].size\n",
    "      \n",
    "    return cp, cn\n",
    "\n",
    "attr = \"X51\"\n",
    "trunc = 0\n",
    "cond_frac_pos, cond_frac_neg = cond_attr(X_train, attr, trunc=trunc, thresh=t)\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"The fraction of training examples that go Bankrupt, with ({attr:s} > {t:2.2f}) is {frac:3.1%}\".format(attr=attr, \n",
    "                                                                                        t=t,\n",
    "                                                                                        frac=cond_frac_pos)\n",
    "     )\n",
    "\n",
    "print(\"The fraction of training examples that DO NOT go Bankrupt, with ({attr:s} > {t:2.2f}) is {frac:3.1%}\".format(attr=attr, \n",
    "                                                                                        t=t,\n",
    "                                                                                        frac=cond_frac_neg)\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-fraction",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "def cond_attr_test(df, attr, trunc=.01, thresh=1):\n",
    "    X = df[attr]\n",
    "    \n",
    "    # Remove outliers, to improve clarity\n",
    "    mask = (X > X.quantile(trunc)) & (X < X.quantile(1-trunc))\n",
    "    X_trunc, y_trunc = X[ mask  ], y_train[ mask ]\n",
    "    \n",
    "    # Condition on value of target and thresh\n",
    "    cp = X_trunc[ (y_trunc == 1) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 1].size\n",
    "    cn = X_trunc[ (y_trunc == 0) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 0].size\n",
    "      \n",
    "    return cp, cn\n",
    "\n",
    "cond_frac_pos_test, cond_frac_neg_test = cond_attr_test(X_train, 'X51', trunc=0, thresh=1.1)\n",
    "\n",
    "assert np.allclose(cond_frac_pos_test, cond_frac_pos)\n",
    "assert np.allclose(cond_frac_neg_test, cond_frac_neg)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "It seems that we can discover a large fraction of examples that go Bankrupt by examining \n",
    "one feature and threshold.\n",
    "\n",
    "But using this alone will result in some number of False Positives (non Bankrupt examples)\n",
    "- And although the percent is small, we will see that the non Bankrupt examples are more numerous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Imbalanced data\n",
    "\n",
    "We have a binary classification problem.\n",
    "\n",
    "Do we have roughly the same number of examples associated with each of the two targets ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "How many training examples do we have that became Bankrupt ?\n",
    "- Set variable `num_bankrupt` to this value\n",
    "\n",
    "How many training examples do we have that *did not become* Bankrupt ?\n",
    "- Set variable `num_nonbankrupt` to this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 4336 total examples: 268 became bankrupt and 4068 did not become bankrupt\n"
     ]
    }
   ],
   "source": [
    "# Set variables\n",
    "#  num_examples: scalar number, number of examples in the training dataset\n",
    "#  num_bankrupt: scalar number, number of examples that became bankrupt\n",
    "#  num_nonbankrupt: scalar number, number of examples that did not become bankrupt\n",
    "num_examples = X_train.shape[0]\n",
    "num_bankrupt = None\n",
    "num_nonbankrupt = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "bankrupt = X_train[ y_train == 1 ] \n",
    "nonbankrupt = X_train[ y_train == 0 ]\n",
    "\n",
    "num_bankrupt    = bankrupt.shape[0]\n",
    "num_nonbankrupt = nonbankrupt.shape[0]\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Of the {t:d} total examples: {b:d} became bankrupt and {nb:d} did not become bankrupt\".format(t=num_examples,\n",
    "                                                                                                    b=num_bankrupt,\n",
    "                                                                                                    nb=num_nonbankrupt)\n",
    "\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "check-imbalance",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "bankrupt_test = X_train[ y_train == 1 ] \n",
    "nonbankrupt_test = X_train[ y_train == 0 ]\n",
    "\n",
    "num_bankrupt_test = bankrupt_test.shape[0]\n",
    "num_nonbankrupt_test = nonbankrupt_test.shape[0]\n",
    "\n",
    "assert num_bankrupt == num_bankrupt_test\n",
    "assert num_nonbankrupt == num_nonbankrupt_test\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This dataset is highly imbalanced: many more examples of one class than the other.\n",
    "\n",
    "Why might this be a problem ?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Consider a naive model that ignores the features and always predicts the *most frequent* value of the target.\n",
    "\n",
    "Assuming the out of sample data has the same distribution as the training data:\n",
    "- We will have perfect conditional accuracy for the examples with target in the majority class\n",
    "- We will have zero conditional accuracy for the examples with target in the non-majority class\n",
    "- Because the number of examples in the majority class is so much larger:\n",
    "    - We might get good unconditional accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Recall our lecture on Recall and Precision.\n",
    "\n",
    "These are metrics that will help us evaluate our model's ability to correctly predict Bankruptcy.\n",
    "\n",
    "We think that you will find that your model may have\n",
    "- High Accuracy\n",
    "- Low Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "There are several ways for you to deal with imbalanced data\n",
    "- Class sensitive weights\n",
    "    - Many models in `sklearn` take an optional argument `class_weight`\n",
    "    - For each target class: you can assign a weight\n",
    "    - The Loss will be computed on a class-weighted basis\n",
    "    - You can choose weights that increase the influence of the non-majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Another way is re-sampling the training set\n",
    "- Expand the number of training examples\n",
    "- By increasing the number of examples of the non-majority class\n",
    "    - Randomly sample examples in the non-majority class\n",
    "    - So you will have duplicates\n",
    "- This creates a more balanced dataset on which to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "These are just some ideas for you to achieve a model with better\n",
    "conditional metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Now submit your assignment!\n",
    "\n",
    "The above steps are an attempt to inspire your own transformations and Exploratory Data Analysis.\n",
    "\n",
    "These will be critical steps in your Final Project, where you will need to build and evaluate your own model for the Classification task of predicting bankruptcy.\n",
    "\n",
    "Please click on the blue button <span style=\"color: blue;\"> **Submit** </span> in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
