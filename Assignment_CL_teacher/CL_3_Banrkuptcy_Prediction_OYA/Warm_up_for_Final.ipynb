{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem description\n",
    "\n",
    "The Final Project will be\n",
    "to predict whether a company will go bankrupt in the following year, based on financial attributes of the company.\n",
    "\n",
    "Perhaps you are contemplating lending money to a company and need to know whether the company is in near-term danger of not being able to repay.\n",
    "\n",
    "This assignment will be a \"warm up\" exercise in advance of the Final Project.\n",
    "We will guide you through some data transformation and Exploratory Data Analysis as a way\n",
    "of inspiring the steps that you will undertake on your own for the Final Project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Goal\n",
    "\n",
    "In previous assignments we provided code that tamed the problem of unruly data, in order to allow you to focus on the *other* steps in the Recipe.  There was also little Exploratory Data Analysis.\n",
    "\n",
    "This assignment will require you to deal with data issues.  It will also make some \"suggestions\" for\n",
    "exploring the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Demonstrate mastery on solving a classification problem and presenting\n",
    "the entire Recipe for Machine Learning process in a notebook.\n",
    "- We will make suggestions for ways to approach the problem\n",
    "    - But there will be little explicit direction for this task.\n",
    "- It is meant to be analogous to a pre-interview task that a potential employer might assign\n",
    "to verify your skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Load the bankruptcy_helper module\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Import bankruptcy_helper module\n",
    "import bankruptcy_helper\n",
    "%aimport bankruptcy_helper\n",
    "\n",
    "helper = bankruptcy_helper.Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# API for students\n",
    "\n",
    "We have defined some utility routines in a file `bankruptcy_helper.py`. There is a class named `Helper` in it.  \n",
    "\n",
    "This will simplify problem solving\n",
    "\n",
    "\n",
    "`helper = bankruptcy_helper.Helper()`\n",
    "\n",
    "\n",
    "\n",
    "- getData: get the training data and holdout data\n",
    "  > `train, holdout = getData()`\n",
    "\n",
    "- plot_attr: Create multiple plots of the distribution of the feature named `attr`, each plot conditioned on a possible value of target/label `y`\n",
    "  >`helper.plot_attr(X, y, attr, trunc)`       \n",
    "\n",
    "  > `X`: DataFrame of features. Each row is an example          \n",
    "  > `y`: DataFrame/ndarray. Label of each example.,      \n",
    "  > `attr`: string.  Name of feature whose distribution will be plotted      \n",
    "  > `trunc`: Scalar. Optional parameter to truncate distribution at a threshold percentage.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Get the data\n",
    "\n",
    "The first step in our Recipe is Get the Data. \n",
    "\n",
    "There are two datasets in this assignment, which are stored in two different directories.\n",
    "\n",
    "- The training data (examples consisting of feature vector/label pairs)\n",
    "    - Stored in the file `train/data.csv`\n",
    "- Holdout data (examples consisting of feature vectors **without** labels)\n",
    "    - Stored in the file `holdout/data.csv`\n",
    "    - Only the instructors have the labels.\n",
    "    - We will evaluate your model performance on this dataset.\n",
    "\n",
    "For the training data\n",
    "- Each example is a row of data corresponding to a single company\n",
    "- There are 64 attributes, described in the section below\n",
    "- The column `Bankrupt`, the label, is 1 if the company subsequently went bankrupt; 0 if it did not go bankrupt\n",
    "- The column `Id` is a Company Identifier\n",
    "\n",
    "The holdout data is identical to the training data with the exception of the absence of `Bankrupt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date shape:  (4818, 66)\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "#  data: training dataset\n",
    "#  holdout: hold out dataset without targets\n",
    "data, holdout = helper.getData()\n",
    "\n",
    "target_attr = \"Bankrupt\" # target attribute in training data, 1 for bankrupt and 0 for not bankrupt\n",
    "\n",
    "n_samples, n_attrs = data.shape\n",
    "print(\"Data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Have a look at the data\n",
    "\n",
    "We will not go through all steps in the Recipe, nor in depth.\n",
    "\n",
    "But here's a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.41769</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>1.1605</td>\n",
       "      <td>-126.39</td>\n",
       "      <td>0.41355</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>1.2395</td>\n",
       "      <td>1.16500</td>\n",
       "      <td>0.51773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049094</td>\n",
       "      <td>0.85835</td>\n",
       "      <td>0.12322</td>\n",
       "      <td>5.6167</td>\n",
       "      <td>7.4042</td>\n",
       "      <td>164.310</td>\n",
       "      <td>2.2214</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0</td>\n",
       "      <td>4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.023834</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.50839</td>\n",
       "      <td>4.2374</td>\n",
       "      <td>22.034</td>\n",
       "      <td>0.058412</td>\n",
       "      <td>-0.027621</td>\n",
       "      <td>3.6579</td>\n",
       "      <td>0.98183</td>\n",
       "      <td>0.76855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031011</td>\n",
       "      <td>1.01850</td>\n",
       "      <td>0.069047</td>\n",
       "      <td>5.7996</td>\n",
       "      <td>7.7529</td>\n",
       "      <td>26.446</td>\n",
       "      <td>13.802</td>\n",
       "      <td>6.4782</td>\n",
       "      <td>0</td>\n",
       "      <td>3537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030515</td>\n",
       "      <td>0.44606</td>\n",
       "      <td>0.19569</td>\n",
       "      <td>1.565</td>\n",
       "      <td>35.766</td>\n",
       "      <td>0.28196</td>\n",
       "      <td>0.039264</td>\n",
       "      <td>0.88456</td>\n",
       "      <td>1.05260</td>\n",
       "      <td>0.39457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077337</td>\n",
       "      <td>0.95006</td>\n",
       "      <td>0.25266</td>\n",
       "      <td>15.049</td>\n",
       "      <td>2.8179</td>\n",
       "      <td>104.730</td>\n",
       "      <td>3.4852</td>\n",
       "      <td>2.6361</td>\n",
       "      <td>0</td>\n",
       "      <td>3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.052318</td>\n",
       "      <td>0.056366</td>\n",
       "      <td>0.54562</td>\n",
       "      <td>10.68</td>\n",
       "      <td>438.2</td>\n",
       "      <td>0.13649</td>\n",
       "      <td>0.058164</td>\n",
       "      <td>10.853</td>\n",
       "      <td>1.02790</td>\n",
       "      <td>0.61173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085524</td>\n",
       "      <td>0.97282</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0157</td>\n",
       "      <td>7.4626</td>\n",
       "      <td>48.756</td>\n",
       "      <td>7.4863</td>\n",
       "      <td>1.0602</td>\n",
       "      <td>0</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.49712</td>\n",
       "      <td>0.12316</td>\n",
       "      <td>1.3036</td>\n",
       "      <td>-71.398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>1.0116</td>\n",
       "      <td>1.29210</td>\n",
       "      <td>0.50288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.99925</td>\n",
       "      <td>0.019736</td>\n",
       "      <td>3.4819</td>\n",
       "      <td>8.582</td>\n",
       "      <td>114.580</td>\n",
       "      <td>3.1854</td>\n",
       "      <td>2.742</td>\n",
       "      <td>0</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2       X3      X4       X5        X6         X7  \\\n",
       "0   0.025417   0.41769   0.0568  1.1605  -126.39   0.41355   0.025417   \n",
       "1  -0.023834    0.2101  0.50839  4.2374   22.034  0.058412  -0.027621   \n",
       "2   0.030515   0.44606  0.19569   1.565   35.766   0.28196   0.039264   \n",
       "3   0.052318  0.056366  0.54562   10.68    438.2   0.13649   0.058164   \n",
       "4   0.000992   0.49712  0.12316  1.3036  -71.398         0   0.001007   \n",
       "\n",
       "        X8       X9      X10  ...        X57      X58       X59     X60  \\\n",
       "0   1.2395  1.16500  0.51773  ...   0.049094  0.85835   0.12322  5.6167   \n",
       "1   3.6579  0.98183  0.76855  ...  -0.031011  1.01850  0.069047  5.7996   \n",
       "2  0.88456  1.05260  0.39457  ...   0.077337  0.95006   0.25266  15.049   \n",
       "3   10.853  1.02790  0.61173  ...   0.085524  0.97282         0  6.0157   \n",
       "4   1.0116  1.29210  0.50288  ...   0.001974  0.99925  0.019736  3.4819   \n",
       "\n",
       "      X61      X62     X63     X64  Bankrupt    Id  \n",
       "0  7.4042  164.310  2.2214   1.334         0  4510  \n",
       "1  7.7529   26.446  13.802  6.4782         0  3537  \n",
       "2  2.8179  104.730  3.4852  2.6361         0  3920  \n",
       "3  7.4626   48.756  7.4863  1.0602         0  1806  \n",
       "4   8.582  114.580  3.1854   2.742         0  1529  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.20839</td>\n",
       "      <td>0.26185</td>\n",
       "      <td>0.41039</td>\n",
       "      <td>2.5692</td>\n",
       "      <td>69.704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20839</td>\n",
       "      <td>2.819</td>\n",
       "      <td>1.641</td>\n",
       "      <td>0.73815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193390</td>\n",
       "      <td>0.28231</td>\n",
       "      <td>0.81043</td>\n",
       "      <td>0</td>\n",
       "      <td>52.04</td>\n",
       "      <td>4.6463</td>\n",
       "      <td>58.171</td>\n",
       "      <td>6.2747</td>\n",
       "      <td>5.0017</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.19877</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>-0.15579</td>\n",
       "      <td>0.83309</td>\n",
       "      <td>-57.414</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.19877</td>\n",
       "      <td>0.067309</td>\n",
       "      <td>0.93406</td>\n",
       "      <td>0.063054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159470</td>\n",
       "      <td>-3.1524</td>\n",
       "      <td>1.20510</td>\n",
       "      <td>0</td>\n",
       "      <td>56.348</td>\n",
       "      <td>1.3163</td>\n",
       "      <td>364.730</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>4.202</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.35741</td>\n",
       "      <td>0.57153</td>\n",
       "      <td>0.34081</td>\n",
       "      <td>1.5991</td>\n",
       "      <td>4.4819</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35741</td>\n",
       "      <td>0.74968</td>\n",
       "      <td>2.6993</td>\n",
       "      <td>0.42847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.83415</td>\n",
       "      <td>0.86775</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6285</td>\n",
       "      <td>7.8131</td>\n",
       "      <td>76.926</td>\n",
       "      <td>4.7448</td>\n",
       "      <td>29.896</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.024312</td>\n",
       "      <td>0.45219</td>\n",
       "      <td>0.011469</td>\n",
       "      <td>1.0393</td>\n",
       "      <td>-831.06</td>\n",
       "      <td>0.006914</td>\n",
       "      <td>0.031273</td>\n",
       "      <td>1.2114</td>\n",
       "      <td>0.88188</td>\n",
       "      <td>0.54781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193770</td>\n",
       "      <td>0.044381</td>\n",
       "      <td>0.82091</td>\n",
       "      <td>0.29244</td>\n",
       "      <td>21.306</td>\n",
       "      <td>3.4388</td>\n",
       "      <td>120.850</td>\n",
       "      <td>3.0202</td>\n",
       "      <td>1.2661</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075494</td>\n",
       "      <td>0.088948</td>\n",
       "      <td>0.56492</td>\n",
       "      <td>7.6065</td>\n",
       "      <td>74.299</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10304</td>\n",
       "      <td>10.243</td>\n",
       "      <td>2.1253</td>\n",
       "      <td>0.91105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037832</td>\n",
       "      <td>0.082864</td>\n",
       "      <td>0.95227</td>\n",
       "      <td>0</td>\n",
       "      <td>15.437</td>\n",
       "      <td>8.391</td>\n",
       "      <td>14.685</td>\n",
       "      <td>24.855</td>\n",
       "      <td>6.0797</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3       X4       X5        X6        X7  \\\n",
       "0   0.20839   0.26185   0.41039   2.5692   69.704         0   0.20839   \n",
       "1  -0.19877    0.9368  -0.15579  0.83309  -57.414         0  -0.19877   \n",
       "2   0.35741   0.57153   0.34081   1.5991   4.4819         0   0.35741   \n",
       "3  0.024312   0.45219  0.011469   1.0393  -831.06  0.006914  0.031273   \n",
       "4  0.075494  0.088948   0.56492   7.6065   74.299         0   0.10304   \n",
       "\n",
       "         X8       X9       X10  ...       X56       X57      X58      X59  \\\n",
       "0     2.819    1.641   0.73815  ...  0.193390   0.28231  0.81043        0   \n",
       "1  0.067309  0.93406  0.063054  ... -0.159470   -3.1524  1.20510        0   \n",
       "2   0.74968   2.6993   0.42847  ...  0.160800   0.83415  0.86775        0   \n",
       "3    1.2114  0.88188   0.54781  ...  0.193770  0.044381  0.82091  0.29244   \n",
       "4    10.243   2.1253   0.91105  ...  0.037832  0.082864  0.95227        0   \n",
       "\n",
       "      X60     X61      X62     X63     X64   Id  \n",
       "0   52.04  4.6463   58.171  6.2747  5.0017  699  \n",
       "1  56.348  1.3163  364.730  1.0007   4.202  539  \n",
       "2  8.6285  7.8131   76.926  4.7448  29.896  867  \n",
       "3  21.306  3.4388  120.850  3.0202  1.2661  595  \n",
       "4  15.437   8.391   14.685  24.855  6.0797  632  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# holdout data\n",
    "holdout.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Pretty *unhelpful* !\n",
    "\n",
    "What are these mysteriously named features ?\n",
    "\n",
    "## Description of attributes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Attribute Information:\n",
    "\n",
    "Id Company Identifier \n",
    "X1 net profit / total assets\n",
    "X2 total liabilities / total assets\n",
    "X3 working capital / total assets\n",
    "X4 current assets / short-term liabilities\n",
    "X5 [(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365\n",
    "X6 retained earnings / total assets\n",
    "X7 EBIT / total assets\n",
    "X8 book value of equity / total liabilities\n",
    "X9 sales / total assets\n",
    "X10 equity / total assets\n",
    "X11 (gross profit + extraordinary items + financial expenses) / total assets\n",
    "X12 gross profit / short-term liabilities\n",
    "X13 (gross profit + depreciation) / sales\n",
    "X14 (gross profit + interest) / total assets\n",
    "X15 (total liabilities * 365) / (gross profit + depreciation)\n",
    "X16 (gross profit + depreciation) / total liabilities\n",
    "X17 total assets / total liabilities\n",
    "X18 gross profit / total assets\n",
    "X19 gross profit / sales\n",
    "X20 (inventory * 365) / sales\n",
    "X21 sales (n) / sales (n-1)\n",
    "X22 profit on operating activities / total assets\n",
    "X23 net profit / sales\n",
    "X24 gross profit (in 3 years) / total assets\n",
    "X25 (equity - share capital) / total assets\n",
    "X26 (net profit + depreciation) / total liabilities\n",
    "X27 profit on operating activities / financial expenses\n",
    "X28 working capital / fixed assets\n",
    "X29 logarithm of total assets\n",
    "X30 (total liabilities - cash) / sales\n",
    "X31 (gross profit + interest) / sales\n",
    "X32 (current liabilities * 365) / cost of products sold\n",
    "X33 operating expenses / short-term liabilities\n",
    "X34 operating expenses / total liabilities\n",
    "X35 profit on sales / total assets\n",
    "X36 total sales / total assets\n",
    "X37 (current assets - inventories) / long-term liabilities\n",
    "X38 constant capital / total assets\n",
    "X39 profit on sales / sales\n",
    "X40 (current assets - inventory - receivables) / short-term liabilities\n",
    "X41 total liabilities / ((profit on operating activities + depreciation) * (12/365))\n",
    "X42 profit on operating activities / sales\n",
    "X43 rotation receivables + inventory turnover in days\n",
    "X44 (receivables * 365) / sales\n",
    "X45 net profit / inventory\n",
    "X46 (current assets - inventory) / short-term liabilities\n",
    "X47 (inventory * 365) / cost of products sold\n",
    "X48 EBITDA (profit on operating activities - depreciation) / total assets\n",
    "X49 EBITDA (profit on operating activities - depreciation) / sales\n",
    "X50 current assets / total liabilities\n",
    "X51 short-term liabilities / total assets\n",
    "X52 (short-term liabilities * 365) / cost of products sold)\n",
    "X53 equity / fixed assets\n",
    "X54 constant capital / fixed assets\n",
    "X55 working capital\n",
    "X56 (sales - cost of products sold) / sales\n",
    "X57 (current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)\n",
    "X58 total costs /total sales\n",
    "X59 long-term liabilities / equity\n",
    "X60 sales / inventory\n",
    "X61 sales / receivables\n",
    "X62 (short-term liabilities *365) / sales\n",
    "X63 sales / short-term liabilities\n",
    "X64 sales / fixed assets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This may still be somewhat unhelpful for those of you not used to reading Financial Statements.\n",
    "\n",
    "But that's partially the point of the exercise\n",
    "- You can *still* perform Machine Learning *even if* you are not an expert in the problem domain\n",
    "    - That's what makes this a good interview exercise: you can demonstrate your thought process even if you don't know the exact meaning of the terms\n",
    "- Of course: becoming an expert in the domain *will improve* your ability to create better models\n",
    "    - Feature engineering is easier if you understand the features, their inter-relationships, and the relationship to the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's get a feel for the data\n",
    "- What is the type of each attribute ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      "X1          4818 non-null object\n",
      "X2          4818 non-null object\n",
      "X3          4818 non-null object\n",
      "X4          4818 non-null object\n",
      "X5          4818 non-null object\n",
      "X6          4818 non-null object\n",
      "X7          4818 non-null object\n",
      "X8          4818 non-null object\n",
      "X9          4818 non-null float64\n",
      "X10         4818 non-null object\n",
      "X11         4818 non-null object\n",
      "X12         4818 non-null object\n",
      "X13         4818 non-null float64\n",
      "X14         4818 non-null object\n",
      "X15         4818 non-null object\n",
      "X16         4818 non-null object\n",
      "X17         4818 non-null object\n",
      "X18         4818 non-null object\n",
      "X19         4818 non-null float64\n",
      "X20         4818 non-null float64\n",
      "X21         4818 non-null object\n",
      "X22         4818 non-null object\n",
      "X23         4818 non-null float64\n",
      "X24         4818 non-null object\n",
      "X25         4818 non-null object\n",
      "X26         4818 non-null object\n",
      "X27         4818 non-null object\n",
      "X28         4818 non-null object\n",
      "X29         4818 non-null object\n",
      "X30         4818 non-null float64\n",
      "X31         4818 non-null float64\n",
      "X32         4818 non-null object\n",
      "X33         4818 non-null object\n",
      "X34         4818 non-null object\n",
      "X35         4818 non-null object\n",
      "X36         4818 non-null object\n",
      "X37         4818 non-null object\n",
      "X38         4818 non-null object\n",
      "X39         4818 non-null float64\n",
      "X40         4818 non-null object\n",
      "X41         4818 non-null object\n",
      "X42         4818 non-null float64\n",
      "X43         4818 non-null float64\n",
      "X44         4818 non-null float64\n",
      "X45         4818 non-null object\n",
      "X46         4818 non-null object\n",
      "X47         4818 non-null object\n",
      "X48         4818 non-null object\n",
      "X49         4818 non-null float64\n",
      "X50         4818 non-null object\n",
      "X51         4818 non-null object\n",
      "X52         4818 non-null object\n",
      "X53         4818 non-null object\n",
      "X54         4818 non-null object\n",
      "X55         4818 non-null float64\n",
      "X56         4818 non-null float64\n",
      "X57         4818 non-null object\n",
      "X58         4818 non-null float64\n",
      "X59         4818 non-null object\n",
      "X60         4818 non-null object\n",
      "X61         4818 non-null object\n",
      "X62         4818 non-null float64\n",
      "X63         4818 non-null object\n",
      "X64         4818 non-null object\n",
      "Bankrupt    4818 non-null int64\n",
      "Id          4818 non-null int64\n",
      "dtypes: float64(16), int64(2), object(48)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "You may be puzzled:\n",
    "- Most attributes are `object` and *not* numeric (`float` or `int`)\n",
    "- But looking at the data via `data.head()` certainly gives the impression that all attributes are numeric\n",
    "\n",
    "Welcome to the world of messy data !  The dataset has represented numbers as strings.\n",
    "- These little unexpected challenges are common in the real-word\n",
    "- Data is rarely perfect and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "So we will first have to convert all attributes to numeric\n",
    "\n",
    "**Question:**\n",
    "\n",
    "Create an all-numeric version of the data.  Assign it to the variable `data` (replacing the original)\n",
    "\n",
    "**Hint:**\n",
    "- Look up the Pandas method `to_numeric`\n",
    "    - We suggest you use the option `errors='coerce'`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "non_numeric_cols = data.select_dtypes(exclude=['float', 'int']).columns\n",
    "data[ non_numeric_cols] = data[ non_numeric_cols ].apply(pd.to_numeric, downcast='float', errors='coerce')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "check-numeric-data",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "assert 'object' not in data.dtypes\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's look at the data again, now that it is numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      "X1          4816 non-null float32\n",
      "X2          4816 non-null float32\n",
      "X3          4816 non-null float32\n",
      "X4          4803 non-null float32\n",
      "X5          4808 non-null float32\n",
      "X6          4816 non-null float32\n",
      "X7          4816 non-null float32\n",
      "X8          4804 non-null float32\n",
      "X9          4818 non-null float64\n",
      "X10         4816 non-null float32\n",
      "X11         4816 non-null float32\n",
      "X12         4803 non-null float32\n",
      "X13         4818 non-null float64\n",
      "X14         4816 non-null float32\n",
      "X15         4812 non-null float32\n",
      "X16         4804 non-null float32\n",
      "X17         4804 non-null float32\n",
      "X18         4816 non-null float32\n",
      "X19         4818 non-null float64\n",
      "X20         4818 non-null float64\n",
      "X21         4744 non-null float32\n",
      "X22         4816 non-null float32\n",
      "X23         4818 non-null float64\n",
      "X24         4702 non-null float32\n",
      "X25         4816 non-null float32\n",
      "X26         4804 non-null float32\n",
      "X27         4513 non-null float32\n",
      "X28         4735 non-null float32\n",
      "X29         4816 non-null float32\n",
      "X30         4818 non-null float64\n",
      "X31         4818 non-null float64\n",
      "X32         4776 non-null float32\n",
      "X33         4803 non-null float32\n",
      "X34         4804 non-null float32\n",
      "X35         4816 non-null float32\n",
      "X36         4816 non-null float32\n",
      "X37         2750 non-null float32\n",
      "X38         4816 non-null float32\n",
      "X39         4818 non-null float64\n",
      "X40         4803 non-null float32\n",
      "X41         4756 non-null float32\n",
      "X42         4818 non-null float64\n",
      "X43         4818 non-null float64\n",
      "X44         4818 non-null float64\n",
      "X45         4598 non-null float32\n",
      "X46         4803 non-null float32\n",
      "X47         4787 non-null float32\n",
      "X48         4816 non-null float32\n",
      "X49         4818 non-null float64\n",
      "X50         4804 non-null float32\n",
      "X51         4816 non-null float32\n",
      "X52         4786 non-null float32\n",
      "X53         4735 non-null float32\n",
      "X54         4735 non-null float32\n",
      "X55         4818 non-null float64\n",
      "X56         4818 non-null float64\n",
      "X57         4816 non-null float32\n",
      "X58         4818 non-null float64\n",
      "X59         4816 non-null float32\n",
      "X60         4598 non-null float32\n",
      "X61         4806 non-null float32\n",
      "X62         4818 non-null float64\n",
      "X63         4803 non-null float32\n",
      "X64         4735 non-null float32\n",
      "Bankrupt    4818 non-null int64\n",
      "Id          4818 non-null int64\n",
      "dtypes: float32(48), float64(16), int64(2)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Hopefully you will see that all the attributes are now numeric.\n",
    "\n",
    "Surprise ! Looks like there are some examples with undefined values for some features !\n",
    "- Why didn't we see this when the data was not encoded as numbers ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "List all the attributes of `data` that are missing from at least one example.\n",
    "- Set list `attrs_missing` to either a list or array of attributes that are missing from at least one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes with values missing for at least some examples\t:\n",
      "\tX1\n",
      "\tX2\n",
      "\tX3\n",
      "\tX4\n",
      "\tX5\n",
      "\tX6\n",
      "\tX7\n",
      "\tX8\n",
      "\tX10\n",
      "\tX11\n",
      "\tX12\n",
      "\tX14\n",
      "\tX15\n",
      "\tX16\n",
      "\tX17\n",
      "\tX18\n",
      "\tX21\n",
      "\tX22\n",
      "\tX24\n",
      "\tX25\n",
      "\tX26\n",
      "\tX27\n",
      "\tX28\n",
      "\tX29\n",
      "\tX32\n",
      "\tX33\n",
      "\tX34\n",
      "\tX35\n",
      "\tX36\n",
      "\tX37\n",
      "\tX38\n",
      "\tX40\n",
      "\tX41\n",
      "\tX45\n",
      "\tX46\n",
      "\tX47\n",
      "\tX48\n",
      "\tX50\n",
      "\tX51\n",
      "\tX52\n",
      "\tX53\n",
      "\tX54\n",
      "\tX57\n",
      "\tX59\n",
      "\tX60\n",
      "\tX61\n",
      "\tX63\n",
      "\tX64\n"
     ]
    }
   ],
   "source": [
    "# Set variable\n",
    "#  attrs_missing: list or array, attributes that are missing from at least one example\n",
    "attrs_missing = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "num_examples = data.shape[0]\n",
    "num_examples_undefined = data.isnull().sum(axis=0)\n",
    "attrs_missing = num_examples_undefined[ num_examples_undefined > 0 ].index.tolist()\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Attributes with values missing for at least some examples\\t:\\n\\t\" + \"\\n\\t\".join(attrs_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "check-missing-data",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "tmp = np.sum(data.isna())\n",
    "attrs_missing_test = tmp[tmp>0].index.tolist()\n",
    "assert set(attrs_missing_test) == set(attrs_missing)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "So it looks like you will have to deal with missing data at some point.\n",
    "\n",
    "We won't do this just now; you will need to address the issue yourself later.\n",
    "\n",
    "But you will hopefully see that our target (`Bankrupt`) is not missing in any example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check if you target is missing any example\n",
    "assert( not target_attr in set(attrs_missing) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The label/target is included in this dataset\n",
    "- It is the attribute `Bankrupt`\n",
    "- Let's separate it from the feature attributes so we don't accidentally train the model with a feature that **is** the target !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (4818, 65)\n"
     ]
    }
   ],
   "source": [
    "data, labels = data.drop(columns=[target_attr]), data[target_attr]\n",
    "print(\"Data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We will shuffle the examples before doing anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape:  (4818,)\n",
      "Label values:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data first\n",
    "data, labels = sklearn.utils.shuffle(data, labels, random_state=42)\n",
    "\n",
    "print(\"Labels shape: \", labels.shape)\n",
    "print(\"Label values: \", np.unique(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Create a test set \n",
    "\n",
    "To train and evaluate a model, we need to split the original dataset into\n",
    "a training subset (in-sample) and a test subset (out of sample).\n",
    "\n",
    "Although **the instructors** are the only ones with the holdout dataset, you probably want\n",
    "to perform out of sample evaluation of your model.\n",
    "So please create a test data set.\n",
    "\n",
    "**Question:**\n",
    "\n",
    "Split the data \n",
    "- Set \n",
    "    - `X_train`: training examples\n",
    "    - `y_train`: labels of the training examples\n",
    "    - `X_test`: test examples\n",
    "    - `y_test`: labels of test examples\n",
    "- 90% will be used for training the model\n",
    "- 10% will be used as validation (out of sample) examples\n",
    "- Use `train_test_split()` from `sklearn` to perform this split\n",
    "    -  Set the `random_state` parameter of `train_test_split()` to be 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (4336, 65)\n",
      "X_test shape: (482, 65)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "# Create variables X_train, X_test, y_train, y_test\n",
    "#   X_train: training examples\n",
    "#   y_train: labels of the training examples\n",
    "#   X_test:  test examples\n",
    "#   y_test:  labels of test examples\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.10, random_state=42)\n",
    "### END SOLUTION\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "check-create-test",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(data, labels, test_size=0.10, random_state=42)\n",
    "assert np.allclose(X_train_, X_train, equal_nan=True)\n",
    "assert np.allclose(y_train_, y_train, equal_nan=True)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "You may want to analyze potential relationships\n",
    "- Between features and the target\n",
    "- Between pairs/groups of features\n",
    "\n",
    "We'll make some suggestions but, ultimately it is up to you.\n",
    "\n",
    "**Warning**\n",
    "\n",
    "We will perform *our* exploration using the **raw** data\n",
    "- Thus, there may be features with missing values\n",
    "- This may affect your analysis\n",
    "- For example: how is the correlation of 2 features computed when there are missing values ?\n",
    "- For the purpose of answering the questions in *this exercise*: leave the missing values in place\n",
    "- For *your Final Project*: feel free to deal with missing features before doing Exploratory Data Analysis\n",
    "\n",
    "**Remember**\n",
    "\n",
    "- Base your analysis on `X_train`, don't peek at your out of sample data !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Features correlated with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "List the 5 features whose correlation with the target are largest (most positive).\n",
    "\n",
    "\n",
    "- Set variable `corr_features`\n",
    "    - To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "    - Most highly correlated with `Bankrupt`\n",
    "    - In *descending order*\n",
    "\n",
    "**Hint:**\n",
    "- Look up the Pandas `corr` method\n",
    "- Look up the Pandas `sort_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features most correlated with target:  ['X2', 'X51', 'X32', 'X9', 'X36']\n"
     ]
    }
   ],
   "source": [
    "# Set variable\n",
    "#  corr_features: list or array, 5 features whose correlations with target are largest\n",
    "corr_features = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# Put target back with data to facilitate correlation\n",
    "df = X_train.copy()\n",
    "df[ target_attr ] = y_train\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "target_corr = corr_matrix['Bankrupt'].sort_values(ascending = False)\n",
    "corr_features = target_corr.index[ 1:6 ].tolist()\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Features most correlated with target: \", corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "check-target-correlation",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "df_test = X_train.copy()\n",
    "df_test[ target_attr ] = y_train\n",
    "corr_matrix_test = df_test.corr()\n",
    "\n",
    "target_corr_test = corr_matrix_test['Bankrupt'].sort_values(ascending = False)\n",
    "corr_features_test = target_corr_test.index[ 1:6 ].tolist()\n",
    "\n",
    "assert list(corr_features) == corr_features_test\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Mutually correlated features\n",
    "\n",
    "When you have a lot of features, you might discover that some of them convey little information\n",
    "- Pairs of highly correlated features: a redundant feature conveys little additional information\n",
    "- A small number of features that adequately represent the whole\n",
    "    - In the Unsupervised Learning lecture, we will learn about PCA, a way to discover a small set of synthetic features that capture the whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Questions:**\n",
    "\n",
    "- List the 5 features whose correlations with feature `X1` are largest (most positive).\n",
    "    - Set variable `X1_corr_p`\n",
    "        - To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "        - Most highly correlated\n",
    "        - In *descending order*\n",
    "    \n",
    "- List the 5 features whose correlations with feature `X1` are *most negative*.\n",
    "    - Set variable `X1_corr_n`\n",
    "        - To be a list or array with the names (e.g., `X3`) of the 5 features\n",
    "        - Most highly *negatively* correlated\n",
    "        - In *ascending order* (most negative first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features most positively correlated with X1 ['X7', 'X14', 'X11', 'X22', 'X35']\n",
      "Features most negatively correlated with X1 ['X36', 'X38', 'X10', 'X25', 'X53']\n"
     ]
    }
   ],
   "source": [
    "# Set varaibels\n",
    "#  X1_corr_p: list or array, 5 features whose correlations with target are most positive\n",
    "#  X1_corr_n: list or array, 5 features whose correlations with target are most negative\n",
    "X1_corr_p = None\n",
    "X1_corr_n = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# Put target back with data to facilitate correlation\n",
    "df = X_train.copy()\n",
    "df[ target_attr ] = y_train\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "X1_corr = corr_matrix['X1'].sort_values(ascending = False)\n",
    "\n",
    "X1_corr_p = X1_corr.index[ 1: 6].tolist()\n",
    "X1_corr_n = X1_corr.index[ -1: - 6 : -1 ].tolist()\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Features most positively correlated with X1\", X1_corr_p)\n",
    "print(\"Features most negatively correlated with X1\", X1_corr_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "check-X1-correlation",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "X1_corr_test = corr_matrix_test['X1'].sort_values(ascending = False)\n",
    "\n",
    "X1_corr_p_test = X1_corr_test.index[ 1: 6].tolist()\n",
    "X1_corr_n_test = X1_corr_test.index[ -1: - 6 : -1 ].tolist()\n",
    "\n",
    "assert X1_corr_p_test == list(X1_corr_p)\n",
    "assert X1_corr_n_test == list(X1_corr_n)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "One thing to consider (we saw something similar in the lecture topic on Influential Points)\n",
    "- Outliers (feature values that are at the extremes of the distribution) can affect correlation\n",
    "\n",
    "To illustrate:\n",
    "- We will show the distribution of one feature, conditional on the value of the associated target value\n",
    "- Here we overlay two distributions\n",
    "    - The distribution of the feature value, conditioned on examples having target 0 (colored green)\n",
    "    - The distribution of the feature value, conditioned on examples having target 1 (colored red)\n",
    "    - When the two distributions overlap: the color will be a blend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot_attr(X_train, y_train, \"X51\", trunc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The above graph is not very informative\n",
    "- The distributions overlap for the bins chosen\n",
    "- But there seem to be many bins with very few values (i.e. X51 > 2)\n",
    "\n",
    "But let's perform the same plot while *eliminating* extreme values of the feature\n",
    "- Eliminate examples with the value of the feature in the upper and lower 1 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAEICAYAAACNqfTZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dfZgdV33Y8e9BQo5ZAhjbKWA7QamVzsgdlxdZpElKCC5g0wcrCXYsOyRD6kZJQE4obVJIqCECEpGSGtcvCaqBjknBGLXkUYuC4+AkTXmLBBgP8rkhQuixhaEYS4FYDpi1T/+4s+Lqald7d7Wzs3v1/TzPPp6Xc/b+jkbX89M5Z86ElBKSJEldeVzXAUiSpJObyYgkSeqUyYgkSeqUyYgkSeqUyYgkSeqUyYgkSerUyq4DkCRJ7YhZfhFwHbACuDnvxa1D558PvAM4H9iY9+L25vizgD8AngQ8Crw178UPtBXn2CQjj3vc49Kpp57adRiSJC2ahx9+OKWUph3liFm+ArgReBFwANgVs3xH3ov3DBS7F3gl8O+HfzXw83kv/m3M8mcAn45Zfnvei3+34I1gjJKRU089lcOHD3cdhiRJiyaE8A/HOb0e2Jv34j6AmOW3AhuAI8lI3ov7m3OPDVbMe/ELA9v3xyz/GnAm0Eoy4pwRSZLG01nAfQP7B5pjcxKzfD2wCvjiAsV1jLHpGZEk6SS0MoSwe2B/W0ppW7Mdpik/p3fAxCx/OvBeoMx78bHZys+XyYgkScvXZEpp3QznDgDnDOyfDdw/6i+OWf4k4MPAG/Je/OT8Q5ydyYgkSeNpF7AmZvlq4MvARuDKUSrGLF8FfAi4Je/FD7YXYl8Yl7f2TkxMJCewSpJOJiGEh1NKEzOdj1n+UvqP7q4A3p334ltjlm8Bdue9uCNm+QX0k47TgG8BX8178byY5a8A3gPsGfh1r8x78a5W2mEyIknS8jRbMrJc+DSNJEnqlMmIJEnqlMmIJEnqlE/TjIGb7rppXvVe9axXLXAkx/fA9TfMq96ZV29e4EgkSUuJPSOSJKlT9owsIfPt4ZAkaTmzZ0SSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHXKZESSJHWq1eXgi6q4CLgOWAHcXJf11qHzzwfeAZwPbKzLentz/FnAHwBPAh4F3lqX9QfajFWSJHWjtZ6RoipWADcCFwNrgSuKqlg7VOxe4JXA+4aOPwz8fF3W5wEXAe8oquIpbcUqSZK602bPyHpgb13W+wCKqrgV2ADcM1WgLuv9zbnHBivWZf2Fge37i6r4GnAm8HctxitJkjrQ5pyRs4D7BvYPNMfmpKiK9cAq4IsLFJckSVpC2uwZCdMcS3P5BUVVPB14L1DWZf3Y8PkQwiZgE8CqVavmE+NJ7aa7bppXvVc961ULHIkk6WTWZs/IAeCcgf2zgftHrVxUxZOADwNvqMv6k9OVSSltSymtSymtW7my1bm4kiSpJW3ewXcBa4qqWA18GdgIXDlKxaIqVgEfAm6py/qD7YUoSZK61lrPSF3Wk8Bm4HYgArfVZb2nqIotRVVcAlBUxQVFVRwALgPeWVTFnqb6zwDPB15ZVMVdzc+z2opVkiR1J6Q0p2kcS9bExEQ6fPhw12GckPnO4Vhs850z8sD1N8yr3plXb55XPUkadyGEh1NKE13HcaKcaKElzyRGksaby8FLkqRO2TMiSdKYill+1GtZ8l7cOnT+qNey5L24feBcCbyh2X1L3otVW3HaMyJJ0hiKWX7Ma1lilo/0WpaY5U8F3gg8j/6K6m+MWX5aW7GajEiSNJ7WA3vzXtyX9+IjwNRrWY7Ie3F/3ot3A8MLi74EuCPvxYN5Lx4C7qD/rrhWmIxIkjSeTuS1LAvySpdROWdEkqTla2UIYffA/raU0rZm+0Rey3LCr3SZC5MRSZKWr8mU0roZzp3Ia1kOAC8YqvsXcw1uVCYjkiSNp13Ampjlc34tC/3V039nYNLqi4HXL3yIfc4ZkSRpDOW9eMxrWfJe3BOzfEvM8ksAYpZfELP8yGtZYpbvaeoeBN5MP6HZBWxpjrXCnhFJksZU3os7gZ1Dx64Z2N5FfwhmurrvBt7daoANe0YkSVKnTEYkSVKnTEYkSVKnTEYkSVKnnMDagpvuuqnrECRJWjbsGZEkSZ0yGZEkSZ0yGZEkSZ0yGZEkSZ0yGZEkSZ0yGZEkSZ0yGZEkSZ1qdZ2RoiouAq4DVgA312W9dej884F3AOcDG+uy3j5wrgTe0Oy+pS7rqs1YNbr5rqNy2QLHIUkaD631jBRVsQK4EbgYWAtcUVTF2qFi9wKvBN43VPepwBuB5wHrgTcWVXFaW7FKkqTutDlMsx7YW5f1vrqsHwFuBTYMFqjLen9d1ncDjw3VfQlwR13WB+uyPgTcAVzUYqySJKkjbSYjZwH3DewfaI61XVeSJC0jbc4ZCdMcSwtZN4SwCdgEsGrVqtEjkyRJS0abPSMHgHMG9s8G7l/IuimlbSmldSmldStX+s4/SZKWozbv4LuANUVVrAa+DGwErhyx7u3A7wxMWn0x8PqFD1GSJHWttZ6Ruqwngc30E4sI3FaX9Z6iKrYUVXEJQFEVFxRVcYD+U5/vLKpiT1P3IPBm+gnNLmBLc0ySJI2ZkNKo0ziWtomJiXT48OGuwwDmvw7HuLvsr4YfmmrXmVdvXtTPk6TFFkJ4OKU00XUcJ8oVWCVJUqdMRiRJUqdMRiRJUqdMRiRJUqdMRiRJUqdMRiRJUqdctlSSpDEVs/wi4DpgBXBz3otbh86fAtwCPBd4ELg878X9McsfD9wMPId+rnBL3ou/21ac9oxIkjSGYpavAG4ELgbWAlfELF87VOwq4FDei+cC1wJva45fBpyS92JBP1H5pZjlz2wrVpMRSZLG03pgb96L+/JefAS4FdgwVGYDUDXb24ELY5YH+i+nnYhZvhI4FXgE+GZbgZqMSJI0ns4C7hvYP9Acm7ZM3ouTwDeA0+knJoeBrwD3Am/Pe7G117KYjEiStHytDCHsHvjZNHAuTFN++B0wM5VZDzwKPANYDfy7mOU/uCART8MJrJIkLV+TKaV1M5w7AJwzsH82cP8MZQ40QzJPBg4CVwIfyXvxO8DXYpZ/DFgH7FvI4KeYjEgL5IHrb5hXPV/oJ6klu4A1MctXA18GNtJPMgbtAErgE8ClwJ15L6aY5fcCL4xZ/kfAE4AfBt7RVqAO00iSNIaaOSCbgduBCNyW9+KemOVbYpZf0hR7F3B6zPK9wGuB1zXHbwSeCHyeflLznrwX724rVntGJEkaU3kv7gR2Dh27ZmD7W/Qf4x2u99B0x9tiz4gkSeqUyYgkSeqUyYgkSeqUyYgkSeqUyYgkSeqUT9NobLnuhyQtDyYjWjS7vrprXvUueNoFCxyJJGkpcZhGkiR1qtWekaIqLgKuA1YAN9dlvXXo/CnALcBzgQeBy+uy3l9UxeOBm4HnNDHeUpf177YZqyRJ6kZrPSNFVaygv5zsxcBa4IqiKtYOFbsKOFSX9bnAtcDbmuOXAafUZV3QT1R+qaiKZ7YVqyRJ6k6bwzTrgb11We+ry/oR4FZgw1CZDUDVbG8HLiyqItB/ffFEURUrgVOBR4BvthirJEnqSJvJyFnAfQP7B5pj05apy3oS+AZwOv3E5DDwFeBe4O11WR8c/oAQwqYQwu4Qwu7JycmFb4EkSWpdm3NGwjTH0ohl1gOPAs8ATgP+qqiKP6vLet9RBVPaBmwDmJiYGP7daskzP/iprkOQJI2RNntGDgDnDOyfDdw/U5lmSObJwEHgSuAjdVl/py7rrwEfA9a1GKskSepIm8nILmBNURWri6pYBWwEdgyV2QGUzfalwJ11WSf6QzMvLKoiFFUxAfww0GsxVkmS1JHWkpFmDshm4HYgArfVZb2nqIotRVVc0hR7F3B6URV7gdcCr2uO3wg8Efg8/aTmPXVZ391WrJIkqTutrjNSl/VOYOfQsWsGtr9F/zHe4XoPTXdckiSNn5GSkaIqPlqX9YWzHZPa4DLykrT0xSz/aN6LF852bDrHTUaKqvge4AnAGUVVnMZ3n355Ev0nXSRJ0kksZvmRXCFm+bxyhdl6Rn4JeE3zyz498AHfpD+vQ0vAfB+13X/Z8xY4EknSSeiEc4XjJiN1WV8HXFdUxdV1WV9/AoFKkqQxlPfidcB1McuvzntxXrnCSHNG6rK+vqiKHwGeOVinLutb5vOhkiRpvOS9eH3M8mNyhbwXZ80VRp3A+l7gHwN30V8ZFforpZqMSJIkYpbPO1cY9dHedcDaZkEySZKkYeuAtXkvzjlXGHXRs88DT5vrL5ckSSeNeecKo/aMnAHcU1TFXwPfnjpYl/UlM1eRJEknkTOAe2KWH5Ur5L04a64wajLypvnFJUmSThJvmm/FUZ+m+cv5foBGN9/1QiRJmk7M8ouA64AVwM15L24dOn8K/QmmzwUeBC7Pe3F/c+584J30Fy97DLgg78VvzfRZeS/OO1cY9Wmav6c/IxZgFfB44HBd1k+a7wdLkqT2xCxfQX/RsRcBB4BdMct35L14z0Cxq4BDeS+eG7N8I/A24PKY5SuBPwJ+Lu/Fz8UsPx34ziyfN22ukPfirLnCqD0j3zu4X1TFTwLrR6krSZI6sR7Ym/fiPoCY5bcCG4DBZGQD3x1e2Q7cELM8AC8G7s578XMAeS8+ONuH5b14VK4Qs3zkXGHUp2mOUpf1HwMvnE9dSZK0YFaGEHYP/GwaOHcWcN/A/oHmGNOVyXtxEvgGcDrwQ0CKWX57zPLPxCz/jbkGlvfiyLnCqMM0Pz2w+zj6zxK75ogkSd2aTCmtm+FcmObY8L17pjIrgR8DLgAeBj4as/zTeS9+dKZAYpbPO1cY9Wmalw1sTwL76XftSJKkpekAcM7A/tnA/TOUOdDME3kycLA5/pd5L34dIGb5TuA5wIzJCCeQK4w6Z+QXRiknSZKWjF3Ampjlq4EvAxuBK4fK7ABK4BPApcCdeS+mmOW3A78Rs/wJwCPAjwPXHu/D8l6cd64w6jDN2cD1wI/S73L5v8Cv1WV9YL4frO75KPHS8MD1Nyzq55159eZF/TxJ3ch7cTJm+WbgdvqP9r4778U9Mcu3ALvzXtwBvAt4b8zyvfR7RDY2dQ/FLP/P9BOaBOzMe/HDx/u8mOXT5gp5L86aK4w6TPMe4H3AZc3+K5pjLxqxviRJWmR5L+4Edg4du2Zg+1t8994+XPeP6D/eO6p55wqjJiNn1mX9noH9/1ZUxWvmEKAkSRpvZ+a9eFSuELN8pFxh1GTk60VVvAJ4f7N/Bf2V2iRJkgC+HrN8XrnCqOuM/GvgZ4CvAl+hP8nFSa2SJGnKvHOFUXtG3gyUdVkfAiiq4qnA25sPnlFRFUetiV+X9dah88esiV+X9f7m3DFr4tdlPeOa+JIkqVNvBsq8Fw8BxCwfKVeA0XtGzp9KRADqsj4IPPt4FYqqmFoT/2JgLXBFURVrh4pdBRyqy/pc+o8Mva2pO7Um/i/XZX0e8AJmWRNfkiR16vypRAQg78VZc4UpoyYjjyuq4rSpnaZnZLZelfXA3rqs99Vl/QgwtSb+oA1A1WxvBy4squLImvh1WX8OoC7rB+uyfnTEWCVJ0uJ7XMzyI7lC0zMy0gjMqMM0vw98vKiK7fSfHf4Z4K2z1JluTfznzVSmLuvJoiqOWhO/qIrbgTOBW+uy/r0RY5UkSYvv94GPxyyfS64AjNgzUpf1LcDLgf8HPAD8dF3W752l2kKsif+zzX9/qqiKC4/5gBA2Tb0caHJycpZwJElSW/JePCZXyHtxtlwBGL1nhLqs7+Ho1w7PZk5r4jfzRI5aE78u668DFFUx7Zr4KaVtwDaAiYkJX9wnSVKH8l6ca64AjD5nZD52AWuKqlhdVMUq+kvM7hgqM7UmPjRr4tdlnegvXXt+URVPaJKUH2cejZMkSUtfa8lIXdaTwNSa+BG4rS7rPUVVbCmq4pKm2LuA04uq2Au8FnhdU/cQMLUm/l3AZ+qyPu6a+JIkaXkaeZhmPuqyPmZN/LqsrxnYnnFN/Lqs57omviRJWobaHKaRJEmaVas9I1KXdn1117zqvXSB45AkHZ89I5IkqVMmI5IkqVMmI5IkqVPOGTmOm+66qesQJEkae/aMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTpmMSJKkTrnomSRJYypm+UXAdcAK4Oa8F7cOnT8FuAV4LvAgcHnei/sHzn8/cA/wprwX395WnPaMSJI0hmKWrwBuBC4G1gJXxCxfO1TsKuBQ3ovnAtcCbxs6fy3wJ23Has+INOSB62/oOgRJWgjrgb15L+4DiFl+K7CBfk/HlA3Am5rt7cANMctD3ospZvlPAvuAw20Has+IJEnj6SzgvoH9A82xacvkvTgJfAM4PWb5BPAfgN9ehDhNRiRJWsZWhhB2D/xsGjgXpimfhvZnKvPbwLV5Lz60UIEej8M0kiQtX5MppXUznDsAnDOwfzZw/wxlDsQsXwk8GTgIPA+4NGb57wFPAR6LWf6tvBdbGcc2GZEkaTztAtbELF8NfBnYCFw5VGYHUAKfAC4F7sx7MQH/YqpAzPI3AQ+1lYiAwzSSJI2lZg7IZuB2IAK35b24J2b5lpjllzTF3kV/jshe4LXA67qINaQ0PHy0PE1MTKTDhxd2wu9Nd920oL9vNs/84KcW9fM0vQuedkHXIbTqzKs3dx2CpAUSQng4pTTRdRwnqtVhmqIqjlpspS7rrUPnj1lspS7r/QPnjyy2Upd1a4utzMTkQJKk9rWWjBRVMbXYyovoT5DZVVTFjrqsB59vvgo4VJf1uUVVbKS/2MrlA+cXZbEVadCur+6aV71x71GRpLa0OWdkPbC3Lut9dVk/AkwttjJoA1A129uBC4uqCABFVUwttrKnxRglSVLH2kxG5rTYSl3WRxZbKapiURdbkSRJ3WkzGTnhxVbqsj7uYishhE1TC71MTk7OM0xJktSlNpORuSy2QlEVw4ut/F5RFfuB1wC/WVTFMY8ApJS2pZTWpZTWrVzpkimSJC1Hbd7BdwFriqqY02IrdVkftdhKURVvAh6qy9q3l0mSNIZa6xlp5oActdhKXdZ7iqrYUlTFUYutFFXR6WIrkiSpOy56dhw7f6tc0N+n8bZcHu110TNpfIzLomcuBy9JkjplMiJJkjplMiJJkjplMiJJkjplMiJJkjplMiJJkjrlsqXSSeaB6+e3fqCPBEtqiz0jkiSpUyYjkiSpUyYjkiSpUyYjkiSpUyYjkiSpUz5NIy2QXV/dNa96y+UFe5LUFpMRSa3yUWJJs3GYRpIkdcpkRJIkdcpkRJIkdcpkRJIkdcoJrJIkjamY5RcB1wErgJvzXtw6dP4U4BbgucCDwOV5L+6PWf4iYCuwCngE+PW8F+9sK057RiRJGkMxy1cANwIXA2uBK2KWrx0qdhVwKO/Fc4Frgbc1x78OvCzvxQIogfe2GavJiCRJ42k9sDfvxX15Lz4C3ApsGCqzAaia7e3AhTHLQ96Ln8178f7m+B7ge5pelFY4TCNJJ8B1VLSEnQXcN7B/AHjeTGXyXpyMWf4N4HT6PSNTXg58Nu/Fb7cVaKvJSFEVR41V1WW9dej8MWNVdVnvL6rimLGquqxbG6uSuuTKrZJOwMoQwu6B/W0ppW3NdpimfBraP26ZmOXn0R+6efEJRTmL1oZpiqo4ZqyqqIppx6rqsp52rKou60UZq5IkaZmaTCmtG/jZNnDuAHDOwP7ZwP1HV/9umZjlK4EnAweb/bOBDwE/n/fiF9tqALQ7Z2Q9sLcu6311WY88VlVURajL+rN1WR81VtX0okiSpNHsAtbELF8ds3wVsBHYMVRmB/1/9ANcCtyZ92KKWf4U4MPA6/Ne/FjbgbaZjEw3VnXWTGXqsp4EpsaqBr0c+Gxd1q2NVUmSNG7yXpwENgO3AxG4Le/FPTHLt8Qsv6Qp9i7g9Jjle4HXAq9rjm8GzgX+Y8zyu5qf72sr1jbnjJzwWFVRFccdqwohbAI2AaxatWp+UUqSNKbyXtwJ7Bw6ds3A9reAy6ap9xbgLa0H2GizZ2ROY1VFVRw1VlVUxZGxqrqspx2rSiltmxonW7nSB4MkSVqO2ryD7wLWFFWxGvgy/bGqK4fKTI1VfYJmrKou61RUxZGxqrqsWx+rkjS7+T7CKkmzaa1npJkDctRYVV3We4qq2FJUxVFjVUVVzDhWVVTFXc1Pa2NVkiSpOyGl4Wkcy9PExEQ6fPjwgv7Onb9Vzl5I6si4rzOyXBYFc9EzdSmE8HBKaaLrOE6UEy2kZcrF0iSNC99NI0mSOmUyIkmSOmUyIkmSOmUyIkmSOuUEVknqgE/hSN9lz4gkSeqUyYgkSeqUyYgkSeqUyYgkSeqUyYgkSeqUyYgkSeqUj/ZKGivj/sjsfNs3X8vlz0XLm8mIdJLxBXuSlhqHaSRJUqdMRiRJUqdMRiRJUqecMyJpJM41kdQWe0YkSVKn7BmR1Kp596gs8iOsmp6PEmsx2DMiSZI6ZTIiSZI65TCNpCXJCbPSyaPVZKSoiouA64AVwM11WW8dOn8KcAvwXOBB4PK6rPc3514PXAU8CvxqXda3txmrJEnjJmb5UffhvBe3Dp0/5j6c9+L+5txR9+G8F1u7D7eWjBRVsQK4EXgRcADYVVTFjrqs7xkodhVwqC7rc4uq2Ai8Dbi8qIq1wEbgPOAZwJ8VVfFDdVk/2la8ksbDfHtUXrrAcUhdi1l+zH04ZvmOvBePuQ/nvXhuzPIj9+GY5cfch2OW/1Dei63ch9vsGVkP7K3Leh9AURW3AhuAwT+EDcCbmu3twA1FVYTm+K11WX8b+FJRFXub3/eJFuOVdBK76a6b5lXvsnl+3nIZhppvnPNlUrig1gN7817cBxCzfKT7cMzyI/fhvBe/DXwpZnmr9+E2k5GzgPsG9g8Az5upTF3Wk0VVfAM4vTn+yaG6Z7UXqiTNz2LfrBf78xbbfJPCVz3rVQscyViY030478XJmOWd3IfbTEbCNMfSiGVGqUsIYROwaep8COEf5hTh7FYCkwv8O7swLu0A27JULf+2/M4tMA7t+K7l2Zb+dRg2a1tezatbCacFC31dTg0h7B7Y35ZS2tZst34fXihtJiMHgHMG9s8G7p+hzIGiKlYCTwYOjliX5g982/DxhRJC2J1SWtfW718s49IOsC1L1bi0ZVzaAbZlqVrktszpPhyzfM734YXS5joju4A1RVWsLqpiFf2JMDuGyuwAymb7UuDOuqxTc3xjURWnFFWxGlgD/HWLsUqSNG52AWtilq+OWT7yfTjvxSP34Zjlp8Qsb/0+3FoyUpf1JLAZuB2IwG11We8pqmJLURWXNMXeBZzeTFB9LfC6pu4e4Db6k2w+ArzaJ2kkSRpd3ovH3IfzXtwTs3xLzPKj7sPNBNUj9+G8F4+5D7f1JA1ASKm1IaBlL4SwaWDsbdkal3aAbVmqxqUt49IOsC1L1Ti1ZSGZjEiSpE75bhpJktSpkzIZCSFcFEL4mxDC3hDC66Y5f0oI4QPN+U+FEJ45cO71zfG/CSG8ZDHjns4IbXltCOGeEMLdIYSPhhB+YODcoyGEu5qf4UlNi26EtrwyhPDAQMz/ZuBcGUL42+anHK67mEZox7UDbfhCCOHvBs4ttWvy7hDC10IIn5/hfAgh/JemrXeHEJ4zcG4pXZPZ2vGzTfx3hxA+HkL4ZwPn9ocQ6uaa7J6u/mIaoS0vCCF8Y+Dv0TUD5477d3OxjdCWXx9ox+eb78dTm3NL5rqEEM4JIfx5CCGGEPaEEH5tmjLL4rvSmZTSSfVDf33+LwI/CKwCPgesHSrzKuAPm+2NwAea7bVN+VOA1c3vWbHE2/ITwBOa7V+Zakuz/1DX12OObXklcMM0dZ8K7Gv+e1qzfdpSbcdQ+auBdy/Fa9LE83zgOcDnZzj/UuBP6K9J8MPAp5baNRmxHT8yFR9w8VQ7mv39wBldX4s5tOUFwP+e5vic/m4uhbYMlX0ZcOdSvC7A04HnNNvfC3xhmv9/LYvvSlc/J2PPyHpgb0ppX0rpEWBqedxBG4Cq2d4OXBhCOLI8bkrp2ymlLwFTy+N2Zda2pJT+PKX0cLP7SfrPii9Fo1yXmbwEuCOldDCldAi4A7iopThnM9d2XAG8f1Eim4eU0v+hv+bATDYAt6S+TwJPCSE8naV1TWZtR0rp402csLS/J6Nck5mcyHesFXNsy5L9rqSUvpJS+kyz/ff0n1wZXq10WXxXunIyJiPTLY87/JfmSJmU0iQwuDzubHUX01zjuYp+Zj7le0IIu0MInwwh/GQbAc7BqG15edPFuT2EMLUgz1K6LiPH0gyZrQbuHDi8lK7JKGZq71K6JnM1/D1JwJ+GED4d+qs+Lwf/PITwuRDCn4QQzmuOLdtrEkJ4Av0b9P8YOLwkr0voD+s/G/jU0Klx/K4smDZXYF2qls3yuCMYOZ4QwiuAdcCPDxz+/pTS/SGEHwTuDCHUKaUvthDnKEZpy/8C3p9S+nYI4Zfp9169cMS6i2UusWwEtqeUBp/dX0rXZBTL5bsykhDCT9BPRn5s4PCPNtfk+4A7Qgi95l/0S9VngB9IKT0UQngp8Mf0F6xaltek8TLgYymlwV6UJXddQghPpJ8wvSal9M3h09NUWbbflYV2MvaMzGV5XEIInS2PO4KR4gkh/Evgt4BLUkrfnjqeUrq/+e8+4C/oZ/NdmbUtKaUHB+L/r8BzR627iOYSy0aGup2X2DUZxUztXUrXZCQhhPOBm4ENKaUHp44PXJOvAR+i26HZWaWUvplSeqjZ3gk8PoRwBsvwmgw43ndlSVyXEMLj6Sci/z2l9D+nKTI235VWdD1pZbF/6PcG7aPfPT41ieu8oTKv5ugJrLc12+dx9ATWfXQ7gXWUtjyb/qS1NUPHTwNOabbPAP6WDiezjdiWpw9s/xTwyWb7qcCXmjad1mw/dam2oyn3T+hPwAtL9ZoMxPVMZp4s+a84elLeXy+1azJiO76f/hywHxk6PgF878D2x/okfOYAAAKxSURBVIGLlvg1edrU3yv6N+h7m+sz0t/NpdSW5vzUPwYnlup1af58bwHecZwyy+a70sXPSTdMk1KaDCFMLY+7gv6TDHtCCFuA3SmlHfSXx31vCGEv/S/BxqbunhDC1PK4k8Cr09Fd7ItqxLb8J+CJwAf7c3C5N6V0CZAD7wwhPEa/h2xrSumeThrCyG351RDCJfT/7A/Sf7qGlNLBEMKb6b+HAWBLOro7d9GM2A7oT8a7NTX/N2osqWsCEEJ4P/2nM84IIRwA3gg8HiCl9IfATvpPCewFHgZ+oTm3ZK4JjNSOa+jPC7up+Z5Mpv7LzP4R8KHm2ErgfSmljyx6AwaM0JZLgV8JIUwC/wBsbP6eTft3s4MmHDFCW6D/D48/TSkdHqi61K7LjwI/B9QhhLuaY79JP8ldVt+VrrgCqyRJ6tTJOGdEkiQtISYjkiSpUyYjkiSpUyYjkiSpUyYjkiSpUyYjkmbUvI30SwNvSj2t2f+BMMMbhkMIm5s3k6ZmsS1JOi4f7ZV0XCGE3wDOTSltCiG8E9ifUvrdEMJDKaUnTlP+2cAh+ivIrkspfX1xI5a03JiMSDquZpnrTwPvBn4ReHZK6ZGZkpGBevsxGZE0gpNuBVZJc5NS+k4I4deBjwAvTv3Xz0PzhmH6K+JuTSn9cWdBSlrWTEYkjeJi4CvAPwXuaI4ttzcMS1qinMAq6bhCCM8CXkT/5V7/NoTwdFiWbxiWtESZjEiaUei/iewPgNeklO6l/+LFtzdP1ZzSlDmD/ovCOn2pn6Tly2RE0vH8Iv03PU8NzdwEZMD5wO4QwueAP2fgDcMhhF9t3sB6NnB3COHmDuKWtIz4NI0kSeqUPSOSJKlTJiOSJKlTJiOSJKlTJiOSJKlTJiOSJKlTJiOSJKlTJiOSJKlTJiOSJKlT/x83x1XV6pniewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot_attr(X_train, y_train, \"X51\", trunc=.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We can now see that\n",
    "- When the feature value is greater than 1.25\n",
    "- The associated example indicates the company will go Bankrupt (`Bankrupt` = 1)\n",
    "\n",
    "Just something to keep in mind in performing your own analysis and building your models\n",
    "- Is there value in creating a synthetic feature: `X51 > t` for some threshold `t` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "- Let `t = 1.1`\n",
    "- Set variable `cond_frac_pos` to the fraction of examples that go Bankrupt where `X51 > t`\n",
    "$$\n",
    "\\frac{ \\text{count(Bankrupt == 1 and X51 > t} )} { \\text{count(Bankrupt == 1)} }\n",
    "$$\n",
    "\n",
    "- Set variable `cond_frac_neg` to the fraction of examples that *do not* go Bankrupt where `X51 > t`\n",
    "$$\n",
    "\\frac{ \\text{count(Bankrupt == 0 and X51 > t} )} { \\text{count(Bankrupt == 0)} }\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of training examples that go Bankrupt, with (X51 > 1.10) is 14.4%\n",
      "The fraction of training examples that DO NOT go Bankrupt, with (X51 > 1.10) is 1.6%\n"
     ]
    }
   ],
   "source": [
    "# Set variables\n",
    "#  t: scalar number, threshold\n",
    "#  cond_frac_pos: scalar number, fraction of examples that go bankrupt where X51 > t\n",
    "#  Cond_frac_neg: scalar number, fraction of examples that do not go bankrupt where X51 > t\n",
    "t = 1.1\n",
    "cond_frac_pos = None\n",
    "cond_frac_neg = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def cond_attr(df, attr, trunc=.01, thresh=1):\n",
    "    X = df[attr]\n",
    "    \n",
    "    # Remove outliers, to improve clarity\n",
    "    mask = (X > X.quantile(trunc)) & (X < X.quantile(1-trunc))\n",
    "    X_trunc, y_trunc = X[ mask  ], y_train[ mask ]\n",
    "    \n",
    "    # Condition on value of target and thresh\n",
    "    cp = X_trunc[ (y_trunc == 1) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 1].size\n",
    "    cn = X_trunc[ (y_trunc == 0) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 0].size\n",
    "      \n",
    "    return cp, cn\n",
    "\n",
    "attr = \"X51\"\n",
    "trunc = 0\n",
    "cond_frac_pos, cond_frac_neg = cond_attr(X_train, attr, trunc=trunc, thresh=t)\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"The fraction of training examples that go Bankrupt, with ({attr:s} > {t:2.2f}) is {frac:3.1%}\".format(attr=attr, \n",
    "                                                                                        t=t,\n",
    "                                                                                        frac=cond_frac_pos)\n",
    "     )\n",
    "\n",
    "print(\"The fraction of training examples that DO NOT go Bankrupt, with ({attr:s} > {t:2.2f}) is {frac:3.1%}\".format(attr=attr, \n",
    "                                                                                        t=t,\n",
    "                                                                                        frac=cond_frac_neg)\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "check-fraction",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "def cond_attr_test(df, attr, trunc=.01, thresh=1):\n",
    "    X = df[attr]\n",
    "    \n",
    "    # Remove outliers, to improve clarity\n",
    "    mask = (X > X.quantile(trunc)) & (X < X.quantile(1-trunc))\n",
    "    X_trunc, y_trunc = X[ mask  ], y_train[ mask ]\n",
    "    \n",
    "    # Condition on value of target and thresh\n",
    "    cp = X_trunc[ (y_trunc == 1) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 1].size\n",
    "    cn = X_trunc[ (y_trunc == 0) & (X_trunc > thresh) ].size/X_trunc[ y_trunc == 0].size\n",
    "      \n",
    "    return cp, cn\n",
    "\n",
    "cond_frac_pos_test, cond_frac_neg_test = cond_attr_test(X_train, 'X51', trunc=0, thresh=1.1)\n",
    "\n",
    "assert np.allclose(cond_frac_pos_test, cond_frac_pos)\n",
    "assert np.allclose(cond_frac_neg_test, cond_frac_neg)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "It seems that we can discover a large fraction of examples that go Bankrupt by examining \n",
    "one feature and threshold.\n",
    "\n",
    "But using this alone will result in some number of False Positives (non Bankrupt examples)\n",
    "- And although the percent is small, we will see that the non Bankrupt examples are more numerous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Imbalanced data\n",
    "\n",
    "We have a binary classification problem.\n",
    "\n",
    "Do we have roughly the same number of examples associated with each of the two targets ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question:**\n",
    "\n",
    "How many training examples do we have that became Bankrupt ?\n",
    "- Set variable `num_bankrupt` to this value\n",
    "\n",
    "How many training examples do we have that *did not become* Bankrupt ?\n",
    "- Set variable `num_nonbankrupt` to this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 4336 total examples: 268 became bankrupt and 4068 did not become bankrupt\n"
     ]
    }
   ],
   "source": [
    "# Set variables\n",
    "#  num_examples: scalar number, number of examples in the training dataset\n",
    "#  num_bankrupt: scalar number, number of examples that became bankrupt\n",
    "#  num_nonbankrupt: scalar number, number of examples that did not become bankrupt\n",
    "num_examples = X_train.shape[0]\n",
    "num_bankrupt = None\n",
    "num_nonbankrupt = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "bankrupt = X_train[ y_train == 1 ] \n",
    "nonbankrupt = X_train[ y_train == 0 ]\n",
    "\n",
    "num_bankrupt    = bankrupt.shape[0]\n",
    "num_nonbankrupt = nonbankrupt.shape[0]\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Of the {t:d} total examples: {b:d} became bankrupt and {nb:d} did not become bankrupt\".format(t=num_examples,\n",
    "                                                                                                    b=num_bankrupt,\n",
    "                                                                                                    nb=num_nonbankrupt)\n",
    "\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "check-imbalance",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "bankrupt_test = X_train[ y_train == 1 ] \n",
    "nonbankrupt_test = X_train[ y_train == 0 ]\n",
    "\n",
    "num_bankrupt_test = bankrupt_test.shape[0]\n",
    "num_nonbankrupt_test = nonbankrupt_test.shape[0]\n",
    "\n",
    "assert num_bankrupt == num_bankrupt_test\n",
    "assert num_nonbankrupt == num_nonbankrupt_test\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This dataset is highly imbalanced: many more examples of one class than the other.\n",
    "\n",
    "Why might this be a problem ?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Consider a naive model that ignores the features and always predicts the *most frequent* value of the target.\n",
    "\n",
    "Assuming the out of sample data has the same distribution as the training data:\n",
    "- We will have perfect conditional accuracy for the examples with target in the majority class\n",
    "- We will have zero conditional accuracy for the examples with target in the non-majority class\n",
    "- Because the number of examples in the majority class is so much larger:\n",
    "    - We might get good unconditional accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Recall our lecture on Recall and Precision.\n",
    "\n",
    "These are metrics that will help us evaluate our model's ability to correctly predict Bankruptcy.\n",
    "\n",
    "We think that you will find that your model may have\n",
    "- High Accuracy\n",
    "- Low Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "There are several ways for you to deal with imbalanced data\n",
    "- Class sensitive weights\n",
    "    - Many models in `sklearn` take an optional argument `class_weight`\n",
    "    - For each target class: you can assign a weight\n",
    "    - The Loss will be computed on a class-weighted basis\n",
    "    - You can choose weights that increase the influence of the non-majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Another way is re-sampling the training set\n",
    "- Expand the number of training examples\n",
    "- By increasing the number of examples of the non-majority class\n",
    "    - Randomly sample examples in the non-majority class\n",
    "    - So you will have duplicates\n",
    "- This creates a more balanced dataset on which to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "These are just some ideas for you to achieve a model with better\n",
    "conditional metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Now submit your assignment!\n",
    "\n",
    "The above steps are an attempt to inspire your own transformations and Exploratory Data Analysis.\n",
    "\n",
    "These will be critical steps in your Final Project, where you will need to build and evaluate your own model for the Classification task of predicting bankruptcy.\n",
    "\n",
    "Please click on the blue button <span style=\"color: blue;\"> **Submit** </span> in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
