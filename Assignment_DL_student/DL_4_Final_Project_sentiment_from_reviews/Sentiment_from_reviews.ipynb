{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "yN3g4v8Zl4Fy",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a631b04310e1e422",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Final Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "moP0TbbABpSP",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c26bf7c2dab01a4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem description\n",
    "\n",
    "Time to show off everything you learned !\n",
    "\n",
    "You will be performing a Classification task to analyze the sentiment of product reviews.\n",
    "\n",
    "This is similar to a prior assignment\n",
    "- With a different dataset\n",
    "- Multinomial classification with 5 classes\n",
    "\n",
    "But, by now, you have many more tools at your disposal.\n",
    "\n",
    "## Some possible approaches\n",
    "- A review is a sequence of words.  You will need to deal with sequences in some manner.  Some suggestions\n",
    "  - Pooling\n",
    "  - Recurrent Neural Network\n",
    "- Is there an advantage to recognizing *adjacent* words groups (\"n-grams\") rather than treating the document as an unordered set of words ?\n",
    "  - Consider these two sentences\n",
    "    - \"Machine Learning is easy not hard\"\n",
    "    - \"Machine Learning is hard not easy\"\n",
    "\n",
    "  - Two sentences with identical words but different meaning.\n",
    "  - Hint: Convolutional layer\n",
    "- How should we encode words ?\n",
    "  - OHE ? Embedding ?\n",
    "\n",
    "We will **not specify** an approach.  Feel free to experiment.\n",
    "\n",
    "Your goal is to produce a model with an out of sample accuracy meeting a minimum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SIA71lpFmaw8"
   },
   "source": [
    "## Grading\n",
    "\n",
    "Prior assignments evaluated you step by step.\n",
    "\n",
    "This project is **results-based**. Your goal is to create a model\n",
    "- That achieves an out of sample accuracy of at least 50%\n",
    "- 60% would be better !\n",
    "\n",
    "There are three data files:  \n",
    "- `train.csv`: dataset you need to work on. You have all information in this dataset, including labels.\n",
    "- `test.csv`: dataset used to test your model. You don't have any label in this dataset. You need to do prediction on the dataset and submit your result.\n",
    "- `submit_sample.csv`: your submitted file should be similar to this file\n",
    "\n",
    "**Submit your file: save outputs of your model in a pandas dataframe, name it \"my_submit.csv\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "tEqGfYbUBpSQ",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88951105efefd305",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Learning objectives\n",
    "- Experimentation !\n",
    "- Error Analysis leading to model improvement\n",
    "- Appreciate how choices impact number of weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": [],
    "colab_type": "code",
    "deletable": false,
    "id": "efiTwPiKBpSc",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b7e86b89aee9a3c4",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Running TensorFlow version \",tf.__version__)\n",
    "\n",
    "# Parse tensorflow version\n",
    "version_match = re.match(\"([0-9]+)\\.([0-9]+)\", tf.__version__)\n",
    "tf_major, tf_minor = int(version_match.group(1)) , int(version_match.group(2))\n",
    "print(\"Version {v:d}, minor {m:d}\".format(v=tf_major, m=tf_minor) )\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, LSTM\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "7bmNajQkBpSf",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-170cfd1efadd8802",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# API for students\n",
    "\n",
    "We will define some utility routines.\n",
    "\n",
    "This will simplify problem solving\n",
    "\n",
    "More importantly: it adds structure to your submission so that it may be easily graded\n",
    "\n",
    "**If you want to take a look at the API or change it, you can open it by selecting \"File->Open->final_helper.py\"**\n",
    "\n",
    "`helper = final_helper.HELPER()`\n",
    "\n",
    "### Preprocess raw dataset\n",
    "- getDataRaw: get raw data. \n",
    "  >`DIR` is the directory of data        \n",
    "  >`tweet_file` is the name of data file          \n",
    "  >`tweets_raw = helper.getDataRaw(DIR, tweet_file)`         \n",
    "- getTextClean: clean text. \n",
    "  >`data_raw` is the raw data you get from `helper.getDataRaw()`, which is a pandas DataFrame          \n",
    "  >`textAttr` is the column of text data      \n",
    "  >`sentAttr` is the column of label       \n",
    "  >`docs, sents = helepr.getTextClean(data_raw, textAttr, sentAttr`         \n",
    "- encodeDocs: text tokenization\n",
    "  >`docs` is the text data          \n",
    "  >`vocab_size` is the size of vocabulary           \n",
    "  >`words_in_doc` is number of words in a review           \n",
    "  >`tok, encoded_docs, encoded_docs_padded = helper.encodeDocs(docs, vocab_size, words_in_doc)`        \n",
    "- showEncodedDocs: display data by reversing index back to word. \n",
    "  >`tok` is an object of `Tokenizer`             \n",
    "  >`encoded_docs_padded` is the text data which you have encoded and padded                  \n",
    "  >`helper.showEncodedDocs(tok, encoded_docs_padded)`                   \n",
    "- getExamplesOHE: one-hot encode samples. \n",
    "  >`encoded_docs_padded` is the text data which you have encoded and padded                 \n",
    "  >`sents` is the labels                \n",
    "  >`vocab_size` is number of words in the vocabulary           \n",
    "  >`X, y = helper.getExamples(encoded_docs_padded, sents, vocab_size)`          \n",
    "\n",
    "### Train model\n",
    "- trainModelCat: train model for categorical labels\n",
    "  >`patience` and `min_delta` are parameters of `EarlyStopping`        \n",
    "  >`history = helper.trainModelCat(model, X_train, X_val, y_train, y_val, num_epochs=30, metric=\"acc\", patience=5, min_delta=.005)`\n",
    "  \n",
    "### Save model and load model\n",
    "- save model (portable): save a model in `./models` directory\n",
    "  >`helper.saveModel(model, modelName)`\n",
    "- save history (non-portable): save a model history in `./models` directory\n",
    "  >`helper.saveHistory(history, modelName)`\n",
    "- save model (portable): save a model in `./models` directory\n",
    "  >`helper.saveModel(model, modelName)`\n",
    "- save history (non-portable): save a model history in `./models` directory\n",
    "  >`helper.saveHistory(history, modelName)`\n",
    "\n",
    "### Plot models and training results\n",
    "- plotModel: plot your models\n",
    "  >`helper.plotModel(model, model_name)`\n",
    "- plot_training: plot your training results\n",
    "  >`helper.plot_training(history, metric='acc)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": [],
    "colab_type": "code",
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "id": "NiwvVQUJBpSV",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cfe849d1d33396b8",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import final_helper\n",
    "%aimport final_helper\n",
    "\n",
    "helper = final_helper.HELPER()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "OHUZacWsBpSi",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee6367be6de141fb",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "\n",
    "\n",
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": [],
    "colab_type": "code",
    "collapsed": true,
    "id": "OUhrnGczBpSi"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "DATA_DIR = \"./Data\"\n",
    "train_file = \"train.csv\"\n",
    "test_file = \"test.csv\"\n",
    "train_raw = helper.getDataRaw(DATA_DIR, train_file)\n",
    "test_raw = helper.getDataRaw(DATA_DIR, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "z6x5Q--mJXDE",
    "outputId": "2463af1a-fda4-4288-8616-5d333c772acf"
   },
   "outputs": [],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2XffyPrDedWO",
    "outputId": "14c176e6-c6f4-4820-fc38-0b9f9fb3f625"
   },
   "outputs": [],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "xN_lWRgsBpSl",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-90095d097450c21b",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "The reviews are in the \"reviewText\" attribute.\n",
    "\n",
    "\n",
    "\n",
    "You may try to use other attributes as additional features if you choose, but we suggest that your first model may use this as the only source of features.\n",
    "\n",
    "When you are manipulating your training set, **DON'T FORGET** to do the same manipulation on **test** set, because you need to use your test set as input of your final model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "o0ufUriSrtp6",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-21e7f15d216a299b",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Get the labelled training data\n",
    "- Features: docs.  Each document is a single review (sequence of characters)\n",
    "- Targets/Labels: sents. Each is the sentiment associated with the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "vwoaUwe-BpSm",
    "outputId": "ff9004ae-0baf-4341-b343-f66d647ffe06"
   },
   "outputs": [],
   "source": [
    "textAttr, sentAttr, titleAttr = \"reviewText\", \"overall\", \"title\"\n",
    "\n",
    "## Clean text\n",
    "# training data\n",
    "docs, sents = helper.getTextClean(train_raw, textAttr, sentAttr)\n",
    "\n",
    "# We will treat the sentiment values as Categorical, rather than numeric\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "sents = le.fit_transform(sents)\n",
    "\n",
    "print(\"Docs shape is \", docs.shape)\n",
    "print(\"Sents shape is \", sents.shape)\n",
    "\n",
    "print(docs[:5])\n",
    "print(\"\\nPossible sentiment values: \",  np.unique(sents) ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "AJyBBa-PBpSo",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15cf5b5f07f8f376",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## More data preprocessing\n",
    "\n",
    "We will need to convert the text in a *sequence* of numbers\n",
    "- Break text up into words\n",
    "- Assign each word a distinct integer\n",
    "\n",
    "Moreover, it will be easier if all sequences have the same length.\n",
    "We can add a \"padding\" character to the front if necessary.\n",
    "\n",
    "We do this for you below.\n",
    "\n",
    "Our method returns\n",
    "- encoded_docs_padded: A matrix of training example *features*\n",
    "  - Each row is an example\n",
    "  - Each row is a *sequence* of fixed length\n",
    "  - Each element of the sequence is an integer, encoding a word in the vocabulary\n",
    "  - The sequence length of every example is *identical* because we have prepended padding if necessary\n",
    "- encoded_docs: A matrix of *unpadded* training example *features*\n",
    "- tok: the Tokenizer used to\n",
    "  - parse strings of characters into words\n",
    "  - encoded each word as an integer\n",
    "\n",
    "\n",
    "You may study our methods parameters and modify them if you wish, e.g., alter the size of the vocabulary or length of sequences.\n",
    "\n",
    "We suggest that your first model uses\n",
    "- encoded_docs_padded as your set of training features, e.g., X\n",
    "- sents: as your targets\n",
    "with the default settings of the method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "ggdZME_FBpSo",
    "outputId": "4d3b180b-9337-4374-8772-f5b29e35f196"
   },
   "outputs": [],
   "source": [
    "## set parameters:\n",
    "# vocab_size : number of words in the vocabulary \n",
    "# words_in_doc: number of words in a review\n",
    "vocab_size_sm, words_in_doc_sm = 400, 100\n",
    "\n",
    "tok, encoded_docs, encoded_docs_padded = helper.encodeDocs(docs_total, vocab_size=vocab_size_sm, words_in_doc=words_in_doc_sm)\n",
    "\n",
    "print(\"Training example features shape: \",encoded_docs_padded.shape)\n",
    "print(\"Training example features: preview\")\n",
    "print(encoded_docs_padded[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "RSPg2B1RBpSq",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f84f1f8a9da9185b",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Verify that our encoded documents are the same as the cleaned original\n",
    "\n",
    "At this point: convince yourself that all we have done was encode words as integers and pad out all text to the same length.  The following will demonstrate this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9HDv4_BXBpSr",
    "outputId": "7a675806-1dd5-4c8b-c0a0-882a67866da4"
   },
   "outputs": [],
   "source": [
    "helper.showEncodedDocs(tok, encoded_docs_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXTltHXxx10g"
   },
   "source": [
    "# Split the examples into training and validation data\n",
    "\n",
    "**Note:**  \n",
    "- You may want to use one-hot encoding to your data. You can use\n",
    "  >`X_train_OHE, _ = helper.getExamplesOHE(X_train, sents, vocab_size_sm)`       \n",
    "  >`X_val_OHE, _ = helper.getExamplesOHE(X_val, sents, vocab_size_sm)` \n",
    "  \n",
    "  But be **careful**, since our vocabulary is very huge, one hot encoding may take too much memory. If you allocate too much memory for data, the program may die!\n",
    "  \n",
    "- If you don't use on-hot encoding, you can try embedding layer in your model, which creates much more dnese data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": [],
    "colab_type": "code",
    "collapsed": true,
    "id": "FzxNUXNXvu7r"
   },
   "outputs": [],
   "source": [
    "# Set the following variables\n",
    "# - X_train: ndarray of training example features\n",
    "# - X_val:  ndarray of validation example features\n",
    "# - y_train: ndarray of training example targets\n",
    "# - y_val:  ndarray of validation example targets\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": [],
    "colab_type": "code",
    "collapsed": true,
    "id": "H6oS5W_hBpS2",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0de960d0bf5c6d38",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Verify your training and test dataset\n",
    "\n",
    "# Set two variables\n",
    "# example_sequence_len: length of the sequence\n",
    "# example_num_features: number of features in a single element of the sequence (of a single example)\n",
    "\n",
    "# If using OHE:\n",
    "example_shape = X_train_OHE.shape[1:]\n",
    "example_sequence_len, example_num_features = example_shape[0], example_shape[1]\n",
    "\n",
    "assert example_sequence_len == words_in_doc_sm\n",
    "assert example_num_features == vocab_size_sm\n",
    "\n",
    "# If NOT using OHE\n",
    "example_shape = X_train.shape[1:]\n",
    "example_sequence_len, example_num_features = example_shape[0], tok.num_words\n",
    "\n",
    "assert example_sequence_len == words_in_doc_sm\n",
    "assert example_num_features == vocab_size_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "uHurBXP607UT",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a599f8ddd1edc00",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Create and train your model\n",
    "\n",
    "**Note:**\n",
    "\n",
    "- There is a `trainModelCat()` API already in the `final_helper.py` file. You can directly use it by\n",
    "  >`history = helper.trainModelCat(model, X_train, X_val, y_train, y_val, num_epochs=30, metric=\"acc\", patience=5, min_delta=.005)`\n",
    "  \n",
    "  You can change the `trainModelCat()` code or write training process by yourself if you have better idea!   \n",
    "\n",
    "\n",
    "- To to see your model performance, use this API is very convenient\n",
    "  >`helper.plot_training(history)`\n",
    "  \n",
    "  \n",
    "- I recommend you to build a simple model first (for example, OHE + GlobalMaxPooling + Logistic Regression). After that, you can check the performance of your simple model and do error analysis. Based on the results of your simple model, you can try to build more complex model (for example, embedding + lstm) to improve your model performance!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": [],
    "colab_type": "code",
    "collapsed": true,
    "id": "o97G-ue51CKX"
   },
   "outputs": [],
   "source": [
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "gtQ_IGvQBpTS",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f1feed2553377a71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## How many weights in your Classifier only model ?\n",
    "\n",
    "How many weights in your model ?\n",
    "\n",
    "You should always be sensitive to how \"big\" your model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": [],
    "colab_type": "code",
    "collapsed": true,
    "id": "-u1ERSiuBpTS",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad84e21e2763f573",
     "locked": false,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set variable\n",
    "num_weight = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "iz_Wroa1BpTU",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0ad6ed9cd2b135fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Submit your predictions\n",
    "\n",
    "Now you have built your best model, please do prediction on `test.csv`. Save your results in a pandas DataFrame which should be similar to the file `submit_sample.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": [],
    "colab_type": "code",
    "collapsed": true,
    "id": "NIgzZKsQ16VX"
   },
   "outputs": [],
   "source": [
    "my_results = pd.DataFrame()\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "\n",
    "# Save your results in a csv file\n",
    "my_results.to_csv('my_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bpWw_tXH_zwu"
   },
   "source": [
    "## Discussion topics\n",
    "- Compare the number of weights in each model.  Did the added complexity (more weights) lead to better performance ?\n",
    "- **Where** were the largest increase in weights between models\n",
    "  - Embeddings consume a lot of weights\n",
    "    - But eliminates a dimension: single integer representation of a word vs a OHE vector of length words_in_vocab\n",
    "    - So subsequent layers may need fewer weights compared to OHE\n",
    "- Should we have formulated this as a Regression task rather than a Classification task ?\n",
    "  - Is the difference in rating between 0 and 1 the same as between 3 and 4 ?\n",
    "    - Perhaps there are bigger *absolute* differences in satisfaction  in lower ratings\n",
    "      - i.e., Big difference between 0 and 1, smaller difference between 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "gtQ_IGvQBpTS",
    "IoeQjuCDBpTG"
   ],
   "name": "Sentiment_from_reviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": [],
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": [],
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
