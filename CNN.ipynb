{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "%\n",
       "%\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\kernel}{\\mathbf{k}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# My standard magic !  You will see this in almost all my notebooks.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "import cnn_helper\n",
    "%aimport cnn_helper\n",
    "cnnh = cnn_helper.CNN_Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks (CNN): HIgh Level\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>TL;DR</b> \n",
    "    <br>\n",
    "    <ul>\n",
    "        <li> A single unit in Fully Connected (FC) Layer identifies the presence/absence of a single feature spanning the <b>entire</b> input</li>\n",
    "        <li>A single \"kernel\" in a Convolutional Layer identifies the presence/absence of a single feature</li>\n",
    "        <ul>\n",
    "            <li>Whose size is a fraction of the entire input</li>\n",
    "            <li>At <b>each</b> sub-span of the input</li>\n",
    "        </ul>\n",
    "        \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example**\n",
    "- FC: is the input image the digit \"8\"\n",
    "- CNN: are there one or more small \"8\"'s in the input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks: Introduction\n",
    "\n",
    "$$\n",
    "\\y_{\\llp,j} = N(\\y_{(\\ll-1)}, \\kernel, j) \\cdot \\kernel_\\llp\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have seen how the Fully Connected (FC) layer performs a template-matching on the layer's inputs.\n",
    "$$\n",
    "\\y_\\llp = a_\\llp ( \\W_\\llp \\y_{(\\ll-1)} + b )\n",
    "$$\n",
    "\n",
    "- Each element of $\\y_{(\\ll-1)}$ is independent\n",
    "    - there is no relationship between $\\y_{(\\ll-1), j}$ and $\\y_{(\\ll-1), j+1}$\n",
    "    - even though they are adjacent in the vector ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To see the lack of relationship:\n",
    "\n",
    "Let $\\text{perm}$ be a random ordering of the integers in the range $[1 \\ldots n]$.\n",
    "\n",
    "Then\n",
    "- $\\x[ \\text{perm} ]$ is a permutation of input $\\x$\n",
    "- $\\Theta[ \\text{perm} ]$ is the corresponding permutation of parametrs $\\Theta$.\n",
    "\n",
    "$$\n",
    "\\Theta^T \\cdot \\x = \\x[ \\text{perm} ] \\cdot \\Theta[ \\text{perm} ]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So a FC layer cannot take advantage of any explicit ordering among the input elements\n",
    "- timeseries of prices\n",
    "- adjacent pixels in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>CNN convolution</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/CNN_convolution_1.jpg\" width=900></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We place $(3 \\times 3)$ Kernel (weight matrix) on the inputs ($\\y_{(0)}$, output of layer 0)\n",
    "- Performs dot product\n",
    "- Produces Layer 1 output ($\\y_{(1)}$) feature labelled $1$\n",
    "\n",
    "Slide the Kernel up and repeat:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>CNN convolution</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/CNN_convolution_2.jpg\" width=900></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The dot product *using the identical kernel weights* produces output ($\\y_{(1)}$) feature labelled $2$\n",
    "\n",
    "Repeat, centering the Kernel over each feature in $\\y_{(0)}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>CNN convolution</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/CNN_convolution_3.jpg\" width=900></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "<center>Fully Connected vs Convolution</center>\n",
    "<tr>\n",
    "<img src=\"images/CNN_vs_FC.jpg\" width=600\">\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The template is called a *kernel* or *filter*\n",
    "- The output of a convolution is called a *feature map*\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So a Convolutional Layer can use *many fewer* weights/parameters than a Fully Connected Layer.\n",
    "\n",
    "As we will see, this enables us to create *many* separate convolutions in a single layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- How do we construct a \"good\" kernel ?\n",
    "- How do we decide which one to use ?\n",
    "\n",
    "It all depends on the objective.\n",
    "\n",
    "Machine Learning to the rescue: let an ML algorithm \"learn\" the kernel that is best suited to the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, consider a two layer Sequential model\n",
    "- First layer is a convolution with kernel $\\kernel$\n",
    "- Second layer if a classifier with parameters $\\Theta$\n",
    "\n",
    "Let $\\loss$ be some loss function appropriate to classifcation, e.g, cross entropy.\n",
    "\n",
    "Then our ML Swiss Army Knife (Gradient Descent) solves for the loss-minimizing values of $\\Theta, \\kernel$\n",
    "$$\n",
    "\\Theta, \\kernel = \\argmin{\\Theta, \\kernel} \\loss\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CNN advantages/disadvantages\n",
    "\n",
    "**Advantages**\n",
    "- Translational invariance\n",
    "    - feature can be anywhere\n",
    "- Locality\n",
    "    - feature depends on nearby features, not the entire set of features\n",
    "    - reduced number of parameters compared to a Fully Connected layer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Disadvantages**\n",
    "- Output feature map is roughly same size as input\n",
    "    - lots of computation to compute a single output feature\n",
    "        - one per feature of input map\n",
    "    - higher computation cost\n",
    "        - training and inference\n",
    "- Translational invariance not always a positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "       <center>CNN convolution</center>\n",
    "    <tr>\n",
    "        <td><img src=\"images/CNN_feature_map.jpg\" width=600></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple case: 1d convolution\n",
    "\n",
    "We have thus far illustrated Convolution with input layer $0$ having $\\x^\\ip$ of dimension $N_{(0)} \\in \\{2,3 \\}$.\n",
    "\n",
    "We can generalize the logic to tensors of dimension $N > 3$.\n",
    "\n",
    "But we also have the simplest case of $N=1$.\n",
    "- can consider the one dimensional $\\x^\\ip$ has being two dimensional with leading dimension $1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One dimensional convolution is quite common\n",
    "- timeseries of prices\n",
    "- sequence of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "Consider a time series of prices of length 5\n",
    "- a positive spike at elements 1 and 3\n",
    "- a FC has no order\n",
    "    - can't distinguish between $[+,-+]$ and $[+,+,-]$\n",
    "    - but a 1D convolution with kernel size 3 can\n",
    "\n",
    "Consider a sequence of words\n",
    "- an FC cannot distinguish $[\"not\", \"like\", \"ML\"]$ from $[\"ML\", \"not\", \"like\"]$\n",
    "    - but a 1D convolution with kernel size 3 can"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So Convolutional Layers can impose a partial ordering (within range of kernel) where FC Layers cannot.\n",
    "\n",
    "This doesn't completely address the issue of inputs that are sequences as the \"field\"\n",
    "of ordering is only within (a small) kernel.\n",
    "\n",
    "We will learn to deal with sequences when we study Recurrent Neural Networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Technical points\n",
    "\n",
    "## Convolution versus Cross Correlation\n",
    "- math definition of convolution\n",
    "    - dot product of input and *reversed* filter\n",
    "    - we are doing [cross correlation](https://en.wikipedia.org/wiki/Convolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Receptive field\n",
    "\n",
    "The *receptive field* of a elements of a feature map\n",
    "- are the Layer 0 (input) features that affect features in the map.\n",
    "\n",
    "\n",
    "For ease of notation:\n",
    "- we assume $N=2$ as the dimension of the kernel\n",
    "- we assume that all $N$ dimensions of the kernel are the same ($f_\\llp$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So we will assume without loss of generality that\n",
    "- the \"height\" and \"width\" of a single kernel kernel is $(f \\times f)$\n",
    "- the full dimensionality of a single layer $\\ll$ kernel is $(n_{(\\ll-1),1} \\times f \\times f)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus the receptive field of a Convolutional Layer at layer $1$ is $(f \\times f)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Increasing the Receptive Field\n",
    "\n",
    "There are several ways to \"widen\" the receptive field\n",
    "- Increasing $f_\\llp$, the size of the kernel\n",
    "- Stacking Convolutional Layers\n",
    "- Stride\n",
    "- Pooling\n",
    "\n",
    "Striding and Pooling also have the effect of reducing the size of the output feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Increase the size of the kernel\n",
    "\n",
    "Although this is the most *obvious* way of increasing the receptive field, we tend to avoid it !\n",
    "\n",
    "We will see the reason shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For simplicity of drawing: let's consider \n",
    "- One dimension\n",
    "- Kernel size 3\n",
    "- Two layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <center>Conv 1D Receptive field: 2 layers</center>\n",
    "    <br>\n",
    "<img src=images/Conv1d_receptive.jpg width=800>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The elements in $\\y_\\llp$\n",
    "- Are colored\n",
    "- The same color as the elements of $\\y_{(\\ll-1)}$ that they depend on\n",
    "\n",
    "Each element of layer $\\ll$ depends on $f_\\llp = 3$ elements of layer $\\ll-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider the element in the center of of $y_{(\\ll+1)}$, i.e., $y_{(\\ll+1),3}$\n",
    "- It depends on the Orange, Green, and Blue elements of $\\y_\\llp$\n",
    "- Which in turn depend on the Orange, Green and Blue elements of $\\y_{(\\ll-1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Each element of layer $\\ll+1$ \n",
    "- Depends on $f_\\llp = 3$ elements of layer $\\ll$\n",
    "- Depnds on $f_\\llp + 1 + 1 =5$ elements of layer $\\ll-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One can trace an element in layer $\\ll+1$\n",
    "- Backwards through layers\n",
    "- To input layer $0$\n",
    "\n",
    "The elements  in layer $0$ that $\\y_{\\ll+1),3}$ depends on are called the *receptive field* of the layer $\\ll$ element.\n",
    "\n",
    "The size of the receptive field increases with the depth of the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One can apply similar logic to a two dimensional kernel.\n",
    "\n",
    "As you go one layer deeper in the NN, the receptive field width and height increase by (2 * *stride*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <center>Conv 2D Receptive field: 2 layers</center>\n",
    "    <br>\n",
    "<img src=images/Conv2d_receptive.jpg width=800>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So\n",
    "- Rather than having a one layer network with $f_\\llp = 5$\n",
    "- We can have *two* layers with $f_\\llp = f_{(\\ll+1)} = 3$\n",
    "- And the elements in the final layer will depend on *identical* elements of layer $0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>CNN receptive field</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/CNN_Receptive_field.jpg\" width=600></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Each grid in Layer 1 refers to the *same* features in Layer 0\n",
    "- The layer 2 feature labelled $i$ is a function of the Layer 1 features labelled $i$\n",
    "- By completing the $(3 \\times 3)$ grid in Layer 2:\n",
    "    - all $(5 \\times 5)$ layer 0 features are touched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|  Layer  | Receptive field |\n",
    "|-- |-- |\n",
    "1 | $(3 \\times 3)$\n",
    "1 | $(5 \\times 5)$\n",
    "1 | $(7 \\times 7)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Strides\n",
    "\n",
    "Thus far, we have slid the kernel over *each* feature of the input feature map.\n",
    "\n",
    "That is: the kernel moves with *stride* $S = 1$\n",
    "\n",
    "Alternatively, we could skip $(S-1)$ features of the input feature map with stride $S > 1$.\n",
    "\n",
    "This will \n",
    "- enlarge the receptive field\n",
    "- decrease the size of the output feature map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pooling\n",
    "\n",
    "We can \"down sample\" a feature map by combining features.\n",
    "\n",
    "For example: we can replace a $(2 \\times 2)$ region of feature values with a single average value.\n",
    "\n",
    "This is called *pooling*.\n",
    "\n",
    "When combined with a stride $S > 1$ this results in \"down sampling\" (reduced spatial dimensions).\n",
    "\n",
    "After pooling, each synthetic feature is a function of more than one features of the prior layer.\n",
    "\n",
    "Pooling will\n",
    "- enlarge the receptive field\n",
    "- decrease the size (assuming $S > 1$) of the pooling layer's output feature map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pooling operations\n",
    "- Average pooling\n",
    "    - average over the kernel \n",
    "- Max pooling\n",
    "    - Max over the kernel\n",
    "    \n",
    "Pooling without a kernel:\n",
    "- Global average pooling\n",
    "    - replace each feature map with a single value: the maximum over the spatial dimensions\n",
    "- K-Max pooling\n",
    "    - replace one dimension of the volume with the $K$ largest elements of the dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Size of output\n",
    "\n",
    "We can relate the size of a layer's output feature map to the size of its input feature map:\n",
    "\n",
    "- input $W_i \\times H_i \\times D_i$\n",
    "- $N$: input size $N \\times N$\n",
    "- $F$: filter size $F \\times F$\n",
    "- $S$: stride\n",
    "- $P$: padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No padding\n",
    "- output size $( (W_i -F)/S +1 ) \\times ( (H_i - F)/S +1 ) \\times D_o$\n",
    "\n",
    "Padding\n",
    "- output size $( (W_i -F +2P)/S +1 ) \\times ( (H_i - F +2P)/S +1 ) \\times D_o$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "    \n",
    "Assuming full padding, a layer $\\ll$ Convolutional Layer with $n_{\\llp,1}$ kernels will have output $\\y_\\llp$ dimension\n",
    "- $(n_{\\llp,1} \\times n_{(\\ll-1),2} \\times n_{(\\ll-1),3})$\n",
    "    - $n_{\\llp,1}$ features\n",
    "    - over a spatial map of $(n_{(\\ll-1),2} \\times n_{(\\ll-1),3})$\n",
    "    \n",
    "That is, the number of features changes but the spatial dimension is similar to $\\y_{(\\ll-1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Down-sampling: Why does output size matter\n",
    "\n",
    "Convolution applies a kernel to *each* region of the input feature map (assuming $S=1$).\n",
    "\n",
    "Reducing the size of feature map at layer $(\\ll-1)$ \n",
    "- will reduce the number of operations\n",
    "performed by Convolution at layer $\\ll$.\n",
    "\n",
    "For image inputs (with thousands or millions of input features) there is a incentive to down-sample\n",
    "- Speed up training\n",
    "- Speed up inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Down-sample by\n",
    "- Increasing Stride\n",
    "- Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Number of parameters\n",
    "\n",
    "The real power of convolution comes from using the *same* filter against all locations of the input.\n",
    "\n",
    "As a result, the number of parameters is quite small (compared to a separate set of parameters per each input).\n",
    "\n",
    "- Dimension of a single filter $F \\times F \\times D_i$\n",
    "- $D_o$: number of output filters\n",
    "- total parameters: $F * F * D_i * D_o$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember: there is a depth to the input and the filter applies to the entire input depth\n",
    "- size of a filter $F *F * D_i$\n",
    "- number of filters: $D_o$, one per output channel\n",
    "- total: $F * F * D_i * D_o$\n",
    "\n",
    "If we were to have a separate filter for each input location, the number of parameters would increase\n",
    "by a factor of $W_i * H_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why Stacking Conv Layers beats larger kernels\n",
    "\n",
    "A single Conv layer kernel with $f=5$ \n",
    "- Has the same receptive field $(5 \\times 5)$\n",
    "- As two stacked layers with kernel size $f=3$.\n",
    "\n",
    "Why might we prefer the latter ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's consider a Convolutional Layer $\\ll$.\n",
    "- The number of features at the input feature map is $n_{(\\ll-1),1}$\n",
    "- The number of features at the output feature map is $n_{\\llp,1}$\n",
    "- The number of weights in each kernel of layer $\\ll$ is $(n_{(\\ll-1),1}\\times f_\\llp)$ (assuming $N=2$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The single Convolutional Layer $\\ll$ with  kernel size $f_\\llp = f$ uses\n",
    "    - $n_{\\llp,1} * (n_{(\\ll-1),1} * f^2)$ weights\n",
    "- Two stacked Convolutional Layers $\\ll, (\\ll+1)$, each with kernel size $f_\\llp = f_{(\\ll +1)} = g$ uses\n",
    "    - $2 * n_{\\llp,1} * (n_{(\\ll-1),1} * g^2)$ weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The single Convolutional Layer uses $\\frac{f^2}{2 g}$ times as many weights.\n",
    "\n",
    "For $f = 5, g=3$: single layer uses almost 3 times (25/9) as many weights !\n",
    "\n",
    "For $f = 7, g=3$: single layer uses almost 5+ times (49/9) as many weights !\n",
    "\n",
    "So it is more parameter efficient to use multiple layers to increase receptive field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Increased depth has another advantage:\n",
    "- each additional layer introduces another non-linear activation\n",
    "\n",
    "Increase non-linearity may result in more complex features being learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Early CNN's tended to use larger kernels.\n",
    "\n",
    "Today, $(3 \\times 3)$ kernels, with many layers, is more common.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Kernel size 1\n",
    "\n",
    "Why might one want $f_\\llp =1$\n",
    "- i.e, a $(1 \\times 1)$ kernel ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Remember that Convolutional Layer $\\ll$ transforms\n",
    "- an input of dimension $(n_{(\\ll-1),1} \\times n_{(\\ll-1),2} \\times n_{(\\ll-1),3})$\n",
    "- into output with dimension $(n_{\\llp,1} \\times n_{(\\ll-1),2} \\times n_{(\\ll-1),3})$\n",
    "\n",
    "by combining the $(n_{(\\ll-1),1} \\times f_\\llp \\times f_\\llp)$ features of layer ($\\ll -1)$ at a time.\n",
    "\n",
    "Setting $f_\\llp = 1$ combines the $n_{(\\ll-1),1}$ layer $(\\ll-1)$ features at *each* location into a single\n",
    "layer $\\ll feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So $f_\\llp = 1$ is a simple way of reducing the number of features from $n_{(\\ll-1),1}$ to $n_{\\llp,1}$\n",
    "- Using only $(1 * n_{\\llp,1})$ weights !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CNN Math: Time versus number of parameters\n",
    "\n",
    "For simplicity, we will assume that the layers of our NN have\n",
    "data in 3 dimensions:\n",
    "- the first dimension indexes a feature map (i.e., layer encodes a feature at each spatial location)\n",
    "- the final two dimensions are the spatial dimensions (i.e, height and width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider a convolutional layer $\\ll$, that uses full padding\n",
    "- operating on input $\\y_{(\\ll-1)}$ of dimension $(n_{(\\ll-1),1} \\times n_{(\\ll-1),2} \\times n_{(\\ll-1),3})$\n",
    "    - $n_{(\\ll-1),1}$ feature maps over spatial locations of dimension $(n_{(\\ll-1),2} \\times n_{(\\ll-1),3})$\n",
    "- using $n_{\\llp,1}$ kernels of shape $(f_\\llp \\times f_\\llp)$ to produce $n_{\\llp,1}$   output feature maps\n",
    "    - spatial dimensions $(n_{\\llp,2} \\times n_{\\llp,3}) = (n_{(\\ll-1),2} \\times n_{(\\ll-1),3})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's measure the space (number of parameters) and time (number of operations) of layer $\\ll$:\n",
    "- Number of parameters (shape of kernel $\\kernel_\\llp$)\n",
    "    - $n_{\\llp,1} \\times n_{(\\ll-1),1} \\times f_\\llp \\times f_\\llp$\n",
    "- Number of multiplications to produce $\\y_\\llp$ via the Convolutiona Layer\n",
    "    - $n_{\\llp,1} \\times n_{(\\ll-1),1} \\times f_\\llp \\times f_\\llp \\times n_{(\\ll-1),2} \\times n_{(\\ll-1),3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A Convolutional Layer's space requirements\n",
    "- Number of parameters relatively efficient\n",
    "    - contingent on the number of feature maps of the input and output\n",
    "    - not their spatial dimension\n",
    "- Size of output\n",
    "    - contingent on number of feature maps of the input and output\n",
    "    - **and** their spatial dimension\n",
    "\n",
    "The number of operations (element-wise multiplications) can be quite large\n",
    "- contingent on number of feature maps of the input and output **and** their spatial dimension\n",
    "- will impact speed of both training and inference (test time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It becomes of great practical importance to control the space and time requirements.\n",
    "\n",
    "This becomes most apparant when connecting the final Convolutional Layer $\\ll -1$ to\n",
    "a Fully Connected layer $\\ll$\n",
    "- usually happens in the head of a NN, prior to classification or regression\n",
    "- Suppose FC layer $\\ll$ has $n_\\ll$ units (and we flatten the volume of $\\y_{(\\ll-1)}$ to one dimension)\n",
    "- number of parameters for the FC layer:\n",
    "    - $n_\\llp \\times n_{(\\ll-1),1} \\times n_{(\\ll-1),2} \\times n_{(\\ll-1),3}$\n",
    "    - $n_\\llp$ typically large so as to not lose too much information relative to $\\y_{(\\ll-1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's summarize our knowledge of controlling the size of $\\y_{(\\ll-1)}$:\n",
    "- Controlling spatial dimensions\n",
    "    - Increase stride\n",
    "    - Pooling\n",
    "        - Global average pooling often used in final Convolutional Layer\n",
    "- Control number of feature maps per layer\n",
    "    - Choice of $n_{\\llp,1}$\n",
    "    - Kernel size $f_\\llp = 1$\n",
    "        - preserve spatial dimension\n",
    "        - change number of feature maps from $n_{(\\ll-1),1}$ to $n_{\\llp,1}$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Striding and Pooling\n",
    "- increase receptive field\n",
    "- typically small values (e.g., $S=2$) \n",
    "    - limited reduction\n",
    "\n",
    "Kernel size $f_\\llp = 1$\n",
    "- reduction depends on the ratio of $n_{\\llp,1}$ to $n_{(\\ll-1),1}$\n",
    "    - unlimited reduction possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolution as matrix multiplication\n",
    "[A guide to convolutional arithmetic for deep learning](https://arxiv.org/pdf/1603.07285.pdf)\n",
    "\n",
    "Convolution involves a multi-dimensional dot product over a large volume\n",
    "- each location, of each input feature map\n",
    "\n",
    "Doing this in a loop would be very expensive.\n",
    "\n",
    "There are many highly efficient libraries for matrix multiplication\n",
    "- some of which can take advantage of parallelism and GPU's.\n",
    "\n",
    "Geron equation 13-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can turn convolution into matrix multiplication.\n",
    "\n",
    "For simplicity, we will show this for a single channel, using a $(3 \\times 3)$ kernel on a $(4 \\times 4 \\times 1)$ input volume.\n",
    "\n",
    "Basically: we flatten out both the kernel matrix $W$ \n",
    "\n",
    "$$\n",
    "W = \\begin{pmatrix}\n",
    "w_{0,0} & w_{0,1} & w_{0,2} \\\\\n",
    "w_{1,0} & w_{1,1} & w_{1,2} \\\\\n",
    "w_{2,0} & w_{2,1} & w_{2,2}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "and the input volume matrix.\n",
    "\n",
    "Since the input volume is $(16 \\times 1)$, we will left multiply by a matrix with number of rows equal to the output volume, and $16$ columns.\n",
    "\n",
    "For simplicity, we do this without padding, so the output volume is $(2 \\times 2)$ which flattened is $(4 \\times 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$C = \\begin{pmatrix}\n",
    "    w_{0,0} & w_{0,1} & w_{0,2} & 0 & w_{1,0} & w_{1,1} & w_{1,2} & 0 & w_{2,0} & w_{2,1} & w_{2,2} & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "    0       & w_{0,0} & w_{0,1} & w_{0,2} & 0 & w_{1,0} & w_{1,1} & w_{1,2} & 0 & w_{2,0} & w_{2,1} & w_{2,2} & 0 & 0 & 0 & 0 \\\\\n",
    "    0       & 0       & 0       & 0       & w_{0,0} & w_{0,1} & w_{0,2} & 0 & w_{1,0} & w_{1,1} & w_{1,2} & 0 & w_{2,0} & w_{2,1} & w_{2,2} & 0 \\\\\n",
    "    0 & 0       & 0       & 0       & 0       & w_{0,0} & w_{0,1} & w_{0,2} & 0 & w_{1,0} & w_{1,1} & w_{1,2} & 0 & w_{2,0} & w_{2,1} & w_{2,2} \n",
    "  \\end{pmatrix}\n",
    "  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once you understand that the convolution result\n",
    "- is obtained as $C X'_{l}$ \n",
    "- (where $X'_{l}$ is the flattened inputs to layer $l$), \n",
    "- you can imagine an inverse of $C$ to go from the convolution result\n",
    "backwards to $X'_{l}$.\n",
    "\n",
    "That is, we can trace backwards from each activation in a feature map to the inputs that went into its\n",
    "computation.\n",
    "\n",
    "This will enable us to do back propagation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inverting convolution\n",
    "\n",
    "For a variety of reasons, it will prove useful to invert the convolution operation.\n",
    "\n",
    "For example\n",
    "- if we view convolution as down-sampling, there will be cases where we want to restore the original volume by up-sampling\n",
    "- we want to know which elements of the input volume contribute to a particular element of the output volume\n",
    "    - need to back propagate the gradient\n",
    "- we may want to know which elements of the input volume contribute most to an element of the output volume (perhaps an output volume several layers removed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will discuss these in the context of understanding what a layer of a CNN is \"looking for\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How many filters to use (what is the correct  number of channels ?)\n",
    " [Bag of Tricks for Image Classification with CNNs](https://arxiv.org/abs/1812.01187)\n",
    " \n",
    "Suppose the kernel size for a CNN layer is $(W \\times H \\times D)$ (thus operating on an input whose channel depth is $D$).\n",
    "\n",
    "Then each convolution dot product is a function of $N = (W*H*D)$ inputs.\n",
    "\n",
    "Having more than $N$ output channels is the opposite of compressing the input: we are generating more\n",
    "values than in the input.\n",
    "\n",
    "So we can argue for $N$ as an  upper bound.\n",
    "\n",
    "This argument is mitigated somewhat by the \"lottery ticket\" argument: \n",
    "- having extra neurons, even if many are eventually \"dead\" (unused, and hence can be pruned), facilitates training\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
