{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6N2CBGINh8Pv",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-781158b4d8582eff",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem description\n",
    "\n",
    "To a large degree, financial data has traditionally been numeric in format.\n",
    "\n",
    "But in recent years, non-numeric formats like image, text and audio have been introduced.  \n",
    "\n",
    "Private companies have satellites orbiting the Earth taking photos and offering them to customers.  A financial analyst might be able to extract information from these photos that could aid in the prediction of the future price of a stock\n",
    "\n",
    "- Approximate number of customers visiting each store: count number of cars in parking lot\n",
    "- Approximate activity in a factory by counting number of supplier trucks arriving and number of delivery trucks leaving\n",
    "- Approximate demand for a commodity at each location: count cargo ships traveling between ports\n",
    "\n",
    "In this assignment, we will attempt to recognize ships in satellite photos.\n",
    "This would be a first step toward\n",
    "counting.\n",
    "\n",
    "As in any other domain: specific knowledge of the problem area will make you a better analyst.\n",
    "For this assignment, we will ignore domain-specific information and just try to use a labeled training set (photo plus a binary indicator for whether a ship is present/absent in the photo), assuming that the labels are perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CeLXwiRUkM7E",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-927d32994455c2a4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Goal: \n",
    "\n",
    "In this notebook, you will need to create a model in `TensorFlow/Keras` to classify satellite photos.\n",
    "- The features are images: 3 dimensional collection of pixels\n",
    "  - 2 spatial dimensions\n",
    "  - 1 dimension with 3 features for different parts of the color spectrum: Red, Green, Blue\n",
    "- The labels are either 1 (ship is present) or 0 (ship is not present)\n",
    "\n",
    "There are two notebook files in this assignment:\n",
    "- The one you are viewing now: First and only notebook you need to work on. \n",
    "    - Train your models here\n",
    "    - There are cells that will save your models to a file\n",
    "- **`Model_test.ipynb`**:\n",
    "    - This notebook is used to grade your assignment. PLEASE IGNORE\n",
    "\n",
    "You will create several Keras `Sequential` models, of increasing complexity\n",
    "- A model that implements only a Classification Head (no transformations other than perhaps rearranging the image)\n",
    "- A model that adds a Dense layer before the head\n",
    "- (Later assignment) A model that adds Convolutional layers before the Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EI8sBAa9-u0",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bbc7640b0aa2f6b9",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Learning objectives\n",
    "- Learn how to construct Neural Networks using Keras Sequential model\n",
    "- Appreciate how layer choices impact number of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YxXiLgtXAdYS",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3fe918b7fc402898",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Imports modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrjN4zPEAfQb",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-070cebdd7ee912db",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "## Import tensorflow and check the version\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "print(\"Running TensorFlow version \",tf.__version__)\n",
    "\n",
    "# Parse tensorflow version\n",
    "import re\n",
    "\n",
    "version_match = re.match(\"([0-9]+)\\.([0-9]+)\", tf.__version__)\n",
    "tf_major, tf_minor = int(version_match.group(1)) , int(version_match.group(2))\n",
    "print(\"Version {v:d}, minor {m:d}\".format(v=tf_major, m=tf_minor) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O7LEiY7ilZpz",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1005e0ae8cabee0e",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# API for students\n",
    "\n",
    "We have defined some utility routines in a file `helper.py`. There is a class named `Helper` in it.  \n",
    "\n",
    "This will simplify problem solving\n",
    "\n",
    "More importantly: it adds structure to your submission so that it may be easily graded\n",
    "\n",
    "`helper = helper.Helper()`\n",
    "\n",
    "- getData: Get a collection of labeled images, used as follows\n",
    "\n",
    "  >`data, labels = helper.getData()`\n",
    "- showData: Visualize labeled images, used as follows\n",
    "\n",
    "  >`helper.showData(data, labels)`\n",
    "- plot training results: Visualize training accuracy, loss and validation accuracy, loss\n",
    "\n",
    "  >`helper.plotTrain(history, modelName)`, where history is the result of model training\n",
    "- save model: save a model in `./models` directory\n",
    "\n",
    "  >`helper.saveModel(model, modelName)`\n",
    "- save history: save a model history in `./models` directory\n",
    "  >`helper.saveHistory(history, modelName)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-232785a938df9d8a",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the helper module\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Import helper module\n",
    "import helper\n",
    "%aimport helper\n",
    "\n",
    "helper = helper.Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6qfyKiQ3FTXu",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e4d6b6651f9d5e13",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Get the data\n",
    "\n",
    "The first step in our Recipe is Get the Data.\n",
    "\n",
    "We have provided a utility method `getData` to simplify this for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "5TGSVUf6FVis",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c6e43d865e98cc5",
     "locked": true,
     "solution": false
    },
    "outputId": "f529d119-8369-4b18-8d57-559333cb50cb"
   },
   "outputs": [],
   "source": [
    "# Get the data\n",
    "data, labels = helper.getData()\n",
    "n_samples, width, height, channel = data.shape\n",
    "print(\"Data shape: \", data.shape)\n",
    "print(\"Labels shape: \", labels.shape)\n",
    "print(\"Label values: \", np.unique(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7f0731f6291cf725",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We will shuffle the examples before doing anything else.\n",
    "\n",
    "This is usually a good idea\n",
    "- Many datasets are naturally arranged in a *non-random* order, e.g., examples with the sample label grouped together\n",
    "- You want to make sure that, when you split the examples into training and test examples, each split has a similar distribution of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLyx2K-xBBvr",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9f1f107cbcd456da",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle the data first\n",
    "data, labels = sklearn.utils.shuffle(data, labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data\n",
    "\n",
    "We will not go through all steps in the Recipe, nor in depth.\n",
    "\n",
    "But here's a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0zuY0AOl_K1R",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-90cee4495de96935",
     "locked": true,
     "solution": false
    },
    "outputId": "8e2ff048-a6b6-4919-e40d-8381aee59af7"
   },
   "outputs": [],
   "source": [
    "# Visualize the data samples\n",
    "helper.showData(data[:25], labels[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4c8b0892e4935728",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Eliminate the color dimension\n",
    "\n",
    "As a simplification, we will convert the image from color (RGB, with 3 \"color\" dimensions referred to as Red, Green and Blue) to gray scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8551f6a1f8c925cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Original shape of data: \", data.shape)\n",
    "\n",
    "w = (.299, .587, .114)\n",
    "data_bw = np.sum(data * w, axis=3)\n",
    "\n",
    "print(\"New shape of data: \", data_bw.shape)\n",
    "\n",
    "data_orig = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-73a179f1f6a017d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the data samples\n",
    "helper.showData(data_bw[:25], labels[:25], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uCIcmcDmlkw",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cdda65487ad48f16",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Have  look at the data: Examine the image/label pairs\n",
    "\n",
    "Rather than viewing the examples in random order, let's group them by label.\n",
    "\n",
    "Perhaps we will learn something about the characteristics of images that contain ships.\n",
    "\n",
    "We have loaded and shuffled our dataset, now we will take a look at image/label pairs. \n",
    "\n",
    "Feel free to explore the data using your own ideas and techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2k9YAbAZDbqE",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f5e0d3c18f2d4b8",
     "locked": true,
     "solution": false
    },
    "outputId": "c24286e7-6991-4b78-9716-bad69e27ccfd"
   },
   "outputs": [],
   "source": [
    "# Inspect some data (images)\n",
    "num_each_label = 10\n",
    "\n",
    "for lab in np.unique(labels):\n",
    "    # Fetch images with different labels\n",
    "    X_lab, y_lab = data_bw[ labels == lab ], labels[ labels == lab]\n",
    "    # Display images\n",
    "    fig = helper.showData( X_lab[:num_each_label], [ str(label) for label in y_lab[:num_each_label] ], cmap=\"gray\")\n",
    "    _ = fig.suptitle(\"Label: \"+  str(lab), fontsize=14)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_418VKqmvwy",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34eb095f07300d27",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Make sure the features are in the range [0,1]  \n",
    "\n",
    "**Warm up exercise:** When we want to train image data, the first thing we usually need to do is scaling. \n",
    "\n",
    "Since the feature values in our image data are between 0 and 255, to make them between 0 and 1, we need to divide them by 255.  \n",
    "\n",
    "We also need to consider how to represent our target values\n",
    "- If there are more than 2 possible target values, One Hot Encoding may be appropriate\n",
    "    - **Hint**: Lookup `tf.keras.utils.to_categorical`\n",
    "- If there are only 2 possible targets with values 0 and 1 we can use these targets without further encoding\n",
    "\n",
    "**Question**\n",
    "- Set variable `X` to be our gray-scale examples (`data_bw`), but with values in the range [0,1]\n",
    "- Set variable `y` to be the representation of our target values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBJaZ3qyDq65",
    "nbgrader": {
     "grade": false,
     "grade_id": "Scale_the_data",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "# Assign values for X, y\n",
    "#  X: the array of features\n",
    "#  y: the array of labels\n",
    "# The length of X and y should be identical and equal to the length of data.\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "X, y = np.array([]), np.array([])\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X = data_bw / 255.\n",
    "y = labels\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a80cad4b10d52d33",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check if your solution is right \n",
    "assert X.shape == (4000, 80, 80)\n",
    "assert ( (y.shape == (4000,)) or (y.shape == (4000,1)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aHnlcZ4WNN1T",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96db16f7139d0dc5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Split data into training data and testing data\n",
    "To train and evaluate a model, we need to split the original dataset into\n",
    "a training subset (in-sample) and a test subset (out of sample).\n",
    "\n",
    "We will do this for you in the cell below.\n",
    "\n",
    "**DO NOT** shuffle the data until after we have performed the split into train/test sets\n",
    "- We want everyone to have the **identical** test set for grading\n",
    "- Do not change this cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OhmoI5erNf7I",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-833fa27d89a1170e",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# Save X_train, X_test, y_train, y_test for final testing\n",
    "if not os.path.exists('./data'):\n",
    "    os.mkdir('./data')\n",
    "np.savez_compressed('./data/train_test_data.npz', X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7JTJltPLJYp3",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c3845037b6f7611c",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Create a model using only Classification, no data transformation (other than reshaping)\n",
    "\n",
    "**Question:** You need to build a 1-layer (head layer only) network model with `tensorflow.keras`. Please name the head layer \"dense_head\". \n",
    "\n",
    "Set variable `model0` to be a Keras `Sequential` model object that implements your model.\n",
    "\n",
    "**Hints:**\n",
    "1. Since the dataset is 2-dimensional, you may want to use `Flatten()` in `tensorflow.keras.layers` to make your input data 1 dimensional.\n",
    "    - The `input shape` argument of the `Flatten()` layer should be the shape of a single example\n",
    "2. The number of units in your head layer \n",
    "    - Depends on how you represented the target\n",
    "    - It should be equal to the final dimension of  `y`\n",
    "3. Activation function for the head layer: Since this is a classification problem\n",
    "    - Use  `sigmoid` if your target's final dimension equals 1\n",
    "    - Use  `softmax` if your target's final dimension is greater than 1\n",
    "\n",
    "Notice that our model has lots of parameters but we have relatively few training examples.\n",
    "\n",
    "So our model will likely be prone to overfitting.\n",
    "- A Dropout layer maybe helpful to prevent overfitting and accelerate your training process. \n",
    "    - If you want to use a Dropout layer, you can use `Dropout()`, which is in  `tensorflow.keras.layers`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 775
    },
    "colab_type": "code",
    "id": "wFF00mA7PUYD",
    "nbgrader": {
     "grade": false,
     "grade_id": "build_model_0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "56c302a5-efba-4c2e-bb3e-08f58c6e4dd9"
   },
   "outputs": [],
   "source": [
    "# Set model0 equal to a Keras Sequential model\n",
    "model0 = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# Set Classifier activation and loss depending on shape of target\n",
    "if helper.y_OHE(y):\n",
    "    num_cases = 2\n",
    "    activation = \"softmax\"\n",
    "    loss = 'categorical_crossentropy'\n",
    "else:\n",
    "    num_cases = 1\n",
    "    activation = \"sigmoid\"\n",
    "    loss = 'binary_crossentropy'\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model0 = Sequential()\n",
    "model0.add(Flatten(input_shape=(X.shape[1:])))\n",
    "model0.add(Dropout(0.2))\n",
    "model0.add(Dense(num_cases, activation=activation, name='dense_head'\n",
    "                )\n",
    "          )\n",
    "\n",
    "# Alternative solution: Use a regularizer rather than Dropout\n",
    "# Regularize\n",
    "from tensorflow.keras import regularizers\n",
    "C= X.shape[0]\n",
    "regularizer = regularizers.l2( 1/C )\n",
    "\n",
    "model0_reg = Sequential()\n",
    "model0_reg.add(Flatten(input_shape=(X.shape[1:])))\n",
    "#model0.add(Dropout(0.2))\n",
    "model0_reg.add(Dense(num_cases, activation=activation, name='dense_head', \n",
    "                 kernel_regularizer=regularizer, bias_regularizer=regularizer\n",
    "                )\n",
    "          )\n",
    "\n",
    "# Keep all the models in a hash\n",
    "model_to_use = \"Using dropout\"\n",
    "model0_s = { \"Using dropout\": model0,\n",
    "             \"Using regularizer\": model0_reg\n",
    "           }\n",
    "\n",
    "model0 = model0_s[model_to_use]\n",
    "### END SOLUTION\n",
    "\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3922bc3edce3a82a",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# We can plot our model here using plot_model()\n",
    "plot_model(model0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-30b12281f8b3ff4b",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Train model\n",
    "\n",
    "**Question:**\n",
    "\n",
    "Now that you have built your first model, you will compile and train it. The requirements are as follows:\n",
    "\n",
    "- Split the **training** examples `X_train, y_train` again !\n",
    "    - 80% will be used for training the model\n",
    "    - 20% will be used as validation (out of sample) examples\n",
    "    - Use `train_test_split()` from `sklearn` to perform this split\n",
    "        -  Set the `random_state` parameter of `train_test_split()` to be 42\n",
    "\n",
    "- Loss function: \n",
    "    - `binary_crossentropy` if your target is one-dimensional\n",
    "    - `categorical_crossentropy`if your target is One Hot Encoded\n",
    "- Metric: \"accuracy\"\n",
    "- Set the model name to be \"Head Only\" and store it in a variable `model_name0`\n",
    "- Use the value in variable `max_epochs` as the number of epochs for training\n",
    "- Save your training results in a variable named `history0`\n",
    "- Plot your training results using the `plotTrain` method described in the Student API above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "train_model_0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the model name and max_epochs\n",
    "model_name0 = \"Head only\"\n",
    "max_epochs = 20\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_, X_val_, y_train_, y_val_ = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# Try a couple of models\n",
    "history0_s = {}\n",
    "for model_name, model in model0_s.items():\n",
    "    print(\"Model: \", model_name)\n",
    "    model.compile(loss=loss, metrics=metrics)\n",
    "    history = model.fit(X_train_, y_train_, epochs=max_epochs, validation_data=(X_val_, y_val_))\n",
    "    fig, axs = helper.plotTrain(history, model_name0 + ' (' + model_name +')')\n",
    "\n",
    "    history0_s[model_name] = history\n",
    "\n",
    "model0 = model0_s[model_to_use]\n",
    "history0 = history0_s[model_to_use]\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHsceFTbpnvr",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e1886c4e415f795e",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## How many weights in the model ?\n",
    "\n",
    "**Question:**   \n",
    "\n",
    "Calculate the number of parameters in your model.  \n",
    "- Set variable `num_parameters0` to be equal to the number of parameters in your model.\n",
    "\n",
    "**Hint:** The model object may have a method to help you ! Remember that Jupyter can help you find the methods that an object implements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dgDetvgupt58",
    "nbgrader": {
     "grade": false,
     "grade_id": "num_of_parameters",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set num_parameters0 equal to the number of weights in the model\n",
    "num_parameters0 = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "num_parameters0 = model0.count_params()\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Parameters number in model0: \", num_parameters0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hR7QB27Jhx8",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-89fa3731299113d7",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "**Question:**\n",
    "\n",
    "We have trained our model. We now need to  evaluate the model using the test dataset created in an earlier cell.\n",
    "\n",
    "Please store the model score in a variable named `score0`.   \n",
    "\n",
    "**Hint:** The model object has a method  `evaluate`.  Use that to compute the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_y1rTpduJhkE",
    "nbgrader": {
     "grade": false,
     "grade_id": "evaluate_model_0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "8e8c0c99-2c80-4ec3-bab9-e08de97c3807"
   },
   "outputs": [],
   "source": [
    "score0 = []\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "score0 = model0.evaluate(X_test, y_test, verbose=0)\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"{n:s}: Test loss: {l:3.2f} / Test accuracy: {a:3.2f}\".format(n=model_name0, l=score0[0], a=score0[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNkyZ8VRd-d3",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6aed77f4dd85c016",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Save the trained model0 and history0 for submission\n",
    "\n",
    "Your fitted model can be saved for later use\n",
    "- In general: so you can resume training at a later time\n",
    "- In particular: to allow us to grade it !\n",
    "\n",
    "Execute the following cell to save your model, which you will submit to us for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "OesE2_-gd-d4",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9cde4b2b69397c4",
     "locked": true,
     "solution": false
    },
    "outputId": "c4cf36e4-00bc-4d73-8aa2-7cae8724f4a8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "helper.saveModel(model0, model_name0)\n",
    "helper.saveHistory(history0, model_name0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_E8q6JBd-d7",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b6e3b1e0ad21422",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Restore the model (make sure that it works)\n",
    "\n",
    "model_loaded = helper.loadModel(model_name0)\n",
    "score_loaded = model_loaded.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "assert score_loaded[0] == score0[0] and score_loaded[1] == score0[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JXX-_3_SKsla",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67c1b5674378d4f6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Create a new model with an additional Dense layer \n",
    "\n",
    "**Question:** \n",
    "\n",
    "We will add more layers to the original model0. \n",
    "\n",
    "- You need to add **AT LEAST ONE** Dense layer followed by an activation function (for example, ReLU)\n",
    "    - You can add more layers if you like\n",
    "    \n",
    "- The number of units in your very **FIRST** Dense layer should be equal to the value of variable `num_features_1`, as set below.\n",
    "    - Please name this Dense layer \"dense_1\" and the head layer \"dense_head\". \n",
    "\n",
    "Set variable `model1` to be a Keras `Sequential` model object that implements your model.\n",
    "\n",
    "**Hints:**\n",
    "- Don't forget to flatten your input data!\n",
    "- A Dropout layer maybe helpful to prevent overfitting and accelerate your training process. \n",
    "    - If you want to use a Dropout layer, you can use `Dropout()`, which is in  `tensorflow.keras.layers`. \n",
    "\n",
    "Hopefully your new model performs **better** than your first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Ga3U-syPaCz",
    "nbgrader": {
     "grade": false,
     "grade_id": "build_model_1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set model1 equal to a Keras Sequential model\n",
    "model1 = None\n",
    "num_features_1 = 64\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Flatten(input_shape=(X.shape[1:])))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(num_features_1, activation='relu', name='dense_1'))\n",
    "\n",
    "model1.add(Dense(num_cases, activation=activation, name='dense_head'\n",
    "                )\n",
    "          )\n",
    "\n",
    "# Alternative solution: Use a regularizer rather than Dropout\n",
    "model1_reg = Sequential()\n",
    "model1_reg.add(Flatten(input_shape=(X.shape[1:])))\n",
    "model1_reg.add(Dropout(0.2))\n",
    "model1_reg.add(Dense(num_features_1, activation='relu', name='dense_1'))\n",
    "\n",
    "model1_reg.add(Dense(num_cases, activation=activation, name='dense_head',\n",
    "                  kernel_regularizer=regularizer, bias_regularizer=regularizer\n",
    "                )\n",
    "          )\n",
    "\n",
    "# Keep all the models in a hash\n",
    "model1_s = { \"Using dropout\": model1,\n",
    "             \"Using regularizer\": model1_reg\n",
    "           }\n",
    "\n",
    "model1= model1_s[model_to_use]\n",
    "### END SOLUTION\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-607314e54aa25e50",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot your model\n",
    "plot_model(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad82889fc971e9fd",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Train your new model\n",
    "\n",
    "**Question:**\n",
    "\n",
    "Now that you have built your new model1,  you will compile and train model1. The requirements are as follows:\n",
    "\n",
    "- Set the model name to be \"Dense + Head\" and store it in a variable `model_name0`\n",
    "- Use the same datasets for training and validation as in your first model\n",
    "- Use the same Loss function and metrics as in your first model\n",
    "- Use the value in variable`max_epochs` as the number of epochs for training\n",
    "- Save your training results in a variable named `history1`\n",
    "- Plot your training results using the`plotTrain` method described in the Student API above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "train_model_1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Train the model using the API\n",
    "model_name1 = \"Dense + Head\"\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# Try a couple of models\n",
    "history1_s = {}\n",
    "for model_name, model in model1_s.items():\n",
    "    print(\"Model: \", model_name)\n",
    "    model.compile(loss=loss, metrics=metrics)\n",
    "    history = model.fit(X_train_, y_train_, epochs=max_epochs, validation_data=(X_val_, y_val_))\n",
    "    fig, axs = helper.plotTrain(history, model_name0 + ' (' + model_name +')')\n",
    "    \n",
    "    history1_s[model_name] = history\n",
    "\n",
    "history1= history1_s[model_to_use]\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XzU2xKWcsEAo",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a048e8f185c7dafe",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## How many weights in this model ?\n",
    "\n",
    "**Question:** \n",
    "\n",
    "Calculate the number of parameters in your new model.  \n",
    "- Set variable `num_parameters1` to be equal to the number of parameters in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gXs0EZZVsHqB",
    "nbgrader": {
     "grade": false,
     "grade_id": "num_parameters_model_1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set num_parameters1 equal to the number of weights in the model\n",
    "num_parameters1 = None\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "num_parameters1 = model1.count_params()\n",
    "### END SOLUTION\n",
    "\n",
    "print('Parameters number in model1:', num_parameters1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfBjJLU7J7L4",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-848f6eee66efac66",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "**Question:** \n",
    "\n",
    "Evaluate the new model using the test dataset. Please store the model score in a variable named `score1`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5wFSFvwJ68n",
    "nbgrader": {
     "grade": false,
     "grade_id": "evaluate_model_1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "score1 = []\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "score1 = model1.evaluate(X_test, y_test, verbose=0)\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"{n:s}: Test loss: {l:3.2f} / Test accuracy: {a:3.2f}\".format(n=model_name1, l=score1[0], a=score1[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b7c5d4dbb25b7b33",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Save your trained model1 and history1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f7c7b3b8e2701251",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "helper.saveModel(model1, model_name1)\n",
    "helper.saveHistory(history1, model_name1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a0132560885e887",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Discussion\n",
    "You can learn a lot by experimenting.  Some ideas to try:\n",
    "- Try more than one additional `Dense` layer \n",
    "- Change the number of units (features) of your `Dense` layers. \n",
    "- Ways to combat overfitting\n",
    "    - Use `Dropout` layers; vary the parameter \n",
    "    - Add a Regularization penalty to the loss function\n",
    "        - You can encourage small weights for the Classifier Head layer by using a regularizer\n",
    "        - This will make our Head layer more similar to most implementations of Logistic Regression\n",
    "        - See [Layer weight regularizers](https://keras.io/api/layers/regularizers/)\n",
    "- Change the activation function\n",
    "- Change the classifier    - \n",
    "- ...\n",
    "\n",
    "Observe the effect of each change on the Loss and Accuracy.\n",
    "\n",
    "- You may want to use early stopping in training\n",
    "    - In order to stop training when model metrics *worsen* rather than *improve*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Submit your assignment!\n",
    "Please click on the blue button <span style=\"color: blue;\"> **Submit** </span> in the upper right corner of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Create Assignment",
  "colab": {
   "collapsed_sections": [],
   "name": "Ships_in_satellite_images.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
