{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yN3g4v8Zl4Fy"
   },
   "source": [
    "# Final Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "moP0TbbABpSP"
   },
   "source": [
    "## Problem description\n",
    "\n",
    "Time to show off everything you learned !\n",
    "\n",
    "You will be performing a Classification task to analyze the sentiment of product reviews.\n",
    "\n",
    "This is similar to a prior assignment\n",
    "- With a different dataset\n",
    "- Multinomial classification with 5 classes\n",
    "\n",
    "But, by now, you have many more tools at your disposal.\n",
    "\n",
    "## Some possible approaches\n",
    "- A review is a sequence of words.  You will need to deal with sequences in some manner.  Some suggestions\n",
    "  - Pooling\n",
    "  - Recurrent Neural Network\n",
    "- Is there an advantage to recognizing *adjacent* words groups (\"n-grams\") rather than treating the document as an unordered set of words ?\n",
    "  - Consider these two sentences\n",
    "    - \"Machine Learning is easy not hard\"\n",
    "    - \"Machine Learning is hard not easy\"\n",
    "\n",
    "  - Two sentences with identical words but different meaning.\n",
    "  - Hint: Convolutional layer\n",
    "- How should we encode words ?\n",
    "  - OHE ? Embedding ?\n",
    "\n",
    "We will **not specify** an approach.  Feel free to experiment.\n",
    "\n",
    "Your goal is to produce a model with an out of sample accuracy meeting a minimum\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SIA71lpFmaw8"
   },
   "source": [
    "## Grading\n",
    "\n",
    "Prior assignments evaluated you step by step.\n",
    "\n",
    "This project is **results-based**. Your goal is to create a model\n",
    "- That achieves an out of sample accuracy of at least 50%\n",
    "- 60% would be better !\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tEqGfYbUBpSQ"
   },
   "source": [
    "## Learning objectives\n",
    "- Experimentation !\n",
    "- Error Analysis leading to model improvement\n",
    "- Appreciate how choices impact number of weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efiTwPiKBpSc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TensorFlow version  2.1.0\n",
      "Version 2, minor 1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import gzip\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Running TensorFlow version \",tf.__version__)\n",
    "\n",
    "# Parse tensorflow version\n",
    "version_match = re.match(\"([0-9]+)\\.([0-9]+)\", tf.__version__)\n",
    "tf_major, tf_minor = int(version_match.group(1)) , int(version_match.group(2))\n",
    "print(\"Version {v:d}, minor {m:d}\".format(v=tf_major, m=tf_minor) )\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, LSTM\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bmNajQkBpSf"
   },
   "source": [
    "# API for students\n",
    "\n",
    "We will define some utility routines.\n",
    "\n",
    "This will simplify problem solving\n",
    "\n",
    "More importantly: it adds structure to your submission so that it may be easily graded\n",
    "\n",
    "- getData: Get a collection of labelled images, used as follows\n",
    "\n",
    "  >`data, labels = getData()`\n",
    "- showData: Visualize labelled images, used as follows\n",
    "\n",
    "  >`showData(data, labels)`\n",
    "\n",
    "- train: train a model and visualize its progress, used as follows\n",
    "\n",
    "  >`train(model, X_train, y_train, model_name, epochs=max_epochs)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiwvVQUJBpSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# My standard magic !  You will see this in almost all my notebooks.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import final_helper\n",
    "%aimport final_helper\n",
    "\n",
    "helper = final_helper.HELPER()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHUZacWsBpSi"
   },
   "source": [
    "\n",
    "\n",
    "## Get the reviews (as text)\n",
    "- **Teacher version:** include code to read and format the raw data, producing a file for the students.  Hide this from student\n",
    "\n",
    "- **Student version:** read file prepared by teacher version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUhrnGczBpSi"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"./Data\"\n",
    "data_file = \"Software_5.json\"\n",
    "data_raw = helper.getDataRaw(DATA_DIR, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "z6x5Q--mJXDE",
    "outputId": "2463af1a-fda4-4288-8616-5d333c772acf"
   },
   "outputs": [],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2XffyPrDedWO",
    "outputId": "14c176e6-c6f4-4820-fc38-0b9f9fb3f625"
   },
   "outputs": [],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_raw, test_size=0.1, shuffle=False)\n",
    "test_student = test.loc[:, test.columns != 'overall']\n",
    "test_grad = test[['reviewerID', 'overall']]\n",
    "train.to_csv('./Data/train.csv', index=False)\n",
    "test_student.to_csv('./Data/test.csv', index=False)\n",
    "test_grad.to_csv('./Data/test_grad.csv', index=False)\n",
    "test_grad[:20].to_csv('./Data/submit_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xN_lWRgsBpSl"
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "The reviews are in the \"reviewText\" attribute.\n",
    "\n",
    "\n",
    "\n",
    "You may try to use other attributes as additional features if you choose, but we suggest that your first model may use this as the only source of features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0ufUriSrtp6"
   },
   "source": [
    "# Get the labelled training data\n",
    "- Features: docs.  Each document is a single review (sequence of characters)\n",
    "- Targets/Labels: sents. Each is the sentiment associated with the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "vwoaUwe-BpSm",
    "outputId": "ff9004ae-0baf-4341-b343-f66d647ffe06"
   },
   "outputs": [],
   "source": [
    "textAttr, sentAttr, titleAttr = \"reviewText\", \"overall\", \"title\"\n",
    "docs, sents = helper.getTextClean(data_raw, textAttr, sentAttr)\n",
    "\n",
    "print(\"Docs shape is \", docs.shape)\n",
    "print(\"Sents shape is \", sents.shape)\n",
    "\n",
    "# docs[:5]\n",
    "print(\"\\nPossible sentiment values: \",  np.unique(sents) ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJyBBa-PBpSo"
   },
   "source": [
    "## More data preprocessing\n",
    "\n",
    "We will need to convert the text in a *sequence* of numbers\n",
    "- Break text up into words\n",
    "- Assign each word a distinct integer\n",
    "\n",
    "Moreover, it will be easier if all sequences have the same length.\n",
    "We can add a \"padding\" character to the front if necessary.\n",
    "\n",
    "We do this for you below.\n",
    "\n",
    "Our method returns\n",
    "- encoded_docs_padded: A matrix of training example *features*\n",
    "  - Each row is an example\n",
    "  - Each row is a *sequence* of fixed length\n",
    "  - Each element of the sequence is an integer, encoding a word in the vocabulary\n",
    "  - The sequence length of every example is *identical* because we have prepended padding if necessary\n",
    "- encoded_docs: A matrix of *unpadded* training example *features*\n",
    "- tok: the Tokenizer used to\n",
    "  - parse strings of characters into words\n",
    "  - encoded each word as an integer\n",
    "\n",
    "\n",
    "You may study our methods parameters and modify them if you wish, e.g., alter the size of the vocabulary or length of sequences.\n",
    "\n",
    "We suggest that your first model uses\n",
    "- encoded_docs_padded as your set of training features, e.g., X\n",
    "- sents: as your targets\n",
    "with the default settings of the method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "ggdZME_FBpSo",
    "outputId": "4d3b180b-9337-4374-8772-f5b29e35f196"
   },
   "outputs": [],
   "source": [
    "## set parameters:\n",
    "# vocab_size : number of words in the vocabulary \n",
    "# words_in_doc: number of words in a review\n",
    "vocab_size_sm, words_in_doc_sm = 400, 100\n",
    "\n",
    "tok, encoded_docs, encoded_docs_padded = helper.encodeDocs(docs, vocab_size=vocab_size_sm, words_in_doc=words_in_doc_sm)\n",
    "\n",
    "print(\"Training example features shape: \",encoded_docs_padded.shape)\n",
    "\n",
    "print(\"Training example features: preview\")\n",
    "encoded_docs_padded[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RSPg2B1RBpSq"
   },
   "source": [
    "## Verify that our encoded documents are the same as the cleaned original\n",
    "\n",
    "At this point: convince yourself that all we have done was encode words as integers and pad out all text to the same length.  The following will demonstrate this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "9HDv4_BXBpSr",
    "outputId": "7a675806-1dd5-4c8b-c0a0-882a67866da4"
   },
   "outputs": [],
   "source": [
    "helper.showEncodedDocs(tok, encoded_docs_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXTltHXxx10g"
   },
   "source": [
    "# Split the examples into training and test (out of sample) data\n",
    "- The number of test examples should be 10% of the total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzxNUXNXvu7r"
   },
   "outputs": [],
   "source": [
    "# Set the following variables\n",
    "# - X_train: ndarray of training example features\n",
    "# - X_test:  ndarray of test example features\n",
    "# - y_train: ndarray of training example targets\n",
    "# - y_test:  ndarray of test example targets\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_docs_padded, sents, test_size=0.10, random_state=42)\n",
    "\n",
    "# OHE the X for some models\n",
    "vocab_size_sm, words_in_doc_sm = 400, 100\n",
    "X_train_OHE, _ = helper.getExamplesOHE(X_train, sents, vocab_size_sm)\n",
    "X_test_OHE, _ = helper.getExamplesOHE(X_test, sents, vocab_size_sm)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6oS5W_hBpS2",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0de960d0bf5c6d38",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set two variables\n",
    "# example_sequence_len: length of the sequence\n",
    "# example_num_features: number of features in a single element of the sequence (of a single example)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# If using OHE:\n",
    "example_shape = X_train_OHE.shape[1:]\n",
    "example_sequence_len, example_num_features = example_shape[0], example_shape[1]\n",
    "\n",
    "assert example_sequence_len == words_in_doc_sm\n",
    "assert example_num_features == vocab_size_sm\n",
    "\n",
    "# If NOT using OHE\n",
    "example_shape = X_train.shape[1:]\n",
    "example_sequence_len, example_num_features = example_shape[0], tok.num_words\n",
    "\n",
    "assert example_sequence_len == words_in_doc_sm\n",
    "assert example_num_features == vocab_size_sm\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uHurBXP607UT"
   },
   "source": [
    "# Create your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o97G-ue51CKX"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Set variables\n",
    "# - model: a Keras Sequential model to predict sentiment\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqzhT4oaBpTJ",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00ae8f085cb69e3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Sample models (for teacher review, not for students)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMLLFIU40UDF"
   },
   "source": [
    "## Simple model: OHE + GlobalMaxPooling + Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0YCQQYrxSH-6",
    "outputId": "2223055d-1388-49c2-a59d-cb1c17ed551e"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "def runModel(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    plot_file = helper.plotModel(model_simple, model_name)\n",
    "    IPython.display.Image(plot_file) \n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    patience = 5\n",
    "    min_delta = .005\n",
    "    max_epochs=30\n",
    "    history = helper.trainModelCat( model, X_train, y_train, max_epochs)\n",
    "\n",
    "    helper.plot_training(history)\n",
    "\n",
    "    helper.eval_model(model, X_test, y_test)\n",
    "\n",
    "\n",
    "model_simple = Sequential( [ GlobalMaxPooling1D(input_shape=X_train_OHE.shape[-2:]),\n",
    "                             Dense( len( np.unique(y_train) ), activation=\"softmax\")\n",
    "                           ]\n",
    "                         )\n",
    "\n",
    "runModel(model_simple, \"OHE + GlobalMaxPooling\", X_train_OHE, X_test_OHE, y_train, y_test)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mEKx798u5j0F"
   },
   "source": [
    "## Model: OHE + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-PHHzHQ0BpTA",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c6f79f80ec231277",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "bf4a7683-9549-4aa9-e1c8-f22c114087b0"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "lstm_size_sm = 4\n",
    "model_lstm = Sequential( [\n",
    "                          LSTM(lstm_size_sm, input_shape=X_train_OHE.shape[-2:], recurrent_dropout=0.),\n",
    "                          Dropout(0.3),\n",
    "                          Dense( len( np.unique(y_train) ), activation=\"softmax\")\n",
    "                         ]\n",
    "                       )\n",
    "\n",
    "runModel(model_lstm, \"OHE + LSTM\", X_train_OHE, X_test_OHE, y_train, y_test)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M48Bu9U0dt1G"
   },
   "source": [
    "## Model: Embedding + GlobalMaxPooling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NxQInB0PoTB9",
    "outputId": "c7d42fda-7e2d-4c4b-9f28-c46c1107085a"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "embed_size_sm=16\n",
    "model_simple_es = Sequential( [Embedding(tok.num_words+1, embed_size_sm, input_length=words_in_doc_sm),\n",
    "                             GlobalMaxPooling1D(),\n",
    "                             Dense( len( np.unique(y_train) ), activation=\"softmax\")\n",
    "                         ]\n",
    "                       )\n",
    "\n",
    "runModel(model_simple_es, \"Embedding + GlobalMaxPooling\", X_train, X_test, y_train, y_test)\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4Lg4EVtbJ00"
   },
   "source": [
    "# Embedding + LSTM (rather than GlobalPooling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aNtzvlpNdwNQ",
    "outputId": "9c9817ca-4638-4c75-bad0-bf7c2526cfca"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_lstm_e = Sequential( [Embedding(tok.num_words+1, embed_size_sm, input_length=words_in_doc_sm),\n",
    "                            LSTM(lstm_size_sm),\n",
    "                          Dense( len( np.unique(y_train) ), activation=\"softmax\")\n",
    "                         ]\n",
    "                       )\n",
    "\n",
    "runModel(model_lstm_e, \"Embedding + LSTM\", X_train, X_test, y_train, y_test)\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0mgU33LLlmXs"
   },
   "source": [
    "# Try a larger vocab, since Embeddings are more compact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ji9SBZe0dOpT"
   },
   "source": [
    "## model: Embedding Big + GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ROCtJSr0pR6j",
    "outputId": "fc53ecd1-bbfa-4fd5-e23e-e92f9ecc6e76"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "vocab_size_b, words_in_doc_b, embed_size_b, lstm_size_b = int(10*vocab_size_sm), words_in_doc_sm, int(1*embed_size_sm), lstm_size_sm\n",
    "tok_b, encoded_docs_b, encoded_docs_padded_b = encodeDocs(docs, vocab_size=vocab_size_b, words_in_doc=words_in_doc_b)\n",
    "\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(encoded_docs_padded_b, sents, test_size=0.10, random_state=42)\n",
    "\n",
    "X_train_b.shape, y_train_b.shape\n",
    "\n",
    "\n",
    "model_simple_es_b = Sequential( [Embedding(tok_b.num_words+1, embed_size_b, input_length=words_in_doc_b),\n",
    "                             GlobalMaxPooling1D(),\n",
    "                          Dense( len( np.unique(y_train_b) ), activation=\"softmax\")\n",
    "                         ]\n",
    "                       )\n",
    "\n",
    "runModel(model_simple_es_b, \"Embedding Big + GlobalMaxPooling\", X_train_b, X_test_b, y_train_b, y_test_b)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "erWemn_-dMTr"
   },
   "source": [
    "## Model: Embedding Big + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "baQaoQiQcSju",
    "outputId": "9bd5df7b-0a92-429f-8ae8-227e1aa98982"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_lstm_b = Sequential( [Embedding(tok_b.num_words+1, embed_size_b, input_length=words_in_doc_b),\n",
    "                            LSTM(lstm_size_b),\n",
    "                            Dropout(0.25),\n",
    "                          Dense( len( np.unique(y_train_b) ), activation=\"softmax\")\n",
    "                         ]\n",
    "                       )\n",
    "\n",
    "runModel(model_lstm_b, \"Embedding Big + LSTM\", X_train_b, X_test_b, y_train_b, y_test_b)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mSw-Cw4d14X"
   },
   "source": [
    "## Model: more complex\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MT2AM28CV1vd",
    "outputId": "54407b4a-7894-4ecd-e6d0-83dfd9ed373e"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION \n",
    "model_x = Sequential( [Embedding(tok_b.num_words+1, embed_size_b, input_length=words_in_doc_b),\n",
    "                          Dropout(0.25),\n",
    "                          #LSTM(lstm_size_b), Dense(50, activation=\"relu\"),\n",
    "                          GlobalMaxPooling1D(),\n",
    "                          Dropout(0.25),\n",
    "                           Dense(100, activation=\"relu\"),\n",
    "                         \n",
    "                          Dense( len( np.unique(y_train_b) ), activation=\"softmax\")\n",
    "                         ]\n",
    "                       )\n",
    "\n",
    "runModel(model_x, \"Embedding Big + Compldex\", X_train_b, X_test_b, y_train_b, y_test_b)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iz_Wroa1BpTU",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0ad6ed9cd2b135fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Submit your model\n",
    "\n",
    "\n",
    "- Was the increase in number of weights compensated by a gain in accuracy when using a Recurrent Layer type compared to the Classifier only model ?\n",
    "- Can you speculate why this is so ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NIgzZKsQ16VX"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "model = model_simple\n",
    "\n",
    "# This model uses non-standard features\n",
    "X_test = X_test_OHE\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZodh8L_1xsT"
   },
   "source": [
    "# Evaluate your model on the previously constructed test examples (out of sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ykqbRFlC1f_A",
    "outputId": "db4345d2-92f2-4d1f-aaf6-05407509e98d"
   },
   "outputs": [],
   "source": [
    "loss_test, acc_test = eval_model(model, X_test, y_test)\n",
    "# - loss_test: Loss, out of sample\n",
    "# - acc_test:  Accuracy, out of sample.  This is what you will be graded on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gtQ_IGvQBpTS",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f1feed2553377a71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## How many weights in your Classifier only model ?\n",
    "\n",
    "How many weights in your model ?\n",
    "\n",
    "You should always be sensitive to how \"big\" your model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-u1ERSiuBpTS",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad84e21e2763f573",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set variable\n",
    "# - num_weight: number of weights in your model\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "num_weights = model.count_params()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bpWw_tXH_zwu"
   },
   "source": [
    "# Discussion topics\n",
    "- Compare the number of weights in each model.  Did the added complexity (more weights) lead to better performance ?\n",
    "- **Where** were the largest increase in weights between models\n",
    "  - Embeddings consume a lot of weights\n",
    "    - But eliminates a dimension: single integer representation of a word vs a OHE vector of length words_in_vocab\n",
    "    - So subsequent layers may need fewer weights compared to OHE\n",
    "- Should we have formulated this as a Regression task rather than a Classification task ?\n",
    "  - Is the difference in rating between 0 and 1 the same as between 3 and 4 ?\n",
    "    - Perhaps there are bigger *absolute* differences in satisfaction  in lower ratings\n",
    "      - i.e., Big difference between 0 and 1, smaller difference between 3 and 4"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Create Assignment",
  "colab": {
   "collapsed_sections": [
    "gtQ_IGvQBpTS",
    "IoeQjuCDBpTG"
   ],
   "name": "Sentiment_from_reviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
